============================================================
Phase 2: HF Finetuning & Evaluation Pipeline
============================================================

[10:38:18] Phase 2.1: SKIPPING - SST-2 checkpoint already exists

[10:38:18] Phase 2.2: Evaluating GPT-2 SST-2...
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/ayman/modern_llm/.venv/lib/python3.12/site-packages/peft/tuners/lora/layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
  warnings.warn(
Processed 160 samples...
Processed 320 samples...
Processed 480 samples...
Processed 640 samples...
Processed 800 samples...

Accuracy: 0.8945
Macro F1: 0.8941
Wrote metrics to experiments/sst2_eval_metrics.csv
Wrote 92 misclassified examples (showing first 50) to experiments/sst2_misclassified.json

[10:38:29] Phase 2.3: Training T5 + LoRA on DialogSum...
Training:   0%|          | 0/2000 [00:00<?, ?step/s]/home/ayman/modern_llm/src/modern_llm/training/trainer_base.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(dtype=autocast_dtype, enabled=self.use_amp):
10:38:35 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=1.1452 lr=5.000e-06
10:38:45 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
10:38:45 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=0.9921 lr=5.000e-06
10:38:55 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
10:38:55 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=1.1623 lr=5.000e-06
10:39:05 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
10:39:06 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=1.2905 lr=5.000e-06
10:39:16 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
10:39:16 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=1.1327 lr=5.000e-06
10:39:26 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
10:39:26 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=2.0150 lr=5.000e-06
10:39:36 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
10:39:36 - trainer.t5-dialogsum-lora-main - INFO - step=0 loss=0.8813 lr=5.000e-06
10:39:46 - trainer.t5-dialogsum-lora-main - INFO - eval step=0 loss=15.4822 ppl=5294453.70
Training:   0%|          | 1/2000 [01:11<39:58:31, 71.99s/step]Training:   0%|          | 2/2000 [01:12<16:36:19, 29.92s/step]Training:   0%|          | 3/2000 [01:12<9:08:13, 16.47s/step] Training:   0%|          | 4/2000 [01:13<5:37:46, 10.15s/step]Training:   0%|          | 5/2000 [01:13<3:41:29,  6.66s/step]Training:   0%|          | 6/2000 [01:14<2:31:24,  4.56s/step]Training:   0%|          | 7/2000 [01:14<1:46:56,  3.22s/step]Training:   0%|          | 8/2000 [01:15<1:17:48,  2.34s/step]Training:   0%|          | 9/2000 [01:15<58:18,  1.76s/step]  Training:   0%|          | 10/2000 [01:16<45:04,  1.36s/step]Training:   1%|          | 11/2000 [01:16<36:01,  1.09s/step]Training:   1%|          | 12/2000 [01:17<29:45,  1.11step/s]Training:   1%|          | 13/2000 [01:17<25:25,  1.30step/s]Training:   1%|          | 14/2000 [01:18<22:25,  1.48step/s]Training:   1%|          | 15/2000 [01:18<20:19,  1.63step/s]Training:   1%|          | 16/2000 [01:19<18:51,  1.75step/s]Training:   1%|          | 17/2000 [01:19<17:49,  1.85step/s]Training:   1%|          | 18/2000 [01:19<17:06,  1.93step/s]Training:   1%|          | 19/2000 [01:20<16:36,  1.99step/s]Training:   1%|          | 20/2000 [01:20<16:15,  2.03step/s]Training:   1%|          | 21/2000 [01:21<16:00,  2.06step/s]Training:   1%|          | 22/2000 [01:21<15:49,  2.08step/s]Training:   1%|          | 23/2000 [01:22<15:41,  2.10step/s]Training:   1%|          | 24/2000 [01:22<15:36,  2.11step/s]Training:   1%|▏         | 25/2000 [01:23<15:32,  2.12step/s]Training:   1%|▏         | 26/2000 [01:23<15:29,  2.12step/s]Training:   1%|▏         | 27/2000 [01:24<15:27,  2.13step/s]Training:   1%|▏         | 28/2000 [01:24<15:25,  2.13step/s]Training:   1%|▏         | 29/2000 [01:25<15:24,  2.13step/s]Training:   2%|▏         | 30/2000 [01:25<15:23,  2.13step/s]Training:   2%|▏         | 31/2000 [01:26<15:22,  2.13step/s]Training:   2%|▏         | 32/2000 [01:26<15:22,  2.13step/s]Training:   2%|▏         | 33/2000 [01:26<15:21,  2.14step/s]Training:   2%|▏         | 34/2000 [01:27<15:20,  2.14step/s]Training:   2%|▏         | 35/2000 [01:27<15:19,  2.14step/s]Training:   2%|▏         | 36/2000 [01:28<15:19,  2.14step/s]Training:   2%|▏         | 37/2000 [01:28<15:18,  2.14step/s]Training:   2%|▏         | 38/2000 [01:29<15:18,  2.14step/s]Training:   2%|▏         | 39/2000 [01:29<15:18,  2.14step/s]Training:   2%|▏         | 40/2000 [01:30<15:17,  2.14step/s]Training:   2%|▏         | 41/2000 [01:30<15:16,  2.14step/s]Training:   2%|▏         | 42/2000 [01:31<15:16,  2.14step/s]Training:   2%|▏         | 43/2000 [01:31<15:15,  2.14step/s]Training:   2%|▏         | 44/2000 [01:32<15:15,  2.14step/s]Training:   2%|▏         | 45/2000 [01:32<15:14,  2.14step/s]Training:   2%|▏         | 46/2000 [01:33<15:15,  2.13step/s]Training:   2%|▏         | 47/2000 [01:33<15:15,  2.13step/s]Training:   2%|▏         | 48/2000 [01:33<15:14,  2.13step/s]Training:   2%|▏         | 49/2000 [01:34<15:13,  2.13step/s]Training:   2%|▎         | 50/2000 [01:34<15:13,  2.14step/s]10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.3675 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.2865 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.3065 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.3326 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.3064 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.3297 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.3183 lr=2.550e-04
10:40:10 - trainer.t5-dialogsum-lora-main - INFO - step=50 loss=0.2956 lr=2.550e-04
Training:   3%|▎         | 51/2000 [01:35<15:12,  2.14step/s]Training:   3%|▎         | 52/2000 [01:35<15:12,  2.14step/s]Training:   3%|▎         | 53/2000 [01:36<15:11,  2.14step/s]Training:   3%|▎         | 54/2000 [01:36<15:11,  2.14step/s]Training:   3%|▎         | 55/2000 [01:37<15:10,  2.14step/s]Training:   3%|▎         | 56/2000 [01:37<15:10,  2.14step/s]Training:   3%|▎         | 57/2000 [01:38<15:09,  2.14step/s]Training:   3%|▎         | 58/2000 [01:38<15:09,  2.14step/s]Training:   3%|▎         | 59/2000 [01:39<15:08,  2.14step/s]Training:   3%|▎         | 60/2000 [01:39<15:08,  2.14step/s]Training:   3%|▎         | 61/2000 [01:40<15:07,  2.14step/s]Training:   3%|▎         | 62/2000 [01:40<15:07,  2.14step/s]Training:   3%|▎         | 63/2000 [01:41<15:06,  2.14step/s]Training:   3%|▎         | 64/2000 [01:41<15:06,  2.14step/s]Training:   3%|▎         | 65/2000 [01:41<15:05,  2.14step/s]Training:   3%|▎         | 66/2000 [01:42<15:04,  2.14step/s]Training:   3%|▎         | 67/2000 [01:42<15:04,  2.14step/s]Training:   3%|▎         | 68/2000 [01:43<15:04,  2.14step/s]Training:   3%|▎         | 69/2000 [01:43<15:03,  2.14step/s]Training:   4%|▎         | 70/2000 [01:44<15:03,  2.14step/s]Training:   4%|▎         | 71/2000 [01:44<15:02,  2.14step/s]Training:   4%|▎         | 72/2000 [01:45<15:02,  2.14step/s]Training:   4%|▎         | 73/2000 [01:45<15:01,  2.14step/s]Training:   4%|▎         | 74/2000 [01:46<15:01,  2.14step/s]Training:   4%|▍         | 75/2000 [01:46<15:00,  2.14step/s]Training:   4%|▍         | 76/2000 [01:47<15:00,  2.14step/s]Training:   4%|▍         | 77/2000 [01:47<14:59,  2.14step/s]Training:   4%|▍         | 78/2000 [01:48<14:59,  2.14step/s]Training:   4%|▍         | 79/2000 [01:48<14:58,  2.14step/s]Training:   4%|▍         | 80/2000 [01:48<14:58,  2.14step/s]Training:   4%|▍         | 81/2000 [01:49<14:58,  2.14step/s]Training:   4%|▍         | 82/2000 [01:49<14:57,  2.14step/s]Training:   4%|▍         | 83/2000 [01:50<14:56,  2.14step/s]Training:   4%|▍         | 84/2000 [01:50<14:56,  2.14step/s]Training:   4%|▍         | 85/2000 [01:51<14:56,  2.14step/s]Training:   4%|▍         | 86/2000 [01:51<14:55,  2.14step/s]Training:   4%|▍         | 87/2000 [01:52<14:55,  2.14step/s]Training:   4%|▍         | 88/2000 [01:52<14:54,  2.14step/s]Training:   4%|▍         | 89/2000 [01:53<14:54,  2.14step/s]Training:   4%|▍         | 90/2000 [01:53<14:53,  2.14step/s]Training:   5%|▍         | 91/2000 [01:54<14:53,  2.14step/s]Training:   5%|▍         | 92/2000 [01:54<14:52,  2.14step/s]Training:   5%|▍         | 93/2000 [01:55<14:52,  2.14step/s]Training:   5%|▍         | 94/2000 [01:55<14:51,  2.14step/s]Training:   5%|▍         | 95/2000 [01:55<14:51,  2.14step/s]Training:   5%|▍         | 96/2000 [01:56<14:51,  2.14step/s]Training:   5%|▍         | 97/2000 [01:56<14:50,  2.14step/s]Training:   5%|▍         | 98/2000 [01:57<14:50,  2.14step/s]Training:   5%|▍         | 99/2000 [01:57<14:49,  2.14step/s]Training:   5%|▌         | 100/2000 [01:58<14:49,  2.14step/s]10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1404 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1159 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1805 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1365 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1580 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1732 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1255 lr=5.000e-04
10:40:33 - trainer.t5-dialogsum-lora-main - INFO - step=100 loss=0.1751 lr=5.000e-04
Training:   5%|▌         | 101/2000 [01:58<14:48,  2.14step/s]Training:   5%|▌         | 102/2000 [01:59<14:48,  2.14step/s]Training:   5%|▌         | 103/2000 [01:59<14:47,  2.14step/s]Training:   5%|▌         | 104/2000 [02:00<14:47,  2.14step/s]Training:   5%|▌         | 105/2000 [02:00<14:46,  2.14step/s]Training:   5%|▌         | 106/2000 [02:01<14:47,  2.14step/s]Training:   5%|▌         | 107/2000 [02:01<14:46,  2.14step/s]Training:   5%|▌         | 108/2000 [02:02<14:46,  2.13step/s]Training:   5%|▌         | 109/2000 [02:02<14:45,  2.14step/s]Training:   6%|▌         | 110/2000 [02:03<14:44,  2.14step/s]Training:   6%|▌         | 111/2000 [02:03<14:44,  2.14step/s]Training:   6%|▌         | 112/2000 [02:03<14:43,  2.14step/s]Training:   6%|▌         | 113/2000 [02:04<14:43,  2.14step/s]Training:   6%|▌         | 114/2000 [02:04<14:42,  2.14step/s]Training:   6%|▌         | 115/2000 [02:05<14:42,  2.14step/s]Training:   6%|▌         | 116/2000 [02:05<14:41,  2.14step/s]Training:   6%|▌         | 117/2000 [02:06<14:41,  2.14step/s]Training:   6%|▌         | 118/2000 [02:06<14:40,  2.14step/s]Training:   6%|▌         | 119/2000 [02:07<14:40,  2.14step/s]Training:   6%|▌         | 120/2000 [02:07<14:39,  2.14step/s]Training:   6%|▌         | 121/2000 [02:08<14:39,  2.14step/s]Training:   6%|▌         | 122/2000 [02:08<14:39,  2.14step/s]Training:   6%|▌         | 123/2000 [02:09<14:39,  2.14step/s]Training:   6%|▌         | 124/2000 [02:09<14:38,  2.14step/s]Training:   6%|▋         | 125/2000 [02:10<14:37,  2.14step/s]Training:   6%|▋         | 126/2000 [02:10<14:37,  2.14step/s]Training:   6%|▋         | 127/2000 [02:10<14:36,  2.14step/s]Training:   6%|▋         | 128/2000 [02:11<14:36,  2.14step/s]Training:   6%|▋         | 129/2000 [02:11<14:35,  2.14step/s]Training:   6%|▋         | 130/2000 [02:12<14:35,  2.14step/s]Training:   7%|▋         | 131/2000 [02:12<14:34,  2.14step/s]Training:   7%|▋         | 132/2000 [02:13<14:34,  2.14step/s]Training:   7%|▋         | 133/2000 [02:13<14:34,  2.14step/s]Training:   7%|▋         | 134/2000 [02:14<14:33,  2.14step/s]Training:   7%|▋         | 135/2000 [02:14<14:33,  2.14step/s]Training:   7%|▋         | 136/2000 [02:15<14:32,  2.14step/s]Training:   7%|▋         | 137/2000 [02:15<14:32,  2.14step/s]Training:   7%|▋         | 138/2000 [02:16<14:31,  2.14step/s]Training:   7%|▋         | 139/2000 [02:16<14:31,  2.14step/s]Training:   7%|▋         | 140/2000 [02:17<14:30,  2.14step/s]Training:   7%|▋         | 141/2000 [02:17<14:30,  2.14step/s]Training:   7%|▋         | 142/2000 [02:17<14:29,  2.14step/s]Training:   7%|▋         | 143/2000 [02:18<14:29,  2.14step/s]Training:   7%|▋         | 144/2000 [02:18<14:28,  2.14step/s]Training:   7%|▋         | 145/2000 [02:19<14:28,  2.14step/s]Training:   7%|▋         | 146/2000 [02:19<14:28,  2.14step/s]Training:   7%|▋         | 147/2000 [02:20<14:27,  2.14step/s]Training:   7%|▋         | 148/2000 [02:20<14:26,  2.14step/s]Training:   7%|▋         | 149/2000 [02:21<14:26,  2.14step/s]Training:   8%|▊         | 150/2000 [02:21<14:25,  2.14step/s]10:40:56 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.1610 lr=5.000e-04
10:40:56 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.1231 lr=5.000e-04
10:40:56 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.1031 lr=5.000e-04
10:40:57 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.0921 lr=5.000e-04
10:40:57 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.1201 lr=5.000e-04
10:40:57 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.0707 lr=5.000e-04
10:40:57 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.1551 lr=5.000e-04
10:40:57 - trainer.t5-dialogsum-lora-main - INFO - step=150 loss=0.1027 lr=5.000e-04
Training:   8%|▊         | 151/2000 [02:22<14:25,  2.14step/s]Training:   8%|▊         | 152/2000 [02:22<14:25,  2.14step/s]Training:   8%|▊         | 153/2000 [02:23<14:24,  2.14step/s]Training:   8%|▊         | 154/2000 [02:23<14:24,  2.14step/s]Training:   8%|▊         | 155/2000 [02:24<14:23,  2.14step/s]Training:   8%|▊         | 156/2000 [02:24<14:23,  2.14step/s]Training:   8%|▊         | 157/2000 [02:25<14:22,  2.14step/s]Training:   8%|▊         | 158/2000 [02:25<14:22,  2.14step/s]Training:   8%|▊         | 159/2000 [02:25<14:21,  2.14step/s]Training:   8%|▊         | 160/2000 [02:26<14:21,  2.14step/s]Training:   8%|▊         | 161/2000 [02:26<14:21,  2.14step/s]Training:   8%|▊         | 162/2000 [02:27<14:20,  2.14step/s]Training:   8%|▊         | 163/2000 [02:27<14:19,  2.14step/s]Training:   8%|▊         | 164/2000 [02:28<14:19,  2.14step/s]Training:   8%|▊         | 165/2000 [02:28<14:18,  2.14step/s]Training:   8%|▊         | 166/2000 [02:29<14:18,  2.14step/s]Training:   8%|▊         | 167/2000 [02:29<14:18,  2.14step/s]Training:   8%|▊         | 168/2000 [02:30<14:17,  2.14step/s]Training:   8%|▊         | 169/2000 [02:30<14:17,  2.14step/s]Training:   8%|▊         | 170/2000 [02:31<14:16,  2.14step/s]Training:   9%|▊         | 171/2000 [02:31<14:16,  2.14step/s]Training:   9%|▊         | 172/2000 [02:32<14:15,  2.14step/s]Training:   9%|▊         | 173/2000 [02:32<14:15,  2.14step/s]Training:   9%|▊         | 174/2000 [02:32<14:15,  2.14step/s]Training:   9%|▉         | 175/2000 [02:33<14:14,  2.14step/s]Training:   9%|▉         | 176/2000 [02:33<14:14,  2.14step/s]Training:   9%|▉         | 177/2000 [02:34<14:13,  2.14step/s]Training:   9%|▉         | 178/2000 [02:34<14:12,  2.14step/s]Training:   9%|▉         | 179/2000 [02:35<14:12,  2.14step/s]Training:   9%|▉         | 180/2000 [02:35<14:12,  2.14step/s]Training:   9%|▉         | 181/2000 [02:36<14:11,  2.14step/s]Training:   9%|▉         | 182/2000 [02:36<14:11,  2.14step/s]Training:   9%|▉         | 183/2000 [02:37<14:10,  2.14step/s]Training:   9%|▉         | 184/2000 [02:37<14:09,  2.14step/s]Training:   9%|▉         | 185/2000 [02:38<14:09,  2.14step/s]Training:   9%|▉         | 186/2000 [02:38<14:08,  2.14step/s]Training:   9%|▉         | 187/2000 [02:39<14:08,  2.14step/s]Training:   9%|▉         | 188/2000 [02:39<14:07,  2.14step/s]Training:   9%|▉         | 189/2000 [02:39<14:07,  2.14step/s]Training:  10%|▉         | 190/2000 [02:40<14:07,  2.14step/s]Training:  10%|▉         | 191/2000 [02:40<14:06,  2.14step/s]Training:  10%|▉         | 192/2000 [02:41<14:06,  2.14step/s]Training:  10%|▉         | 193/2000 [02:41<14:05,  2.14step/s]Training:  10%|▉         | 194/2000 [02:42<14:05,  2.14step/s]Training:  10%|▉         | 195/2000 [02:42<14:04,  2.14step/s]Training:  10%|▉         | 196/2000 [02:43<14:04,  2.14step/s]Training:  10%|▉         | 197/2000 [02:43<14:03,  2.14step/s]Training:  10%|▉         | 198/2000 [02:44<14:03,  2.14step/s]Training:  10%|▉         | 199/2000 [02:44<14:03,  2.14step/s]Training:  10%|█         | 200/2000 [02:45<14:02,  2.14step/s]10:41:20 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.1151 lr=5.000e-04
10:41:30 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:41:30 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.1222 lr=5.000e-04
10:41:40 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:41:40 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.1160 lr=5.000e-04
10:41:50 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:41:50 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.1423 lr=5.000e-04
10:42:00 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:42:00 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.2063 lr=5.000e-04
10:42:10 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:42:10 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.1260 lr=5.000e-04
10:42:19 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:42:20 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.2104 lr=5.000e-04
10:42:29 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
10:42:29 - trainer.t5-dialogsum-lora-main - INFO - step=200 loss=0.2030 lr=5.000e-04
10:42:39 - trainer.t5-dialogsum-lora-main - INFO - eval step=200 loss=0.8969 ppl=2.45
Training:  10%|█         | 201/2000 [04:04<12:06:26, 24.23s/step]Training:  10%|█         | 202/2000 [04:05<8:32:26, 17.10s/step] Training:  10%|█         | 203/2000 [04:05<6:02:42, 12.11s/step]Training:  10%|█         | 204/2000 [04:06<4:17:57,  8.62s/step]Training:  10%|█         | 205/2000 [04:06<3:04:40,  6.17s/step]Training:  10%|█         | 206/2000 [04:07<2:13:23,  4.46s/step]Training:  10%|█         | 207/2000 [04:07<1:37:31,  3.26s/step]Training:  10%|█         | 208/2000 [04:08<1:12:25,  2.42s/step]Training:  10%|█         | 209/2000 [04:08<54:51,  1.84s/step]  Training:  10%|█         | 210/2000 [04:09<42:33,  1.43s/step]Training:  11%|█         | 211/2000 [04:09<33:58,  1.14s/step]Training:  11%|█         | 212/2000 [04:09<27:56,  1.07step/s]Training:  11%|█         | 213/2000 [04:10<23:43,  1.25step/s]Training:  11%|█         | 214/2000 [04:10<20:46,  1.43step/s]Training:  11%|█         | 215/2000 [04:11<18:42,  1.59step/s]Training:  11%|█         | 216/2000 [04:11<17:16,  1.72step/s]Training:  11%|█         | 217/2000 [04:12<16:15,  1.83step/s]Training:  11%|█         | 218/2000 [04:12<15:32,  1.91step/s]Training:  11%|█         | 219/2000 [04:13<15:02,  1.97step/s]Training:  11%|█         | 220/2000 [04:13<14:41,  2.02step/s]Training:  11%|█         | 221/2000 [04:14<14:26,  2.05step/s]Training:  11%|█         | 222/2000 [04:14<14:15,  2.08step/s]Training:  11%|█         | 223/2000 [04:15<14:08,  2.10step/s]Training:  11%|█         | 224/2000 [04:15<14:02,  2.11step/s]Training:  11%|█▏        | 225/2000 [04:16<13:58,  2.12step/s]Training:  11%|█▏        | 226/2000 [04:16<13:55,  2.12step/s]Training:  11%|█▏        | 227/2000 [04:16<13:53,  2.13step/s]Training:  11%|█▏        | 228/2000 [04:17<13:52,  2.13step/s]Training:  11%|█▏        | 229/2000 [04:17<13:50,  2.13step/s]Training:  12%|█▏        | 230/2000 [04:18<13:49,  2.13step/s]Training:  12%|█▏        | 231/2000 [04:18<13:48,  2.13step/s]Training:  12%|█▏        | 232/2000 [04:19<13:48,  2.14step/s]Training:  12%|█▏        | 233/2000 [04:19<13:47,  2.14step/s]Training:  12%|█▏        | 234/2000 [04:20<13:46,  2.14step/s]Training:  12%|█▏        | 235/2000 [04:20<13:46,  2.14step/s]Training:  12%|█▏        | 236/2000 [04:21<13:45,  2.14step/s]Training:  12%|█▏        | 237/2000 [04:21<13:45,  2.14step/s]Training:  12%|█▏        | 238/2000 [04:22<13:45,  2.14step/s]Training:  12%|█▏        | 239/2000 [04:22<13:44,  2.14step/s]Training:  12%|█▏        | 240/2000 [04:23<13:44,  2.14step/s]Training:  12%|█▏        | 241/2000 [04:23<13:43,  2.14step/s]Training:  12%|█▏        | 242/2000 [04:24<13:42,  2.14step/s]Training:  12%|█▏        | 243/2000 [04:24<13:42,  2.14step/s]Training:  12%|█▏        | 244/2000 [04:24<13:42,  2.14step/s]Training:  12%|█▏        | 245/2000 [04:25<13:41,  2.14step/s]Training:  12%|█▏        | 246/2000 [04:25<13:41,  2.14step/s]Training:  12%|█▏        | 247/2000 [04:26<13:40,  2.14step/s]Training:  12%|█▏        | 248/2000 [04:26<13:42,  2.13step/s]Training:  12%|█▏        | 249/2000 [04:27<13:41,  2.13step/s]Training:  12%|█▎        | 250/2000 [04:27<13:40,  2.13step/s]10:43:02 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.1296 lr=5.000e-04
10:43:02 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.1378 lr=5.000e-04
10:43:03 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.0955 lr=5.000e-04
10:43:03 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.1277 lr=5.000e-04
10:43:03 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.1260 lr=5.000e-04
10:43:03 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.1877 lr=5.000e-04
10:43:03 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.0735 lr=5.000e-04
10:43:03 - trainer.t5-dialogsum-lora-main - INFO - step=250 loss=0.1279 lr=5.000e-04
Training:  13%|█▎        | 251/2000 [04:28<13:39,  2.13step/s]Training:  13%|█▎        | 252/2000 [04:28<13:39,  2.13step/s]Training:  13%|█▎        | 253/2000 [04:29<13:38,  2.13step/s]Training:  13%|█▎        | 254/2000 [04:29<13:37,  2.13step/s]Training:  13%|█▎        | 255/2000 [04:30<13:37,  2.14step/s]Training:  13%|█▎        | 256/2000 [04:30<13:36,  2.14step/s]Training:  13%|█▎        | 257/2000 [04:31<13:36,  2.14step/s]Training:  13%|█▎        | 258/2000 [04:31<13:35,  2.14step/s]Training:  13%|█▎        | 259/2000 [04:31<13:34,  2.14step/s]Training:  13%|█▎        | 260/2000 [04:32<13:34,  2.14step/s]Training:  13%|█▎        | 261/2000 [04:32<13:34,  2.13step/s]Training:  13%|█▎        | 262/2000 [04:33<13:34,  2.13step/s]Training:  13%|█▎        | 263/2000 [04:33<13:33,  2.14step/s]Training:  13%|█▎        | 264/2000 [04:34<13:32,  2.14step/s]Training:  13%|█▎        | 265/2000 [04:34<13:32,  2.14step/s]Training:  13%|█▎        | 266/2000 [04:35<13:31,  2.14step/s]Training:  13%|█▎        | 267/2000 [04:35<13:31,  2.14step/s]Training:  13%|█▎        | 268/2000 [04:36<13:30,  2.14step/s]Training:  13%|█▎        | 269/2000 [04:36<13:30,  2.14step/s]Training:  14%|█▎        | 270/2000 [04:37<13:29,  2.14step/s]Training:  14%|█▎        | 271/2000 [04:37<13:29,  2.14step/s]Training:  14%|█▎        | 272/2000 [04:38<13:28,  2.14step/s]Training:  14%|█▎        | 273/2000 [04:38<13:28,  2.14step/s]Training:  14%|█▎        | 274/2000 [04:38<13:27,  2.14step/s]Training:  14%|█▍        | 275/2000 [04:39<13:27,  2.14step/s]Training:  14%|█▍        | 276/2000 [04:39<13:26,  2.14step/s]Training:  14%|█▍        | 277/2000 [04:40<13:26,  2.14step/s]Training:  14%|█▍        | 278/2000 [04:40<13:26,  2.14step/s]Training:  14%|█▍        | 279/2000 [04:41<13:25,  2.14step/s]Training:  14%|█▍        | 280/2000 [04:41<13:24,  2.14step/s]Training:  14%|█▍        | 281/2000 [04:42<13:24,  2.14step/s]Training:  14%|█▍        | 282/2000 [04:42<13:24,  2.14step/s]Training:  14%|█▍        | 283/2000 [04:43<13:23,  2.14step/s]Training:  14%|█▍        | 284/2000 [04:43<13:23,  2.14step/s]Training:  14%|█▍        | 285/2000 [04:44<13:22,  2.14step/s]Training:  14%|█▍        | 286/2000 [04:44<13:22,  2.14step/s]Training:  14%|█▍        | 287/2000 [04:45<13:21,  2.14step/s]Training:  14%|█▍        | 288/2000 [04:45<13:21,  2.14step/s]Training:  14%|█▍        | 289/2000 [04:46<13:20,  2.14step/s]Training:  14%|█▍        | 290/2000 [04:46<13:20,  2.14step/s]Training:  15%|█▍        | 291/2000 [04:46<13:19,  2.14step/s]Training:  15%|█▍        | 292/2000 [04:47<13:19,  2.14step/s]Training:  15%|█▍        | 293/2000 [04:47<13:18,  2.14step/s]Training:  15%|█▍        | 294/2000 [04:48<13:18,  2.14step/s]Training:  15%|█▍        | 295/2000 [04:48<13:17,  2.14step/s]Training:  15%|█▍        | 296/2000 [04:49<13:17,  2.14step/s]Training:  15%|█▍        | 297/2000 [04:49<13:17,  2.14step/s]Training:  15%|█▍        | 298/2000 [04:50<13:17,  2.14step/s]Training:  15%|█▍        | 299/2000 [04:50<13:16,  2.14step/s]Training:  15%|█▌        | 300/2000 [04:51<13:15,  2.14step/s]10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.0766 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.1093 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.1112 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.1105 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.1671 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.1480 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.1799 lr=5.000e-04
10:43:26 - trainer.t5-dialogsum-lora-main - INFO - step=300 loss=0.0915 lr=5.000e-04
Training:  15%|█▌        | 301/2000 [04:51<13:15,  2.14step/s]Training:  15%|█▌        | 302/2000 [04:52<13:14,  2.14step/s]Training:  15%|█▌        | 303/2000 [04:52<13:14,  2.14step/s]Training:  15%|█▌        | 304/2000 [04:53<13:13,  2.14step/s]Training:  15%|█▌        | 305/2000 [04:53<13:13,  2.14step/s]Training:  15%|█▌        | 306/2000 [04:53<13:12,  2.14step/s]Training:  15%|█▌        | 307/2000 [04:54<13:12,  2.14step/s]Training:  15%|█▌        | 308/2000 [04:54<13:11,  2.14step/s]Training:  15%|█▌        | 309/2000 [04:55<13:11,  2.14step/s]Training:  16%|█▌        | 310/2000 [04:55<13:11,  2.14step/s]Training:  16%|█▌        | 311/2000 [04:56<13:10,  2.14step/s]Training:  16%|█▌        | 312/2000 [04:56<13:10,  2.14step/s]Training:  16%|█▌        | 313/2000 [04:57<13:09,  2.14step/s]Training:  16%|█▌        | 314/2000 [04:57<13:09,  2.14step/s]Training:  16%|█▌        | 315/2000 [04:58<13:08,  2.14step/s]Training:  16%|█▌        | 316/2000 [04:58<13:08,  2.14step/s]Training:  16%|█▌        | 317/2000 [04:59<13:07,  2.14step/s]Training:  16%|█▌        | 318/2000 [04:59<13:07,  2.14step/s]Training:  16%|█▌        | 319/2000 [05:00<13:06,  2.14step/s]Training:  16%|█▌        | 320/2000 [05:00<13:06,  2.14step/s]Training:  16%|█▌        | 321/2000 [05:00<13:05,  2.14step/s]Training:  16%|█▌        | 322/2000 [05:01<13:05,  2.14step/s]Training:  16%|█▌        | 323/2000 [05:01<13:05,  2.14step/s]Training:  16%|█▌        | 324/2000 [05:02<13:04,  2.14step/s]Training:  16%|█▋        | 325/2000 [05:02<13:04,  2.14step/s]Training:  16%|█▋        | 326/2000 [05:03<13:03,  2.14step/s]Training:  16%|█▋        | 327/2000 [05:03<13:03,  2.14step/s]Training:  16%|█▋        | 328/2000 [05:04<13:02,  2.14step/s]Training:  16%|█▋        | 329/2000 [05:04<13:02,  2.14step/s]Training:  16%|█▋        | 330/2000 [05:05<13:01,  2.14step/s]Training:  17%|█▋        | 331/2000 [05:05<13:01,  2.14step/s]Training:  17%|█▋        | 332/2000 [05:06<13:00,  2.14step/s]Training:  17%|█▋        | 333/2000 [05:06<13:00,  2.14step/s]Training:  17%|█▋        | 334/2000 [05:07<12:59,  2.14step/s]Training:  17%|█▋        | 335/2000 [05:07<12:59,  2.14step/s]Training:  17%|█▋        | 336/2000 [05:08<12:58,  2.14step/s]Training:  17%|█▋        | 337/2000 [05:08<12:58,  2.14step/s]Training:  17%|█▋        | 338/2000 [05:08<12:57,  2.14step/s]Training:  17%|█▋        | 339/2000 [05:09<12:57,  2.14step/s]Training:  17%|█▋        | 340/2000 [05:09<12:56,  2.14step/s]Training:  17%|█▋        | 341/2000 [05:10<12:56,  2.14step/s]Training:  17%|█▋        | 342/2000 [05:10<12:55,  2.14step/s]Training:  17%|█▋        | 343/2000 [05:11<12:55,  2.14step/s]Training:  17%|█▋        | 344/2000 [05:11<12:55,  2.14step/s]Training:  17%|█▋        | 345/2000 [05:12<12:54,  2.14step/s]Training:  17%|█▋        | 346/2000 [05:12<12:54,  2.14step/s]Training:  17%|█▋        | 347/2000 [05:13<12:53,  2.14step/s]Training:  17%|█▋        | 348/2000 [05:13<12:53,  2.14step/s]Training:  17%|█▋        | 349/2000 [05:14<12:52,  2.14step/s]Training:  18%|█▊        | 350/2000 [05:14<12:52,  2.14step/s]10:43:49 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.1013 lr=5.000e-04
10:43:49 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.0866 lr=5.000e-04
10:43:49 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.1075 lr=5.000e-04
10:43:49 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.1309 lr=5.000e-04
10:43:49 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.1195 lr=5.000e-04
10:43:49 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.1302 lr=5.000e-04
10:43:50 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.0995 lr=5.000e-04
10:43:50 - trainer.t5-dialogsum-lora-main - INFO - step=350 loss=0.1417 lr=5.000e-04
Training:  18%|█▊        | 351/2000 [05:15<12:51,  2.14step/s]Training:  18%|█▊        | 352/2000 [05:15<12:51,  2.14step/s]Training:  18%|█▊        | 353/2000 [05:15<12:50,  2.14step/s]Training:  18%|█▊        | 354/2000 [05:16<12:50,  2.14step/s]Training:  18%|█▊        | 355/2000 [05:16<12:49,  2.14step/s]Training:  18%|█▊        | 356/2000 [05:17<12:49,  2.14step/s]Training:  18%|█▊        | 357/2000 [05:17<12:49,  2.14step/s]Training:  18%|█▊        | 358/2000 [05:18<12:49,  2.14step/s]Training:  18%|█▊        | 359/2000 [05:18<12:48,  2.14step/s]Training:  18%|█▊        | 360/2000 [05:19<12:47,  2.14step/s]Training:  18%|█▊        | 361/2000 [05:19<12:47,  2.14step/s]Training:  18%|█▊        | 362/2000 [05:20<12:46,  2.14step/s]Training:  18%|█▊        | 363/2000 [05:20<12:46,  2.14step/s]Training:  18%|█▊        | 364/2000 [05:21<12:45,  2.14step/s]Training:  18%|█▊        | 365/2000 [05:21<12:45,  2.14step/s]Training:  18%|█▊        | 366/2000 [05:22<12:44,  2.14step/s]Training:  18%|█▊        | 367/2000 [05:22<12:44,  2.14step/s]Training:  18%|█▊        | 368/2000 [05:22<12:43,  2.14step/s]Training:  18%|█▊        | 369/2000 [05:23<12:43,  2.14step/s]Training:  18%|█▊        | 370/2000 [05:23<12:42,  2.14step/s]Training:  19%|█▊        | 371/2000 [05:24<12:42,  2.14step/s]Training:  19%|█▊        | 372/2000 [05:24<12:41,  2.14step/s]Training:  19%|█▊        | 373/2000 [05:25<12:41,  2.14step/s]Training:  19%|█▊        | 374/2000 [05:25<12:41,  2.14step/s]Training:  19%|█▉        | 375/2000 [05:26<12:40,  2.14step/s]Training:  19%|█▉        | 376/2000 [05:26<12:40,  2.14step/s]Training:  19%|█▉        | 377/2000 [05:27<12:39,  2.14step/s]Training:  19%|█▉        | 378/2000 [05:27<12:38,  2.14step/s]Training:  19%|█▉        | 379/2000 [05:28<12:38,  2.14step/s]Training:  19%|█▉        | 380/2000 [05:28<12:38,  2.14step/s]Training:  19%|█▉        | 381/2000 [05:29<12:37,  2.14step/s]Training:  19%|█▉        | 382/2000 [05:29<12:37,  2.14step/s]Training:  19%|█▉        | 383/2000 [05:30<12:36,  2.14step/s]Training:  19%|█▉        | 384/2000 [05:30<12:36,  2.14step/s]Training:  19%|█▉        | 385/2000 [05:30<12:35,  2.14step/s]Training:  19%|█▉        | 386/2000 [05:31<12:35,  2.14step/s]Training:  19%|█▉        | 387/2000 [05:31<12:34,  2.14step/s]Training:  19%|█▉        | 388/2000 [05:32<12:34,  2.14step/s]Training:  19%|█▉        | 389/2000 [05:32<12:34,  2.14step/s]Training:  20%|█▉        | 390/2000 [05:33<12:35,  2.13step/s]Training:  20%|█▉        | 391/2000 [05:33<12:34,  2.13step/s]Training:  20%|█▉        | 392/2000 [05:34<12:33,  2.13step/s]Training:  20%|█▉        | 393/2000 [05:34<12:32,  2.14step/s]Training:  20%|█▉        | 394/2000 [05:35<12:31,  2.14step/s]Training:  20%|█▉        | 395/2000 [05:35<12:31,  2.14step/s]Training:  20%|█▉        | 396/2000 [05:36<12:30,  2.14step/s]Training:  20%|█▉        | 397/2000 [05:36<12:30,  2.14step/s]Training:  20%|█▉        | 398/2000 [05:37<12:29,  2.14step/s]Training:  20%|█▉        | 399/2000 [05:37<12:29,  2.14step/s]Training:  20%|██        | 400/2000 [05:37<12:28,  2.14step/s]10:44:13 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.2144 lr=5.000e-04
10:44:22 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:44:23 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1100 lr=5.000e-04
10:44:32 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:44:33 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1248 lr=5.000e-04
10:44:42 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:44:42 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1008 lr=5.000e-04
10:44:52 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:44:52 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1342 lr=5.000e-04
10:45:02 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:45:02 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1034 lr=5.000e-04
10:45:12 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:45:12 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1662 lr=5.000e-04
10:45:22 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
10:45:22 - trainer.t5-dialogsum-lora-main - INFO - step=400 loss=0.1326 lr=5.000e-04
10:45:32 - trainer.t5-dialogsum-lora-main - INFO - eval step=400 loss=0.8623 ppl=2.37
Training:  20%|██        | 401/2000 [06:57<10:45:38, 24.23s/step]Training:  20%|██        | 402/2000 [06:58<7:35:24, 17.10s/step] Training:  20%|██        | 403/2000 [06:58<5:22:19, 12.11s/step]Training:  20%|██        | 404/2000 [06:59<3:49:13,  8.62s/step]Training:  20%|██        | 405/2000 [06:59<2:44:05,  6.17s/step]Training:  20%|██        | 406/2000 [06:59<1:58:31,  4.46s/step]Training:  20%|██        | 407/2000 [07:00<1:26:38,  3.26s/step]Training:  20%|██        | 408/2000 [07:00<1:04:20,  2.42s/step]Training:  20%|██        | 409/2000 [07:01<48:44,  1.84s/step]  Training:  20%|██        | 410/2000 [07:01<37:49,  1.43s/step]Training:  21%|██        | 411/2000 [07:02<30:10,  1.14s/step]Training:  21%|██        | 412/2000 [07:02<24:49,  1.07step/s]Training:  21%|██        | 413/2000 [07:03<21:04,  1.25step/s]Training:  21%|██        | 414/2000 [07:03<18:27,  1.43step/s]Training:  21%|██        | 415/2000 [07:04<16:37,  1.59step/s]Training:  21%|██        | 416/2000 [07:04<15:20,  1.72step/s]Training:  21%|██        | 417/2000 [07:05<14:25,  1.83step/s]Training:  21%|██        | 418/2000 [07:05<13:47,  1.91step/s]Training:  21%|██        | 419/2000 [07:06<13:21,  1.97step/s]Training:  21%|██        | 420/2000 [07:06<13:02,  2.02step/s]Training:  21%|██        | 421/2000 [07:06<12:49,  2.05step/s]Training:  21%|██        | 422/2000 [07:07<12:39,  2.08step/s]Training:  21%|██        | 423/2000 [07:07<12:32,  2.10step/s]Training:  21%|██        | 424/2000 [07:08<12:27,  2.11step/s]Training:  21%|██▏       | 425/2000 [07:08<12:24,  2.12step/s]Training:  21%|██▏       | 426/2000 [07:09<12:21,  2.12step/s]Training:  21%|██▏       | 427/2000 [07:09<12:19,  2.13step/s]Training:  21%|██▏       | 428/2000 [07:10<12:18,  2.13step/s]Training:  21%|██▏       | 429/2000 [07:10<12:17,  2.13step/s]Training:  22%|██▏       | 430/2000 [07:11<12:16,  2.13step/s]Training:  22%|██▏       | 431/2000 [07:11<12:15,  2.13step/s]Training:  22%|██▏       | 432/2000 [07:12<12:14,  2.13step/s]Training:  22%|██▏       | 433/2000 [07:12<12:13,  2.13step/s]Training:  22%|██▏       | 434/2000 [07:13<12:13,  2.14step/s]Training:  22%|██▏       | 435/2000 [07:13<12:12,  2.14step/s]Training:  22%|██▏       | 436/2000 [07:14<12:12,  2.14step/s]Training:  22%|██▏       | 437/2000 [07:14<12:11,  2.14step/s]Training:  22%|██▏       | 438/2000 [07:14<12:11,  2.14step/s]Training:  22%|██▏       | 439/2000 [07:15<12:10,  2.14step/s]Training:  22%|██▏       | 440/2000 [07:15<12:10,  2.14step/s]Training:  22%|██▏       | 441/2000 [07:16<12:09,  2.14step/s]Training:  22%|██▏       | 442/2000 [07:16<12:09,  2.14step/s]Training:  22%|██▏       | 443/2000 [07:17<12:09,  2.13step/s]Training:  22%|██▏       | 444/2000 [07:17<12:08,  2.13step/s]Training:  22%|██▏       | 445/2000 [07:18<12:08,  2.13step/s]Training:  22%|██▏       | 446/2000 [07:18<12:07,  2.13step/s]Training:  22%|██▏       | 447/2000 [07:19<12:07,  2.14step/s]Training:  22%|██▏       | 448/2000 [07:19<12:06,  2.14step/s]Training:  22%|██▏       | 449/2000 [07:20<12:06,  2.14step/s]Training:  22%|██▎       | 450/2000 [07:20<12:05,  2.14step/s]10:45:55 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1299 lr=5.000e-04
10:45:55 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1239 lr=5.000e-04
10:45:55 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1089 lr=5.000e-04
10:45:55 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1015 lr=5.000e-04
10:45:55 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1331 lr=5.000e-04
10:45:55 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1033 lr=5.000e-04
10:45:56 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.1165 lr=5.000e-04
10:45:56 - trainer.t5-dialogsum-lora-main - INFO - step=450 loss=0.0962 lr=5.000e-04
Training:  23%|██▎       | 451/2000 [07:21<12:05,  2.14step/s]Training:  23%|██▎       | 452/2000 [07:21<12:04,  2.14step/s]Training:  23%|██▎       | 453/2000 [07:21<12:04,  2.14step/s]Training:  23%|██▎       | 454/2000 [07:22<12:03,  2.14step/s]Training:  23%|██▎       | 455/2000 [07:22<12:03,  2.14step/s]Training:  23%|██▎       | 456/2000 [07:23<12:02,  2.14step/s]Training:  23%|██▎       | 457/2000 [07:23<12:02,  2.14step/s]Training:  23%|██▎       | 458/2000 [07:24<12:01,  2.14step/s]Training:  23%|██▎       | 459/2000 [07:24<12:01,  2.14step/s]Training:  23%|██▎       | 460/2000 [07:25<12:00,  2.14step/s]Training:  23%|██▎       | 461/2000 [07:25<12:00,  2.14step/s]Training:  23%|██▎       | 462/2000 [07:26<11:59,  2.14step/s]Training:  23%|██▎       | 463/2000 [07:26<11:59,  2.14step/s]Training:  23%|██▎       | 464/2000 [07:27<11:59,  2.14step/s]Training:  23%|██▎       | 465/2000 [07:27<11:58,  2.14step/s]Training:  23%|██▎       | 466/2000 [07:28<11:58,  2.14step/s]Training:  23%|██▎       | 467/2000 [07:28<11:57,  2.14step/s]Training:  23%|██▎       | 468/2000 [07:28<11:57,  2.14step/s]Training:  23%|██▎       | 469/2000 [07:29<11:56,  2.14step/s]Training:  24%|██▎       | 470/2000 [07:29<11:56,  2.14step/s]Training:  24%|██▎       | 471/2000 [07:30<11:55,  2.14step/s]Training:  24%|██▎       | 472/2000 [07:30<11:55,  2.14step/s]Training:  24%|██▎       | 473/2000 [07:31<11:54,  2.14step/s]Training:  24%|██▎       | 474/2000 [07:31<11:54,  2.14step/s]Training:  24%|██▍       | 475/2000 [07:32<11:53,  2.14step/s]Training:  24%|██▍       | 476/2000 [07:32<11:53,  2.14step/s]Training:  24%|██▍       | 477/2000 [07:33<11:53,  2.13step/s]Training:  24%|██▍       | 478/2000 [07:33<11:52,  2.13step/s]Training:  24%|██▍       | 479/2000 [07:34<11:52,  2.14step/s]Training:  24%|██▍       | 480/2000 [07:34<11:51,  2.14step/s]Training:  24%|██▍       | 481/2000 [07:35<11:51,  2.14step/s]Training:  24%|██▍       | 482/2000 [07:35<11:50,  2.14step/s]Training:  24%|██▍       | 483/2000 [07:36<11:50,  2.14step/s]Training:  24%|██▍       | 484/2000 [07:36<11:49,  2.14step/s]Training:  24%|██▍       | 485/2000 [07:36<11:49,  2.14step/s]Training:  24%|██▍       | 486/2000 [07:37<11:48,  2.14step/s]Training:  24%|██▍       | 487/2000 [07:37<11:48,  2.14step/s]Training:  24%|██▍       | 488/2000 [07:38<11:47,  2.14step/s]Training:  24%|██▍       | 489/2000 [07:38<11:47,  2.14step/s]Training:  24%|██▍       | 490/2000 [07:39<11:47,  2.14step/s]Training:  25%|██▍       | 491/2000 [07:39<11:46,  2.14step/s]Training:  25%|██▍       | 492/2000 [07:40<11:45,  2.14step/s]Training:  25%|██▍       | 493/2000 [07:40<11:45,  2.14step/s]Training:  25%|██▍       | 494/2000 [07:41<11:44,  2.14step/s]Training:  25%|██▍       | 495/2000 [07:41<11:44,  2.14step/s]Training:  25%|██▍       | 496/2000 [07:42<11:43,  2.14step/s]Training:  25%|██▍       | 497/2000 [07:42<11:43,  2.14step/s]Training:  25%|██▍       | 498/2000 [07:43<11:43,  2.14step/s]Training:  25%|██▍       | 499/2000 [07:43<11:42,  2.14step/s]Training:  25%|██▌       | 500/2000 [07:43<11:42,  2.14step/s]10:46:19 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.0957 lr=5.000e-04
10:46:19 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.1283 lr=5.000e-04
10:46:19 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.1264 lr=5.000e-04
10:46:20 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.0970 lr=5.000e-04
10:46:20 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.0676 lr=5.000e-04
10:46:20 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.1272 lr=5.000e-04
10:46:21 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.0610 lr=5.000e-04
10:46:21 - trainer.t5-dialogsum-lora-main - INFO - step=500 loss=0.1253 lr=5.000e-04
Training:  25%|██▌       | 501/2000 [07:46<28:04,  1.12s/step]Training:  25%|██▌       | 502/2000 [07:47<23:10,  1.08step/s]Training:  25%|██▌       | 503/2000 [07:47<19:43,  1.27step/s]Training:  25%|██▌       | 504/2000 [07:48<17:17,  1.44step/s]Training:  25%|██▌       | 505/2000 [07:48<15:35,  1.60step/s]Training:  25%|██▌       | 506/2000 [07:48<14:24,  1.73step/s]Training:  25%|██▌       | 507/2000 [07:49<13:34,  1.83step/s]Training:  25%|██▌       | 508/2000 [07:49<12:59,  1.91step/s]Training:  25%|██▌       | 509/2000 [07:50<12:34,  1.98step/s]Training:  26%|██▌       | 510/2000 [07:50<12:16,  2.02step/s]Training:  26%|██▌       | 511/2000 [07:51<12:04,  2.05step/s]Training:  26%|██▌       | 512/2000 [07:51<11:55,  2.08step/s]Training:  26%|██▌       | 513/2000 [07:52<11:49,  2.10step/s]Training:  26%|██▌       | 514/2000 [07:52<11:44,  2.11step/s]Training:  26%|██▌       | 515/2000 [07:53<11:41,  2.12step/s]Training:  26%|██▌       | 516/2000 [07:53<11:39,  2.12step/s]Training:  26%|██▌       | 517/2000 [07:54<11:37,  2.13step/s]Training:  26%|██▌       | 518/2000 [07:54<11:35,  2.13step/s]Training:  26%|██▌       | 519/2000 [07:55<11:34,  2.13step/s]Training:  26%|██▌       | 520/2000 [07:55<11:33,  2.13step/s]Training:  26%|██▌       | 521/2000 [07:55<11:32,  2.13step/s]Training:  26%|██▌       | 522/2000 [07:56<11:32,  2.13step/s]Training:  26%|██▌       | 523/2000 [07:56<11:31,  2.14step/s]Training:  26%|██▌       | 524/2000 [07:57<11:31,  2.14step/s]Training:  26%|██▋       | 525/2000 [07:57<11:30,  2.14step/s]Training:  26%|██▋       | 526/2000 [07:58<11:30,  2.14step/s]Training:  26%|██▋       | 527/2000 [07:58<11:29,  2.14step/s]Training:  26%|██▋       | 528/2000 [07:59<11:29,  2.14step/s]Training:  26%|██▋       | 529/2000 [07:59<11:28,  2.14step/s]Training:  26%|██▋       | 530/2000 [08:00<11:28,  2.14step/s]Training:  27%|██▋       | 531/2000 [08:00<11:27,  2.14step/s]Training:  27%|██▋       | 532/2000 [08:01<11:27,  2.14step/s]Training:  27%|██▋       | 533/2000 [08:01<11:26,  2.14step/s]Training:  27%|██▋       | 534/2000 [08:02<11:26,  2.14step/s]Training:  27%|██▋       | 535/2000 [08:02<11:25,  2.14step/s]Training:  27%|██▋       | 536/2000 [08:03<11:25,  2.14step/s]Training:  27%|██▋       | 537/2000 [08:03<11:24,  2.14step/s]Training:  27%|██▋       | 538/2000 [08:03<11:24,  2.14step/s]Training:  27%|██▋       | 539/2000 [08:04<11:24,  2.14step/s]Training:  27%|██▋       | 540/2000 [08:04<11:23,  2.13step/s]Training:  27%|██▋       | 541/2000 [08:05<11:23,  2.14step/s]Training:  27%|██▋       | 542/2000 [08:05<11:22,  2.14step/s]Training:  27%|██▋       | 543/2000 [08:06<11:22,  2.14step/s]Training:  27%|██▋       | 544/2000 [08:06<11:21,  2.14step/s]Training:  27%|██▋       | 545/2000 [08:07<11:22,  2.13step/s]Training:  27%|██▋       | 546/2000 [08:07<11:21,  2.13step/s]Training:  27%|██▋       | 547/2000 [08:08<11:20,  2.14step/s]Training:  27%|██▋       | 548/2000 [08:08<11:19,  2.14step/s]Training:  27%|██▋       | 549/2000 [08:09<11:19,  2.14step/s]Training:  28%|██▊       | 550/2000 [08:09<11:18,  2.14step/s]10:46:44 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1500 lr=5.000e-04
10:46:44 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1098 lr=5.000e-04
10:46:44 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1335 lr=5.000e-04
10:46:44 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1708 lr=5.000e-04
10:46:44 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1959 lr=5.000e-04
10:46:44 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1094 lr=5.000e-04
10:46:45 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1215 lr=5.000e-04
10:46:45 - trainer.t5-dialogsum-lora-main - INFO - step=550 loss=0.1466 lr=5.000e-04
Training:  28%|██▊       | 551/2000 [08:10<11:18,  2.14step/s]Training:  28%|██▊       | 552/2000 [08:10<11:17,  2.14step/s]Training:  28%|██▊       | 553/2000 [08:10<11:17,  2.14step/s]Training:  28%|██▊       | 554/2000 [08:11<11:17,  2.14step/s]Training:  28%|██▊       | 555/2000 [08:11<11:16,  2.14step/s]Training:  28%|██▊       | 556/2000 [08:12<11:15,  2.14step/s]Training:  28%|██▊       | 557/2000 [08:12<11:15,  2.14step/s]Training:  28%|██▊       | 558/2000 [08:13<11:14,  2.14step/s]Training:  28%|██▊       | 559/2000 [08:13<11:14,  2.14step/s]Training:  28%|██▊       | 560/2000 [08:14<11:14,  2.14step/s]Training:  28%|██▊       | 561/2000 [08:14<11:13,  2.14step/s]Training:  28%|██▊       | 562/2000 [08:15<11:13,  2.14step/s]Training:  28%|██▊       | 563/2000 [08:15<11:12,  2.14step/s]Training:  28%|██▊       | 564/2000 [08:16<11:12,  2.14step/s]Training:  28%|██▊       | 565/2000 [08:16<11:11,  2.14step/s]Training:  28%|██▊       | 566/2000 [08:17<11:11,  2.14step/s]Training:  28%|██▊       | 567/2000 [08:17<11:11,  2.13step/s]Training:  28%|██▊       | 568/2000 [08:18<11:10,  2.13step/s]Training:  28%|██▊       | 569/2000 [08:18<11:10,  2.13step/s]Training:  28%|██▊       | 570/2000 [08:18<11:09,  2.14step/s]Training:  29%|██▊       | 571/2000 [08:19<11:09,  2.14step/s]Training:  29%|██▊       | 572/2000 [08:19<11:08,  2.14step/s]Training:  29%|██▊       | 573/2000 [08:20<11:07,  2.14step/s]Training:  29%|██▊       | 574/2000 [08:20<11:07,  2.14step/s]Training:  29%|██▉       | 575/2000 [08:21<11:06,  2.14step/s]Training:  29%|██▉       | 576/2000 [08:21<11:06,  2.14step/s]Training:  29%|██▉       | 577/2000 [08:22<11:05,  2.14step/s]Training:  29%|██▉       | 578/2000 [08:22<11:05,  2.14step/s]Training:  29%|██▉       | 579/2000 [08:23<11:05,  2.14step/s]Training:  29%|██▉       | 580/2000 [08:23<11:04,  2.14step/s]Training:  29%|██▉       | 581/2000 [08:24<11:04,  2.14step/s]Training:  29%|██▉       | 582/2000 [08:24<11:03,  2.14step/s]Training:  29%|██▉       | 583/2000 [08:25<11:03,  2.14step/s]Training:  29%|██▉       | 584/2000 [08:25<11:02,  2.14step/s]Training:  29%|██▉       | 585/2000 [08:25<11:02,  2.14step/s]Training:  29%|██▉       | 586/2000 [08:26<11:01,  2.14step/s]Training:  29%|██▉       | 587/2000 [08:26<11:01,  2.14step/s]Training:  29%|██▉       | 588/2000 [08:27<11:00,  2.14step/s]Training:  29%|██▉       | 589/2000 [08:27<11:00,  2.14step/s]Training:  30%|██▉       | 590/2000 [08:28<10:59,  2.14step/s]Training:  30%|██▉       | 591/2000 [08:28<10:59,  2.14step/s]Training:  30%|██▉       | 592/2000 [08:29<10:58,  2.14step/s]Training:  30%|██▉       | 593/2000 [08:29<10:58,  2.14step/s]Training:  30%|██▉       | 594/2000 [08:30<10:57,  2.14step/s]Training:  30%|██▉       | 595/2000 [08:30<10:57,  2.14step/s]Training:  30%|██▉       | 596/2000 [08:31<10:56,  2.14step/s]Training:  30%|██▉       | 597/2000 [08:31<10:56,  2.14step/s]Training:  30%|██▉       | 598/2000 [08:32<10:56,  2.14step/s]Training:  30%|██▉       | 599/2000 [08:32<10:55,  2.14step/s]Training:  30%|███       | 600/2000 [08:32<10:55,  2.14step/s]10:47:08 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.1257 lr=5.000e-04
10:47:18 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:47:18 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.0943 lr=5.000e-04
10:47:27 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:47:28 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.0746 lr=5.000e-04
10:47:37 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:47:37 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.0873 lr=5.000e-04
10:47:47 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:47:47 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.1029 lr=5.000e-04
10:47:57 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:47:57 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.1535 lr=5.000e-04
10:48:07 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:48:07 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.1750 lr=5.000e-04
10:48:17 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
10:48:17 - trainer.t5-dialogsum-lora-main - INFO - step=600 loss=0.1327 lr=5.000e-04
10:48:27 - trainer.t5-dialogsum-lora-main - INFO - eval step=600 loss=0.8379 ppl=2.31
Training:  30%|███       | 601/2000 [09:52<9:24:56, 24.23s/step]Training:  30%|███       | 602/2000 [09:53<6:38:26, 17.10s/step]Training:  30%|███       | 603/2000 [09:53<4:41:59, 12.11s/step]Training:  30%|███       | 604/2000 [09:54<3:20:30,  8.62s/step]Training:  30%|███       | 605/2000 [09:54<2:23:31,  6.17s/step]Training:  30%|███       | 606/2000 [09:54<1:43:39,  4.46s/step]Training:  30%|███       | 607/2000 [09:55<1:15:46,  3.26s/step]Training:  30%|███       | 608/2000 [09:55<56:15,  2.42s/step]  Training:  30%|███       | 609/2000 [09:56<42:36,  1.84s/step]Training:  30%|███       | 610/2000 [09:56<33:05,  1.43s/step]Training:  31%|███       | 611/2000 [09:57<26:23,  1.14s/step]Training:  31%|███       | 612/2000 [09:57<21:42,  1.07step/s]Training:  31%|███       | 613/2000 [09:58<18:26,  1.25step/s]Training:  31%|███       | 614/2000 [09:58<16:08,  1.43step/s]Training:  31%|███       | 615/2000 [09:59<14:31,  1.59step/s]Training:  31%|███       | 616/2000 [09:59<13:24,  1.72step/s]Training:  31%|███       | 617/2000 [10:00<12:37,  1.83step/s]Training:  31%|███       | 618/2000 [10:00<12:03,  1.91step/s]Training:  31%|███       | 619/2000 [10:01<11:40,  1.97step/s]Training:  31%|███       | 620/2000 [10:01<11:23,  2.02step/s]Training:  31%|███       | 621/2000 [10:02<11:11,  2.05step/s]Training:  31%|███       | 622/2000 [10:02<11:03,  2.08step/s]Training:  31%|███       | 623/2000 [10:02<10:57,  2.09step/s]Training:  31%|███       | 624/2000 [10:03<10:53,  2.11step/s]Training:  31%|███▏      | 625/2000 [10:03<10:49,  2.12step/s]Training:  31%|███▏      | 626/2000 [10:04<10:47,  2.12step/s]Training:  31%|███▏      | 627/2000 [10:04<10:45,  2.13step/s]Training:  31%|███▏      | 628/2000 [10:05<10:44,  2.13step/s]Training:  31%|███▏      | 629/2000 [10:05<10:43,  2.13step/s]Training:  32%|███▏      | 630/2000 [10:06<10:42,  2.13step/s]Training:  32%|███▏      | 631/2000 [10:06<10:41,  2.13step/s]Training:  32%|███▏      | 632/2000 [10:07<10:41,  2.13step/s]Training:  32%|███▏      | 633/2000 [10:07<10:40,  2.13step/s]Training:  32%|███▏      | 634/2000 [10:08<10:40,  2.13step/s]Training:  32%|███▏      | 635/2000 [10:08<10:39,  2.13step/s]Training:  32%|███▏      | 636/2000 [10:09<10:38,  2.14step/s]Training:  32%|███▏      | 637/2000 [10:09<10:38,  2.14step/s]Training:  32%|███▏      | 638/2000 [10:09<10:37,  2.14step/s]Training:  32%|███▏      | 639/2000 [10:10<10:37,  2.14step/s]Training:  32%|███▏      | 640/2000 [10:10<10:36,  2.14step/s]Training:  32%|███▏      | 641/2000 [10:11<10:36,  2.14step/s]Training:  32%|███▏      | 642/2000 [10:11<10:35,  2.14step/s]Training:  32%|███▏      | 643/2000 [10:12<10:35,  2.14step/s]Training:  32%|███▏      | 644/2000 [10:12<10:34,  2.14step/s]Training:  32%|███▏      | 645/2000 [10:13<10:34,  2.14step/s]Training:  32%|███▏      | 646/2000 [10:13<10:33,  2.14step/s]Training:  32%|███▏      | 647/2000 [10:14<10:33,  2.14step/s]Training:  32%|███▏      | 648/2000 [10:14<10:32,  2.14step/s]Training:  32%|███▏      | 649/2000 [10:15<10:32,  2.14step/s]Training:  32%|███▎      | 650/2000 [10:15<10:31,  2.14step/s]10:48:50 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.1320 lr=5.000e-04
10:48:50 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.0892 lr=5.000e-04
10:48:50 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.0957 lr=5.000e-04
10:48:50 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.1658 lr=5.000e-04
10:48:50 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.1339 lr=5.000e-04
10:48:51 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.1542 lr=5.000e-04
10:48:51 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.0915 lr=5.000e-04
10:48:51 - trainer.t5-dialogsum-lora-main - INFO - step=650 loss=0.0971 lr=5.000e-04
Training:  33%|███▎      | 651/2000 [10:16<10:31,  2.14step/s]Training:  33%|███▎      | 652/2000 [10:16<10:31,  2.14step/s]Training:  33%|███▎      | 653/2000 [10:16<10:30,  2.14step/s]Training:  33%|███▎      | 654/2000 [10:17<10:30,  2.14step/s]Training:  33%|███▎      | 655/2000 [10:17<10:29,  2.14step/s]Training:  33%|███▎      | 656/2000 [10:18<10:29,  2.13step/s]Training:  33%|███▎      | 657/2000 [10:18<10:29,  2.14step/s]Training:  33%|███▎      | 658/2000 [10:19<10:28,  2.14step/s]Training:  33%|███▎      | 659/2000 [10:19<10:28,  2.14step/s]Training:  33%|███▎      | 660/2000 [10:20<10:27,  2.14step/s]Training:  33%|███▎      | 661/2000 [10:20<10:26,  2.14step/s]Training:  33%|███▎      | 662/2000 [10:21<10:26,  2.14step/s]Training:  33%|███▎      | 663/2000 [10:21<10:25,  2.14step/s]Training:  33%|███▎      | 664/2000 [10:22<10:25,  2.14step/s]Training:  33%|███▎      | 665/2000 [10:22<10:24,  2.14step/s]Training:  33%|███▎      | 666/2000 [10:23<10:24,  2.14step/s]Training:  33%|███▎      | 667/2000 [10:23<10:23,  2.14step/s]Training:  33%|███▎      | 668/2000 [10:24<10:23,  2.14step/s]Training:  33%|███▎      | 669/2000 [10:24<10:22,  2.14step/s]Training:  34%|███▎      | 670/2000 [10:24<10:22,  2.14step/s]Training:  34%|███▎      | 671/2000 [10:25<10:22,  2.14step/s]Training:  34%|███▎      | 672/2000 [10:25<10:21,  2.14step/s]Training:  34%|███▎      | 673/2000 [10:26<10:21,  2.14step/s]Training:  34%|███▎      | 674/2000 [10:26<10:20,  2.14step/s]Training:  34%|███▍      | 675/2000 [10:27<10:20,  2.14step/s]Training:  34%|███▍      | 676/2000 [10:27<10:19,  2.14step/s]Training:  34%|███▍      | 677/2000 [10:28<10:19,  2.13step/s]Training:  34%|███▍      | 678/2000 [10:28<10:19,  2.14step/s]Training:  34%|███▍      | 679/2000 [10:29<10:18,  2.14step/s]Training:  34%|███▍      | 680/2000 [10:29<10:17,  2.14step/s]Training:  34%|███▍      | 681/2000 [10:30<10:17,  2.14step/s]Training:  34%|███▍      | 682/2000 [10:30<10:16,  2.14step/s]Training:  34%|███▍      | 683/2000 [10:31<10:16,  2.14step/s]Training:  34%|███▍      | 684/2000 [10:31<10:15,  2.14step/s]Training:  34%|███▍      | 685/2000 [10:31<10:15,  2.14step/s]Training:  34%|███▍      | 686/2000 [10:32<10:14,  2.14step/s]Training:  34%|███▍      | 687/2000 [10:32<10:14,  2.14step/s]Training:  34%|███▍      | 688/2000 [10:33<10:14,  2.14step/s]Training:  34%|███▍      | 689/2000 [10:33<10:13,  2.14step/s]Training:  34%|███▍      | 690/2000 [10:34<10:13,  2.14step/s]Training:  35%|███▍      | 691/2000 [10:34<10:12,  2.14step/s]Training:  35%|███▍      | 692/2000 [10:35<10:12,  2.14step/s]Training:  35%|███▍      | 693/2000 [10:35<10:11,  2.14step/s]Training:  35%|███▍      | 694/2000 [10:36<10:11,  2.14step/s]Training:  35%|███▍      | 695/2000 [10:36<10:10,  2.14step/s]Training:  35%|███▍      | 696/2000 [10:37<10:10,  2.14step/s]Training:  35%|███▍      | 697/2000 [10:37<10:09,  2.14step/s]Training:  35%|███▍      | 698/2000 [10:38<10:09,  2.14step/s]Training:  35%|███▍      | 699/2000 [10:38<10:08,  2.14step/s]Training:  35%|███▌      | 700/2000 [10:38<10:08,  2.14step/s]10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.1017 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.1197 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.1687 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.0986 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.1538 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.1223 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.1813 lr=5.000e-04
10:49:14 - trainer.t5-dialogsum-lora-main - INFO - step=700 loss=0.0918 lr=5.000e-04
Training:  35%|███▌      | 701/2000 [10:39<10:08,  2.14step/s]Training:  35%|███▌      | 702/2000 [10:39<10:07,  2.14step/s]Training:  35%|███▌      | 703/2000 [10:40<10:07,  2.14step/s]Training:  35%|███▌      | 704/2000 [10:40<10:06,  2.14step/s]Training:  35%|███▌      | 705/2000 [10:41<10:06,  2.14step/s]Training:  35%|███▌      | 706/2000 [10:41<10:05,  2.14step/s]Training:  35%|███▌      | 707/2000 [10:42<10:05,  2.14step/s]Training:  35%|███▌      | 708/2000 [10:42<10:04,  2.14step/s]Training:  35%|███▌      | 709/2000 [10:43<10:04,  2.14step/s]Training:  36%|███▌      | 710/2000 [10:43<10:03,  2.14step/s]Training:  36%|███▌      | 711/2000 [10:44<10:03,  2.14step/s]Training:  36%|███▌      | 712/2000 [10:44<10:02,  2.14step/s]Training:  36%|███▌      | 713/2000 [10:45<10:02,  2.14step/s]Training:  36%|███▌      | 714/2000 [10:45<10:01,  2.14step/s]Training:  36%|███▌      | 715/2000 [10:46<10:01,  2.14step/s]Training:  36%|███▌      | 716/2000 [10:46<10:01,  2.13step/s]Training:  36%|███▌      | 717/2000 [10:46<10:00,  2.14step/s]Training:  36%|███▌      | 718/2000 [10:47<10:00,  2.14step/s]Training:  36%|███▌      | 719/2000 [10:47<09:59,  2.14step/s]Training:  36%|███▌      | 720/2000 [10:48<09:59,  2.14step/s]Training:  36%|███▌      | 721/2000 [10:48<09:58,  2.14step/s]Training:  36%|███▌      | 722/2000 [10:49<09:58,  2.14step/s]Training:  36%|███▌      | 723/2000 [10:49<09:57,  2.14step/s]Training:  36%|███▌      | 724/2000 [10:50<09:57,  2.13step/s]Training:  36%|███▋      | 725/2000 [10:50<09:57,  2.13step/s]Training:  36%|███▋      | 726/2000 [10:51<09:57,  2.13step/s]Training:  36%|███▋      | 727/2000 [10:51<09:56,  2.13step/s]Training:  36%|███▋      | 728/2000 [10:52<09:55,  2.13step/s]Training:  36%|███▋      | 729/2000 [10:52<09:55,  2.13step/s]Training:  36%|███▋      | 730/2000 [10:53<09:54,  2.14step/s]Training:  37%|███▋      | 731/2000 [10:53<09:54,  2.14step/s]Training:  37%|███▋      | 732/2000 [10:53<09:53,  2.14step/s]Training:  37%|███▋      | 733/2000 [10:54<09:53,  2.14step/s]Training:  37%|███▋      | 734/2000 [10:54<09:52,  2.14step/s]Training:  37%|███▋      | 735/2000 [10:55<09:52,  2.14step/s]Training:  37%|███▋      | 736/2000 [10:55<09:51,  2.14step/s]Training:  37%|███▋      | 737/2000 [10:56<09:51,  2.13step/s]Training:  37%|███▋      | 738/2000 [10:56<09:51,  2.14step/s]Training:  37%|███▋      | 739/2000 [10:57<09:50,  2.14step/s]Training:  37%|███▋      | 740/2000 [10:57<09:49,  2.14step/s]Training:  37%|███▋      | 741/2000 [10:58<09:49,  2.14step/s]Training:  37%|███▋      | 742/2000 [10:58<09:48,  2.14step/s]Training:  37%|███▋      | 743/2000 [10:59<09:48,  2.14step/s]Training:  37%|███▋      | 744/2000 [10:59<09:47,  2.14step/s]Training:  37%|███▋      | 745/2000 [11:00<09:47,  2.14step/s]Training:  37%|███▋      | 746/2000 [11:00<09:46,  2.14step/s]Training:  37%|███▋      | 747/2000 [11:01<09:46,  2.14step/s]Training:  37%|███▋      | 748/2000 [11:01<09:46,  2.14step/s]Training:  37%|███▋      | 749/2000 [11:01<09:45,  2.14step/s]Training:  38%|███▊      | 750/2000 [11:02<09:45,  2.14step/s]10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.0883 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.0946 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.1173 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.1237 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.0946 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.0923 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.0919 lr=5.000e-04
10:49:37 - trainer.t5-dialogsum-lora-main - INFO - step=750 loss=0.1094 lr=5.000e-04
Training:  38%|███▊      | 751/2000 [11:02<09:44,  2.14step/s]Training:  38%|███▊      | 752/2000 [11:03<09:44,  2.14step/s]Training:  38%|███▊      | 753/2000 [11:03<09:43,  2.14step/s]Training:  38%|███▊      | 754/2000 [11:04<09:43,  2.14step/s]Training:  38%|███▊      | 755/2000 [11:04<09:42,  2.14step/s]Training:  38%|███▊      | 756/2000 [11:05<09:42,  2.14step/s]Training:  38%|███▊      | 757/2000 [11:05<09:41,  2.14step/s]Training:  38%|███▊      | 758/2000 [11:06<09:41,  2.14step/s]Training:  38%|███▊      | 759/2000 [11:06<09:40,  2.14step/s]Training:  38%|███▊      | 760/2000 [11:07<09:40,  2.14step/s]Training:  38%|███▊      | 761/2000 [11:07<09:39,  2.14step/s]Training:  38%|███▊      | 762/2000 [11:08<09:39,  2.14step/s]Training:  38%|███▊      | 763/2000 [11:08<09:39,  2.14step/s]Training:  38%|███▊      | 764/2000 [11:08<09:38,  2.14step/s]Training:  38%|███▊      | 765/2000 [11:09<09:38,  2.14step/s]Training:  38%|███▊      | 766/2000 [11:09<09:37,  2.14step/s]Training:  38%|███▊      | 767/2000 [11:10<09:37,  2.14step/s]Training:  38%|███▊      | 768/2000 [11:10<09:36,  2.14step/s]Training:  38%|███▊      | 769/2000 [11:11<09:36,  2.14step/s]Training:  38%|███▊      | 770/2000 [11:11<09:35,  2.14step/s]Training:  39%|███▊      | 771/2000 [11:12<09:35,  2.14step/s]Training:  39%|███▊      | 772/2000 [11:12<09:34,  2.14step/s]Training:  39%|███▊      | 773/2000 [11:13<09:34,  2.14step/s]Training:  39%|███▊      | 774/2000 [11:13<09:33,  2.14step/s]Training:  39%|███▉      | 775/2000 [11:14<09:33,  2.14step/s]Training:  39%|███▉      | 776/2000 [11:14<09:32,  2.14step/s]Training:  39%|███▉      | 777/2000 [11:15<09:32,  2.14step/s]Training:  39%|███▉      | 778/2000 [11:15<09:31,  2.14step/s]Training:  39%|███▉      | 779/2000 [11:15<09:31,  2.14step/s]Training:  39%|███▉      | 780/2000 [11:16<09:31,  2.14step/s]Training:  39%|███▉      | 781/2000 [11:16<09:30,  2.14step/s]Training:  39%|███▉      | 782/2000 [11:17<09:30,  2.14step/s]Training:  39%|███▉      | 783/2000 [11:17<09:29,  2.14step/s]Training:  39%|███▉      | 784/2000 [11:18<09:29,  2.14step/s]Training:  39%|███▉      | 785/2000 [11:18<09:28,  2.14step/s]Training:  39%|███▉      | 786/2000 [11:19<09:28,  2.14step/s]Training:  39%|███▉      | 787/2000 [11:19<09:27,  2.14step/s]Training:  39%|███▉      | 788/2000 [11:20<09:27,  2.14step/s]Training:  39%|███▉      | 789/2000 [11:20<09:26,  2.14step/s]Training:  40%|███▉      | 790/2000 [11:21<09:26,  2.14step/s]Training:  40%|███▉      | 791/2000 [11:21<09:25,  2.14step/s]Training:  40%|███▉      | 792/2000 [11:22<09:25,  2.14step/s]Training:  40%|███▉      | 793/2000 [11:22<09:24,  2.14step/s]Training:  40%|███▉      | 794/2000 [11:23<09:24,  2.14step/s]Training:  40%|███▉      | 795/2000 [11:23<09:23,  2.14step/s]Training:  40%|███▉      | 796/2000 [11:23<09:23,  2.14step/s]Training:  40%|███▉      | 797/2000 [11:24<09:23,  2.14step/s]Training:  40%|███▉      | 798/2000 [11:24<09:23,  2.13step/s]Training:  40%|███▉      | 799/2000 [11:25<09:22,  2.13step/s]Training:  40%|████      | 800/2000 [11:25<09:22,  2.13step/s]10:50:00 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.1170 lr=5.000e-04
10:50:10 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:50:10 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.1703 lr=5.000e-04
10:50:20 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:50:20 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.1518 lr=5.000e-04
10:50:30 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:50:30 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.1394 lr=5.000e-04
10:50:40 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:50:40 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.0827 lr=5.000e-04
10:50:50 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:50:50 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.1403 lr=5.000e-04
10:51:00 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:51:00 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.2067 lr=5.000e-04
10:51:10 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
10:51:10 - trainer.t5-dialogsum-lora-main - INFO - step=800 loss=0.1291 lr=5.000e-04
10:51:20 - trainer.t5-dialogsum-lora-main - INFO - eval step=800 loss=0.8343 ppl=2.30
Training:  40%|████      | 801/2000 [12:45<8:04:09, 24.23s/step]Training:  40%|████      | 802/2000 [12:45<5:41:26, 17.10s/step]Training:  40%|████      | 803/2000 [12:46<4:01:36, 12.11s/step]Training:  40%|████      | 804/2000 [12:46<2:51:46,  8.62s/step]Training:  40%|████      | 805/2000 [12:47<2:02:56,  6.17s/step]Training:  40%|████      | 806/2000 [12:47<1:28:46,  4.46s/step]Training:  40%|████      | 807/2000 [12:48<1:04:53,  3.26s/step]Training:  40%|████      | 808/2000 [12:48<48:10,  2.43s/step]  Training:  40%|████      | 809/2000 [12:49<36:28,  1.84s/step]Training:  40%|████      | 810/2000 [12:49<28:18,  1.43s/step]Training:  41%|████      | 811/2000 [12:50<22:34,  1.14s/step]Training:  41%|████      | 812/2000 [12:50<18:34,  1.07step/s]Training:  41%|████      | 813/2000 [12:51<15:46,  1.25step/s]Training:  41%|████      | 814/2000 [12:51<13:48,  1.43step/s]Training:  41%|████      | 815/2000 [12:52<12:25,  1.59step/s]Training:  41%|████      | 816/2000 [12:52<11:27,  1.72step/s]Training:  41%|████      | 817/2000 [12:52<10:47,  1.83step/s]Training:  41%|████      | 818/2000 [12:53<10:18,  1.91step/s]Training:  41%|████      | 819/2000 [12:53<09:58,  1.97step/s]Training:  41%|████      | 820/2000 [12:54<09:44,  2.02step/s]Training:  41%|████      | 821/2000 [12:54<09:34,  2.05step/s]Training:  41%|████      | 822/2000 [12:55<09:27,  2.08step/s]Training:  41%|████      | 823/2000 [12:55<09:21,  2.09step/s]Training:  41%|████      | 824/2000 [12:56<09:18,  2.11step/s]Training:  41%|████▏     | 825/2000 [12:56<09:15,  2.12step/s]Training:  41%|████▏     | 826/2000 [12:57<09:13,  2.12step/s]Training:  41%|████▏     | 827/2000 [12:57<09:11,  2.13step/s]Training:  41%|████▏     | 828/2000 [12:58<09:10,  2.13step/s]Training:  41%|████▏     | 829/2000 [12:58<09:09,  2.13step/s]Training:  42%|████▏     | 830/2000 [12:59<09:08,  2.13step/s]Training:  42%|████▏     | 831/2000 [12:59<09:08,  2.13step/s]Training:  42%|████▏     | 832/2000 [12:59<09:07,  2.13step/s]Training:  42%|████▏     | 833/2000 [13:00<09:06,  2.13step/s]Training:  42%|████▏     | 834/2000 [13:00<09:06,  2.13step/s]Training:  42%|████▏     | 835/2000 [13:01<09:05,  2.13step/s]Training:  42%|████▏     | 836/2000 [13:01<09:05,  2.13step/s]Training:  42%|████▏     | 837/2000 [13:02<09:04,  2.13step/s]Training:  42%|████▏     | 838/2000 [13:02<09:04,  2.13step/s]Training:  42%|████▏     | 839/2000 [13:03<09:03,  2.14step/s]Training:  42%|████▏     | 840/2000 [13:03<09:03,  2.13step/s]Training:  42%|████▏     | 841/2000 [13:04<09:02,  2.14step/s]Training:  42%|████▏     | 842/2000 [13:04<09:02,  2.14step/s]Training:  42%|████▏     | 843/2000 [13:05<09:01,  2.14step/s]Training:  42%|████▏     | 844/2000 [13:05<09:01,  2.14step/s]Training:  42%|████▏     | 845/2000 [13:06<09:00,  2.14step/s]Training:  42%|████▏     | 846/2000 [13:06<09:00,  2.14step/s]Training:  42%|████▏     | 847/2000 [13:07<08:59,  2.14step/s]Training:  42%|████▏     | 848/2000 [13:07<08:59,  2.14step/s]Training:  42%|████▏     | 849/2000 [13:07<08:58,  2.14step/s]Training:  42%|████▎     | 850/2000 [13:08<08:58,  2.14step/s]10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.1207 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.0931 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.1309 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.1028 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.1289 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.1003 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.0977 lr=5.000e-04
10:51:43 - trainer.t5-dialogsum-lora-main - INFO - step=850 loss=0.1637 lr=5.000e-04
Training:  43%|████▎     | 851/2000 [13:08<08:57,  2.14step/s]Training:  43%|████▎     | 852/2000 [13:09<08:57,  2.14step/s]Training:  43%|████▎     | 853/2000 [13:09<08:56,  2.14step/s]Training:  43%|████▎     | 854/2000 [13:10<08:56,  2.14step/s]Training:  43%|████▎     | 855/2000 [13:10<08:55,  2.14step/s]Training:  43%|████▎     | 856/2000 [13:11<08:55,  2.14step/s]Training:  43%|████▎     | 857/2000 [13:11<08:55,  2.14step/s]Training:  43%|████▎     | 858/2000 [13:12<08:54,  2.14step/s]Training:  43%|████▎     | 859/2000 [13:12<08:54,  2.14step/s]Training:  43%|████▎     | 860/2000 [13:13<08:53,  2.14step/s]Training:  43%|████▎     | 861/2000 [13:13<08:53,  2.14step/s]Training:  43%|████▎     | 862/2000 [13:14<08:52,  2.14step/s]Training:  43%|████▎     | 863/2000 [13:14<08:52,  2.14step/s]Training:  43%|████▎     | 864/2000 [13:14<08:51,  2.14step/s]Training:  43%|████▎     | 865/2000 [13:15<08:51,  2.14step/s]Training:  43%|████▎     | 866/2000 [13:15<08:50,  2.14step/s]Training:  43%|████▎     | 867/2000 [13:16<08:50,  2.14step/s]Training:  43%|████▎     | 868/2000 [13:16<08:49,  2.14step/s]Training:  43%|████▎     | 869/2000 [13:17<08:49,  2.14step/s]Training:  44%|████▎     | 870/2000 [13:17<08:49,  2.14step/s]Training:  44%|████▎     | 871/2000 [13:18<08:48,  2.14step/s]Training:  44%|████▎     | 872/2000 [13:18<08:48,  2.14step/s]Training:  44%|████▎     | 873/2000 [13:19<08:47,  2.14step/s]Training:  44%|████▎     | 874/2000 [13:19<08:47,  2.14step/s]Training:  44%|████▍     | 875/2000 [13:20<08:46,  2.14step/s]Training:  44%|████▍     | 876/2000 [13:20<08:46,  2.14step/s]Training:  44%|████▍     | 877/2000 [13:21<08:45,  2.14step/s]Training:  44%|████▍     | 878/2000 [13:21<08:45,  2.14step/s]Training:  44%|████▍     | 879/2000 [13:21<08:44,  2.14step/s]Training:  44%|████▍     | 880/2000 [13:22<08:44,  2.14step/s]Training:  44%|████▍     | 881/2000 [13:22<08:43,  2.14step/s]Training:  44%|████▍     | 882/2000 [13:23<08:43,  2.14step/s]Training:  44%|████▍     | 883/2000 [13:23<08:42,  2.14step/s]Training:  44%|████▍     | 884/2000 [13:24<08:42,  2.14step/s]Training:  44%|████▍     | 885/2000 [13:24<08:41,  2.14step/s]Training:  44%|████▍     | 886/2000 [13:25<08:41,  2.14step/s]Training:  44%|████▍     | 887/2000 [13:25<08:41,  2.14step/s]Training:  44%|████▍     | 888/2000 [13:26<08:40,  2.14step/s]Training:  44%|████▍     | 889/2000 [13:26<08:40,  2.14step/s]Training:  44%|████▍     | 890/2000 [13:27<08:39,  2.14step/s]Training:  45%|████▍     | 891/2000 [13:27<08:39,  2.14step/s]Training:  45%|████▍     | 892/2000 [13:28<08:38,  2.14step/s]Training:  45%|████▍     | 893/2000 [13:28<08:38,  2.14step/s]Training:  45%|████▍     | 894/2000 [13:29<08:37,  2.14step/s]Training:  45%|████▍     | 895/2000 [13:29<08:37,  2.14step/s]Training:  45%|████▍     | 896/2000 [13:29<08:36,  2.14step/s]Training:  45%|████▍     | 897/2000 [13:30<08:36,  2.14step/s]Training:  45%|████▍     | 898/2000 [13:30<08:35,  2.14step/s]Training:  45%|████▍     | 899/2000 [13:31<08:35,  2.13step/s]Training:  45%|████▌     | 900/2000 [13:31<08:35,  2.14step/s]10:52:06 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.0887 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.0755 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.1272 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.1852 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.0904 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.0960 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.1258 lr=5.000e-04
10:52:07 - trainer.t5-dialogsum-lora-main - INFO - step=900 loss=0.0730 lr=5.000e-04
Training:  45%|████▌     | 901/2000 [13:32<08:34,  2.14step/s]Training:  45%|████▌     | 902/2000 [13:32<08:34,  2.14step/s]Training:  45%|████▌     | 903/2000 [13:33<08:34,  2.13step/s]Training:  45%|████▌     | 904/2000 [13:33<08:33,  2.13step/s]Training:  45%|████▌     | 905/2000 [13:34<08:32,  2.13step/s]Training:  45%|████▌     | 906/2000 [13:34<08:32,  2.14step/s]Training:  45%|████▌     | 907/2000 [13:35<08:31,  2.14step/s]Training:  45%|████▌     | 908/2000 [13:35<08:31,  2.14step/s]Training:  45%|████▌     | 909/2000 [13:36<08:30,  2.14step/s]Training:  46%|████▌     | 910/2000 [13:36<08:30,  2.14step/s]Training:  46%|████▌     | 911/2000 [13:36<08:29,  2.14step/s]Training:  46%|████▌     | 912/2000 [13:37<08:29,  2.14step/s]Training:  46%|████▌     | 913/2000 [13:37<08:28,  2.14step/s]Training:  46%|████▌     | 914/2000 [13:38<08:28,  2.14step/s]Training:  46%|████▌     | 915/2000 [13:38<08:27,  2.14step/s]Training:  46%|████▌     | 916/2000 [13:39<08:27,  2.14step/s]Training:  46%|████▌     | 917/2000 [13:39<08:26,  2.14step/s]Training:  46%|████▌     | 918/2000 [13:40<08:26,  2.14step/s]Training:  46%|████▌     | 919/2000 [13:40<08:25,  2.14step/s]Training:  46%|████▌     | 920/2000 [13:41<08:25,  2.14step/s]Training:  46%|████▌     | 921/2000 [13:41<08:25,  2.14step/s]Training:  46%|████▌     | 922/2000 [13:42<08:24,  2.14step/s]Training:  46%|████▌     | 923/2000 [13:42<08:23,  2.14step/s]Training:  46%|████▌     | 924/2000 [13:43<08:23,  2.14step/s]Training:  46%|████▋     | 925/2000 [13:43<08:23,  2.14step/s]Training:  46%|████▋     | 926/2000 [13:43<08:22,  2.14step/s]Training:  46%|████▋     | 927/2000 [13:44<08:22,  2.14step/s]Training:  46%|████▋     | 928/2000 [13:44<08:21,  2.14step/s]Training:  46%|████▋     | 929/2000 [13:45<08:21,  2.13step/s]Training:  46%|████▋     | 930/2000 [13:45<08:21,  2.14step/s]Training:  47%|████▋     | 931/2000 [13:46<08:20,  2.14step/s]Training:  47%|████▋     | 932/2000 [13:46<08:20,  2.14step/s]Training:  47%|████▋     | 933/2000 [13:47<08:19,  2.14step/s]Training:  47%|████▋     | 934/2000 [13:47<08:18,  2.14step/s]Training:  47%|████▋     | 935/2000 [13:48<08:18,  2.14step/s]Training:  47%|████▋     | 936/2000 [13:48<08:17,  2.14step/s]Training:  47%|████▋     | 937/2000 [13:49<08:17,  2.14step/s]Training:  47%|████▋     | 938/2000 [13:49<08:17,  2.14step/s]Training:  47%|████▋     | 939/2000 [13:50<08:16,  2.14step/s]Training:  47%|████▋     | 940/2000 [13:50<08:16,  2.14step/s]Training:  47%|████▋     | 941/2000 [13:51<08:15,  2.14step/s]Training:  47%|████▋     | 942/2000 [13:51<08:15,  2.14step/s]Training:  47%|████▋     | 943/2000 [13:51<08:14,  2.14step/s]Training:  47%|████▋     | 944/2000 [13:52<08:14,  2.14step/s]Training:  47%|████▋     | 945/2000 [13:52<08:13,  2.14step/s]Training:  47%|████▋     | 946/2000 [13:53<08:13,  2.14step/s]Training:  47%|████▋     | 947/2000 [13:53<08:12,  2.14step/s]Training:  47%|████▋     | 948/2000 [13:54<08:12,  2.14step/s]Training:  47%|████▋     | 949/2000 [13:54<08:11,  2.14step/s]Training:  48%|████▊     | 950/2000 [13:55<08:11,  2.14step/s]10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.1842 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.1011 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.1066 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.0620 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.1593 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.0710 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.1097 lr=5.000e-04
10:52:30 - trainer.t5-dialogsum-lora-main - INFO - step=950 loss=0.1201 lr=5.000e-04
Training:  48%|████▊     | 951/2000 [13:55<08:11,  2.14step/s]Training:  48%|████▊     | 952/2000 [13:56<08:10,  2.14step/s]Training:  48%|████▊     | 953/2000 [13:56<08:10,  2.14step/s]Training:  48%|████▊     | 954/2000 [13:57<08:09,  2.14step/s]Training:  48%|████▊     | 955/2000 [13:57<08:09,  2.14step/s]Training:  48%|████▊     | 956/2000 [13:58<08:08,  2.14step/s]Training:  48%|████▊     | 957/2000 [13:58<08:08,  2.14step/s]Training:  48%|████▊     | 958/2000 [13:58<08:07,  2.14step/s]Training:  48%|████▊     | 959/2000 [13:59<08:07,  2.14step/s]Training:  48%|████▊     | 960/2000 [13:59<08:06,  2.14step/s]Training:  48%|████▊     | 961/2000 [14:00<08:06,  2.14step/s]Training:  48%|████▊     | 962/2000 [14:00<08:05,  2.14step/s]Training:  48%|████▊     | 963/2000 [14:01<08:05,  2.14step/s]Training:  48%|████▊     | 964/2000 [14:01<08:05,  2.14step/s]Training:  48%|████▊     | 965/2000 [14:02<08:04,  2.14step/s]Training:  48%|████▊     | 966/2000 [14:02<08:04,  2.14step/s]Training:  48%|████▊     | 967/2000 [14:03<08:03,  2.14step/s]Training:  48%|████▊     | 968/2000 [14:03<08:03,  2.13step/s]Training:  48%|████▊     | 969/2000 [14:04<08:02,  2.14step/s]Training:  48%|████▊     | 970/2000 [14:04<08:02,  2.14step/s]Training:  49%|████▊     | 971/2000 [14:05<08:01,  2.14step/s]Training:  49%|████▊     | 972/2000 [14:05<08:01,  2.14step/s]Training:  49%|████▊     | 973/2000 [14:05<08:00,  2.14step/s]Training:  49%|████▊     | 974/2000 [14:06<08:00,  2.14step/s]Training:  49%|████▉     | 975/2000 [14:06<07:59,  2.14step/s]Training:  49%|████▉     | 976/2000 [14:07<07:59,  2.14step/s]Training:  49%|████▉     | 977/2000 [14:07<07:58,  2.14step/s]Training:  49%|████▉     | 978/2000 [14:08<07:58,  2.14step/s]Training:  49%|████▉     | 979/2000 [14:08<07:57,  2.14step/s]Training:  49%|████▉     | 980/2000 [14:09<07:57,  2.14step/s]Training:  49%|████▉     | 981/2000 [14:09<07:56,  2.14step/s]Training:  49%|████▉     | 982/2000 [14:10<07:56,  2.14step/s]Training:  49%|████▉     | 983/2000 [14:10<07:55,  2.14step/s]Training:  49%|████▉     | 984/2000 [14:11<07:55,  2.14step/s]Training:  49%|████▉     | 985/2000 [14:11<07:55,  2.14step/s]Training:  49%|████▉     | 986/2000 [14:12<07:54,  2.14step/s]Training:  49%|████▉     | 987/2000 [14:12<07:54,  2.14step/s]Training:  49%|████▉     | 988/2000 [14:13<07:53,  2.14step/s]Training:  49%|████▉     | 989/2000 [14:13<07:53,  2.13step/s]Training:  50%|████▉     | 990/2000 [14:13<07:52,  2.14step/s]Training:  50%|████▉     | 991/2000 [14:14<07:52,  2.14step/s]Training:  50%|████▉     | 992/2000 [14:14<07:51,  2.14step/s]Training:  50%|████▉     | 993/2000 [14:15<07:51,  2.14step/s]Training:  50%|████▉     | 994/2000 [14:15<07:50,  2.14step/s]Training:  50%|████▉     | 995/2000 [14:16<07:50,  2.14step/s]Training:  50%|████▉     | 996/2000 [14:16<07:49,  2.14step/s]Training:  50%|████▉     | 997/2000 [14:17<07:49,  2.14step/s]Training:  50%|████▉     | 998/2000 [14:17<07:48,  2.14step/s]Training:  50%|████▉     | 999/2000 [14:18<07:48,  2.14step/s]Training:  50%|█████     | 1000/2000 [14:18<07:47,  2.14step/s]10:52:53 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.1113 lr=5.000e-04
10:53:03 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:53:03 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.0996 lr=5.000e-04
10:53:13 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:53:14 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.0974 lr=5.000e-04
10:53:24 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:53:24 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.1325 lr=5.000e-04
10:53:34 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:53:34 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.1345 lr=5.000e-04
10:53:44 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:53:44 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.1376 lr=5.000e-04
10:53:54 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:53:55 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.0888 lr=5.000e-04
10:54:04 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
10:54:05 - trainer.t5-dialogsum-lora-main - INFO - step=1000 loss=0.0770 lr=5.000e-04
10:54:15 - trainer.t5-dialogsum-lora-main - INFO - eval step=1000 loss=0.8186 ppl=2.27
Training:  50%|█████     | 1001/2000 [15:40<6:54:10, 24.88s/step]Training:  50%|█████     | 1002/2000 [15:40<4:51:58, 17.55s/step]Training:  50%|█████     | 1003/2000 [15:41<3:26:30, 12.43s/step]Training:  50%|█████     | 1004/2000 [15:41<2:26:44,  8.84s/step]Training:  50%|█████     | 1005/2000 [15:42<1:44:56,  6.33s/step]Training:  50%|█████     | 1006/2000 [15:42<1:15:42,  4.57s/step]Training:  50%|█████     | 1007/2000 [15:43<55:16,  3.34s/step]  Training:  50%|█████     | 1008/2000 [15:43<40:58,  2.48s/step]Training:  50%|█████     | 1009/2000 [15:44<30:58,  1.88s/step]Training:  50%|█████     | 1010/2000 [15:44<23:58,  1.45s/step]Training:  51%|█████     | 1011/2000 [15:45<19:04,  1.16s/step]Training:  51%|█████     | 1012/2000 [15:45<15:39,  1.05step/s]Training:  51%|█████     | 1013/2000 [15:46<13:15,  1.24step/s]Training:  51%|█████     | 1014/2000 [15:46<11:34,  1.42step/s]Training:  51%|█████     | 1015/2000 [15:47<10:24,  1.58step/s]Training:  51%|█████     | 1016/2000 [15:47<09:34,  1.71step/s]Training:  51%|█████     | 1017/2000 [15:47<09:00,  1.82step/s]Training:  51%|█████     | 1018/2000 [15:48<08:35,  1.90step/s]Training:  51%|█████     | 1019/2000 [15:48<08:18,  1.97step/s]Training:  51%|█████     | 1020/2000 [15:49<08:06,  2.02step/s]Training:  51%|█████     | 1021/2000 [15:49<07:57,  2.05step/s]Training:  51%|█████     | 1022/2000 [15:50<07:51,  2.08step/s]Training:  51%|█████     | 1023/2000 [15:50<07:46,  2.09step/s]Training:  51%|█████     | 1024/2000 [15:51<07:43,  2.11step/s]Training:  51%|█████▏    | 1025/2000 [15:51<07:40,  2.12step/s]Training:  51%|█████▏    | 1026/2000 [15:52<07:39,  2.12step/s]Training:  51%|█████▏    | 1027/2000 [15:52<07:37,  2.13step/s]Training:  51%|█████▏    | 1028/2000 [15:53<07:36,  2.13step/s]Training:  51%|█████▏    | 1029/2000 [15:53<07:35,  2.13step/s]Training:  52%|█████▏    | 1030/2000 [15:54<07:34,  2.13step/s]Training:  52%|█████▏    | 1031/2000 [15:54<07:34,  2.13step/s]Training:  52%|█████▏    | 1032/2000 [15:54<07:33,  2.13step/s]Training:  52%|█████▏    | 1033/2000 [15:55<07:32,  2.14step/s]Training:  52%|█████▏    | 1034/2000 [15:55<07:32,  2.14step/s]Training:  52%|█████▏    | 1035/2000 [15:56<07:31,  2.14step/s]Training:  52%|█████▏    | 1036/2000 [15:56<07:31,  2.13step/s]Training:  52%|█████▏    | 1037/2000 [15:57<07:30,  2.14step/s]Training:  52%|█████▏    | 1038/2000 [15:57<07:30,  2.14step/s]Training:  52%|█████▏    | 1039/2000 [15:58<07:29,  2.14step/s]Training:  52%|█████▏    | 1040/2000 [15:58<07:29,  2.14step/s]Training:  52%|█████▏    | 1041/2000 [15:59<07:28,  2.14step/s]Training:  52%|█████▏    | 1042/2000 [15:59<07:28,  2.14step/s]Training:  52%|█████▏    | 1043/2000 [16:00<07:27,  2.14step/s]Training:  52%|█████▏    | 1044/2000 [16:00<07:27,  2.14step/s]Training:  52%|█████▏    | 1045/2000 [16:01<07:26,  2.14step/s]Training:  52%|█████▏    | 1046/2000 [16:01<07:26,  2.14step/s]Training:  52%|█████▏    | 1047/2000 [16:01<07:26,  2.14step/s]Training:  52%|█████▏    | 1048/2000 [16:02<07:25,  2.14step/s]Training:  52%|█████▏    | 1049/2000 [16:02<07:25,  2.14step/s]Training:  52%|█████▎    | 1050/2000 [16:03<07:24,  2.14step/s]10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1204 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1225 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1153 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1245 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1129 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1112 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1098 lr=5.000e-04
10:54:38 - trainer.t5-dialogsum-lora-main - INFO - step=1050 loss=0.1109 lr=5.000e-04
Training:  53%|█████▎    | 1051/2000 [16:03<07:24,  2.14step/s]Training:  53%|█████▎    | 1052/2000 [16:04<07:23,  2.14step/s]Training:  53%|█████▎    | 1053/2000 [16:04<07:23,  2.14step/s]Training:  53%|█████▎    | 1054/2000 [16:05<07:22,  2.14step/s]Training:  53%|█████▎    | 1055/2000 [16:05<07:22,  2.14step/s]Training:  53%|█████▎    | 1056/2000 [16:06<07:22,  2.13step/s]Training:  53%|█████▎    | 1057/2000 [16:06<07:21,  2.14step/s]Training:  53%|█████▎    | 1058/2000 [16:07<07:21,  2.14step/s]Training:  53%|█████▎    | 1059/2000 [16:07<07:20,  2.14step/s]Training:  53%|█████▎    | 1060/2000 [16:08<07:20,  2.14step/s]Training:  53%|█████▎    | 1061/2000 [16:08<07:19,  2.14step/s]Training:  53%|█████▎    | 1062/2000 [16:09<07:19,  2.14step/s]Training:  53%|█████▎    | 1063/2000 [16:09<07:18,  2.14step/s]Training:  53%|█████▎    | 1064/2000 [16:09<07:18,  2.14step/s]Training:  53%|█████▎    | 1065/2000 [16:10<07:17,  2.14step/s]Training:  53%|█████▎    | 1066/2000 [16:10<07:17,  2.14step/s]Training:  53%|█████▎    | 1067/2000 [16:11<07:16,  2.14step/s]Training:  53%|█████▎    | 1068/2000 [16:11<07:16,  2.14step/s]Training:  53%|█████▎    | 1069/2000 [16:12<07:15,  2.14step/s]Training:  54%|█████▎    | 1070/2000 [16:12<07:15,  2.14step/s]Training:  54%|█████▎    | 1071/2000 [16:13<07:14,  2.14step/s]Training:  54%|█████▎    | 1072/2000 [16:13<07:14,  2.14step/s]Training:  54%|█████▎    | 1073/2000 [16:14<07:13,  2.14step/s]Training:  54%|█████▎    | 1074/2000 [16:14<07:13,  2.14step/s]Training:  54%|█████▍    | 1075/2000 [16:15<07:13,  2.14step/s]Training:  54%|█████▍    | 1076/2000 [16:15<07:12,  2.14step/s]Training:  54%|█████▍    | 1077/2000 [16:16<07:12,  2.14step/s]Training:  54%|█████▍    | 1078/2000 [16:16<07:11,  2.14step/s]Training:  54%|█████▍    | 1079/2000 [16:16<07:11,  2.14step/s]Training:  54%|█████▍    | 1080/2000 [16:17<07:10,  2.14step/s]Training:  54%|█████▍    | 1081/2000 [16:17<07:10,  2.14step/s]Training:  54%|█████▍    | 1082/2000 [16:18<07:09,  2.14step/s]Training:  54%|█████▍    | 1083/2000 [16:18<07:09,  2.14step/s]Training:  54%|█████▍    | 1084/2000 [16:19<07:08,  2.14step/s]Training:  54%|█████▍    | 1085/2000 [16:19<07:08,  2.14step/s]Training:  54%|█████▍    | 1086/2000 [16:20<07:07,  2.14step/s]Training:  54%|█████▍    | 1087/2000 [16:20<07:07,  2.14step/s]Training:  54%|█████▍    | 1088/2000 [16:21<07:06,  2.14step/s]Training:  54%|█████▍    | 1089/2000 [16:21<07:06,  2.14step/s]Training:  55%|█████▍    | 1090/2000 [16:22<07:05,  2.14step/s]Training:  55%|█████▍    | 1091/2000 [16:22<07:05,  2.14step/s]Training:  55%|█████▍    | 1092/2000 [16:23<07:04,  2.14step/s]Training:  55%|█████▍    | 1093/2000 [16:23<07:04,  2.14step/s]Training:  55%|█████▍    | 1094/2000 [16:23<07:04,  2.14step/s]Training:  55%|█████▍    | 1095/2000 [16:24<07:03,  2.14step/s]Training:  55%|█████▍    | 1096/2000 [16:24<07:03,  2.14step/s]Training:  55%|█████▍    | 1097/2000 [16:25<07:02,  2.14step/s]Training:  55%|█████▍    | 1098/2000 [16:25<07:02,  2.14step/s]Training:  55%|█████▍    | 1099/2000 [16:26<07:01,  2.14step/s]Training:  55%|█████▌    | 1100/2000 [16:26<07:01,  2.14step/s]10:55:01 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.1895 lr=5.000e-04
10:55:01 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.1083 lr=5.000e-04
10:55:02 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.1324 lr=5.000e-04
10:55:02 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.0967 lr=5.000e-04
10:55:02 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.1179 lr=5.000e-04
10:55:02 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.1398 lr=5.000e-04
10:55:02 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.0664 lr=5.000e-04
10:55:02 - trainer.t5-dialogsum-lora-main - INFO - step=1100 loss=0.1391 lr=5.000e-04
Training:  55%|█████▌    | 1101/2000 [16:27<07:00,  2.14step/s]Training:  55%|█████▌    | 1102/2000 [16:27<07:00,  2.14step/s]Training:  55%|█████▌    | 1103/2000 [16:28<06:59,  2.14step/s]Training:  55%|█████▌    | 1104/2000 [16:28<06:59,  2.14step/s]Training:  55%|█████▌    | 1105/2000 [16:29<06:58,  2.14step/s]Training:  55%|█████▌    | 1106/2000 [16:29<06:58,  2.14step/s]Training:  55%|█████▌    | 1107/2000 [16:30<06:57,  2.14step/s]Training:  55%|█████▌    | 1108/2000 [16:30<06:57,  2.14step/s]Training:  55%|█████▌    | 1109/2000 [16:31<06:57,  2.14step/s]Training:  56%|█████▌    | 1110/2000 [16:31<06:56,  2.14step/s]Training:  56%|█████▌    | 1111/2000 [16:31<06:56,  2.14step/s]Training:  56%|█████▌    | 1112/2000 [16:32<06:55,  2.14step/s]Training:  56%|█████▌    | 1113/2000 [16:32<06:55,  2.13step/s]Training:  56%|█████▌    | 1114/2000 [16:33<06:55,  2.13step/s]Training:  56%|█████▌    | 1115/2000 [16:33<06:54,  2.13step/s]Training:  56%|█████▌    | 1116/2000 [16:34<06:54,  2.13step/s]Training:  56%|█████▌    | 1117/2000 [16:34<06:53,  2.13step/s]Training:  56%|█████▌    | 1118/2000 [16:35<06:53,  2.13step/s]Training:  56%|█████▌    | 1119/2000 [16:35<06:52,  2.13step/s]Training:  56%|█████▌    | 1120/2000 [16:36<06:52,  2.13step/s]Training:  56%|█████▌    | 1121/2000 [16:36<06:51,  2.14step/s]Training:  56%|█████▌    | 1122/2000 [16:37<06:51,  2.14step/s]Training:  56%|█████▌    | 1123/2000 [16:37<06:50,  2.14step/s]Training:  56%|█████▌    | 1124/2000 [16:38<06:50,  2.14step/s]Training:  56%|█████▋    | 1125/2000 [16:38<06:49,  2.14step/s]Training:  56%|█████▋    | 1126/2000 [16:38<06:49,  2.14step/s]Training:  56%|█████▋    | 1127/2000 [16:39<06:48,  2.14step/s]Training:  56%|█████▋    | 1128/2000 [16:39<06:48,  2.14step/s]Training:  56%|█████▋    | 1129/2000 [16:40<06:47,  2.14step/s]Training:  56%|█████▋    | 1130/2000 [16:40<06:47,  2.14step/s]Training:  57%|█████▋    | 1131/2000 [16:41<06:46,  2.14step/s]Training:  57%|█████▋    | 1132/2000 [16:41<06:46,  2.14step/s]Training:  57%|█████▋    | 1133/2000 [16:42<06:45,  2.14step/s]Training:  57%|█████▋    | 1134/2000 [16:42<06:45,  2.14step/s]Training:  57%|█████▋    | 1135/2000 [16:43<06:44,  2.14step/s]Training:  57%|█████▋    | 1136/2000 [16:43<06:44,  2.14step/s]Training:  57%|█████▋    | 1137/2000 [16:44<06:43,  2.14step/s]Training:  57%|█████▋    | 1138/2000 [16:44<06:43,  2.14step/s]Training:  57%|█████▋    | 1139/2000 [16:45<06:43,  2.14step/s]Training:  57%|█████▋    | 1140/2000 [16:45<06:42,  2.14step/s]Training:  57%|█████▋    | 1141/2000 [16:46<06:42,  2.13step/s]Training:  57%|█████▋    | 1142/2000 [16:46<06:41,  2.14step/s]Training:  57%|█████▋    | 1143/2000 [16:46<06:41,  2.13step/s]Training:  57%|█████▋    | 1144/2000 [16:47<06:40,  2.13step/s]Training:  57%|█████▋    | 1145/2000 [16:47<06:40,  2.14step/s]Training:  57%|█████▋    | 1146/2000 [16:48<06:39,  2.14step/s]Training:  57%|█████▋    | 1147/2000 [16:48<06:39,  2.14step/s]Training:  57%|█████▋    | 1148/2000 [16:49<06:38,  2.14step/s]Training:  57%|█████▋    | 1149/2000 [16:49<06:38,  2.14step/s]Training:  57%|█████▊    | 1150/2000 [16:50<06:37,  2.14step/s]10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.0922 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.1339 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.1638 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.1268 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.1026 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.0768 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.1815 lr=5.000e-04
10:55:25 - trainer.t5-dialogsum-lora-main - INFO - step=1150 loss=0.0768 lr=5.000e-04
Training:  58%|█████▊    | 1151/2000 [16:50<06:37,  2.14step/s]Training:  58%|█████▊    | 1152/2000 [16:51<06:37,  2.14step/s]Training:  58%|█████▊    | 1153/2000 [16:51<06:36,  2.14step/s]Training:  58%|█████▊    | 1154/2000 [16:52<06:36,  2.14step/s]Training:  58%|█████▊    | 1155/2000 [16:52<06:35,  2.14step/s]Training:  58%|█████▊    | 1156/2000 [16:53<06:35,  2.14step/s]Training:  58%|█████▊    | 1157/2000 [16:53<06:34,  2.14step/s]Training:  58%|█████▊    | 1158/2000 [16:53<06:34,  2.14step/s]Training:  58%|█████▊    | 1159/2000 [16:54<06:33,  2.14step/s]Training:  58%|█████▊    | 1160/2000 [16:54<06:33,  2.14step/s]Training:  58%|█████▊    | 1161/2000 [16:55<06:32,  2.14step/s]Training:  58%|█████▊    | 1162/2000 [16:55<06:32,  2.14step/s]Training:  58%|█████▊    | 1163/2000 [16:56<06:31,  2.14step/s]Training:  58%|█████▊    | 1164/2000 [16:56<06:31,  2.14step/s]Training:  58%|█████▊    | 1165/2000 [16:57<06:30,  2.14step/s]Training:  58%|█████▊    | 1166/2000 [16:57<06:30,  2.14step/s]Training:  58%|█████▊    | 1167/2000 [16:58<06:29,  2.14step/s]Training:  58%|█████▊    | 1168/2000 [16:58<06:29,  2.14step/s]Training:  58%|█████▊    | 1169/2000 [16:59<06:29,  2.14step/s]Training:  58%|█████▊    | 1170/2000 [16:59<06:28,  2.14step/s]Training:  59%|█████▊    | 1171/2000 [17:00<06:28,  2.14step/s]Training:  59%|█████▊    | 1172/2000 [17:00<06:27,  2.14step/s]Training:  59%|█████▊    | 1173/2000 [17:00<06:27,  2.14step/s]Training:  59%|█████▊    | 1174/2000 [17:01<06:26,  2.14step/s]Training:  59%|█████▉    | 1175/2000 [17:01<06:26,  2.14step/s]Training:  59%|█████▉    | 1176/2000 [17:02<06:26,  2.13step/s]Training:  59%|█████▉    | 1177/2000 [17:02<06:25,  2.13step/s]Training:  59%|█████▉    | 1178/2000 [17:03<06:24,  2.14step/s]Training:  59%|█████▉    | 1179/2000 [17:03<06:24,  2.14step/s]Training:  59%|█████▉    | 1180/2000 [17:04<06:24,  2.13step/s]Training:  59%|█████▉    | 1181/2000 [17:04<06:23,  2.13step/s]Training:  59%|█████▉    | 1182/2000 [17:05<06:23,  2.14step/s]Training:  59%|█████▉    | 1183/2000 [17:05<06:22,  2.14step/s]Training:  59%|█████▉    | 1184/2000 [17:06<06:22,  2.14step/s]Training:  59%|█████▉    | 1185/2000 [17:06<06:21,  2.14step/s]Training:  59%|█████▉    | 1186/2000 [17:07<06:21,  2.14step/s]Training:  59%|█████▉    | 1187/2000 [17:07<06:20,  2.14step/s]Training:  59%|█████▉    | 1188/2000 [17:08<06:20,  2.14step/s]Training:  59%|█████▉    | 1189/2000 [17:08<06:19,  2.14step/s]Training:  60%|█████▉    | 1190/2000 [17:08<06:19,  2.14step/s]Training:  60%|█████▉    | 1191/2000 [17:09<06:18,  2.14step/s]Training:  60%|█████▉    | 1192/2000 [17:09<06:18,  2.14step/s]Training:  60%|█████▉    | 1193/2000 [17:10<06:17,  2.14step/s]Training:  60%|█████▉    | 1194/2000 [17:10<06:17,  2.14step/s]Training:  60%|█████▉    | 1195/2000 [17:11<06:16,  2.14step/s]Training:  60%|█████▉    | 1196/2000 [17:11<06:16,  2.14step/s]Training:  60%|█████▉    | 1197/2000 [17:12<06:15,  2.14step/s]Training:  60%|█████▉    | 1198/2000 [17:12<06:15,  2.14step/s]Training:  60%|█████▉    | 1199/2000 [17:13<06:14,  2.14step/s]Training:  60%|██████    | 1200/2000 [17:13<06:14,  2.14step/s]10:55:48 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.1102 lr=5.000e-04
10:55:58 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:55:58 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.1209 lr=5.000e-04
10:56:08 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:56:08 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.0936 lr=5.000e-04
10:56:18 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:56:18 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.0788 lr=5.000e-04
10:56:28 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:56:28 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.1751 lr=5.000e-04
10:56:38 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:56:38 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.0900 lr=5.000e-04
10:56:48 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:56:48 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.0821 lr=5.000e-04
10:56:58 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
10:56:58 - trainer.t5-dialogsum-lora-main - INFO - step=1200 loss=0.1105 lr=5.000e-04
10:57:08 - trainer.t5-dialogsum-lora-main - INFO - eval step=1200 loss=0.8098 ppl=2.25
Training:  60%|██████    | 1201/2000 [18:33<5:22:38, 24.23s/step]Training:  60%|██████    | 1202/2000 [18:33<3:47:26, 17.10s/step]Training:  60%|██████    | 1203/2000 [18:34<2:40:52, 12.11s/step]Training:  60%|██████    | 1204/2000 [18:34<1:54:19,  8.62s/step]Training:  60%|██████    | 1205/2000 [18:35<1:21:47,  6.17s/step]Training:  60%|██████    | 1206/2000 [18:35<59:02,  4.46s/step]  Training:  60%|██████    | 1207/2000 [18:36<43:07,  3.26s/step]Training:  60%|██████    | 1208/2000 [18:36<32:00,  2.42s/step]Training:  60%|██████    | 1209/2000 [18:37<24:13,  1.84s/step]Training:  60%|██████    | 1210/2000 [18:37<18:47,  1.43s/step]Training:  61%|██████    | 1211/2000 [18:37<14:58,  1.14s/step]Training:  61%|██████    | 1212/2000 [18:38<12:19,  1.07step/s]Training:  61%|██████    | 1213/2000 [18:38<10:27,  1.25step/s]Training:  61%|██████    | 1214/2000 [18:39<09:09,  1.43step/s]Training:  61%|██████    | 1215/2000 [18:39<08:14,  1.59step/s]Training:  61%|██████    | 1216/2000 [18:40<07:35,  1.72step/s]Training:  61%|██████    | 1217/2000 [18:40<07:08,  1.83step/s]Training:  61%|██████    | 1218/2000 [18:41<06:49,  1.91step/s]Training:  61%|██████    | 1219/2000 [18:41<06:36,  1.97step/s]Training:  61%|██████    | 1220/2000 [18:42<06:26,  2.02step/s]Training:  61%|██████    | 1221/2000 [18:42<06:19,  2.05step/s]Training:  61%|██████    | 1222/2000 [18:43<06:14,  2.08step/s]Training:  61%|██████    | 1223/2000 [18:43<06:11,  2.09step/s]Training:  61%|██████    | 1224/2000 [18:44<06:08,  2.11step/s]Training:  61%|██████▏   | 1225/2000 [18:44<06:06,  2.12step/s]Training:  61%|██████▏   | 1226/2000 [18:44<06:04,  2.12step/s]Training:  61%|██████▏   | 1227/2000 [18:45<06:03,  2.13step/s]Training:  61%|██████▏   | 1228/2000 [18:45<06:02,  2.13step/s]Training:  61%|██████▏   | 1229/2000 [18:46<06:01,  2.13step/s]Training:  62%|██████▏   | 1230/2000 [18:46<06:01,  2.13step/s]Training:  62%|██████▏   | 1231/2000 [18:47<06:00,  2.13step/s]Training:  62%|██████▏   | 1232/2000 [18:47<05:59,  2.13step/s]Training:  62%|██████▏   | 1233/2000 [18:48<05:59,  2.13step/s]Training:  62%|██████▏   | 1234/2000 [18:48<05:58,  2.14step/s]Training:  62%|██████▏   | 1235/2000 [18:49<05:58,  2.14step/s]Training:  62%|██████▏   | 1236/2000 [18:49<05:57,  2.14step/s]Training:  62%|██████▏   | 1237/2000 [18:50<05:57,  2.14step/s]Training:  62%|██████▏   | 1238/2000 [18:50<05:56,  2.14step/s]Training:  62%|██████▏   | 1239/2000 [18:51<05:56,  2.14step/s]Training:  62%|██████▏   | 1240/2000 [18:51<05:55,  2.14step/s]Training:  62%|██████▏   | 1241/2000 [18:52<05:55,  2.14step/s]Training:  62%|██████▏   | 1242/2000 [18:52<05:54,  2.14step/s]Training:  62%|██████▏   | 1243/2000 [18:52<05:54,  2.14step/s]Training:  62%|██████▏   | 1244/2000 [18:53<05:53,  2.14step/s]Training:  62%|██████▏   | 1245/2000 [18:53<05:53,  2.14step/s]Training:  62%|██████▏   | 1246/2000 [18:54<05:53,  2.13step/s]Training:  62%|██████▏   | 1247/2000 [18:54<05:52,  2.13step/s]Training:  62%|██████▏   | 1248/2000 [18:55<05:52,  2.13step/s]Training:  62%|██████▏   | 1249/2000 [18:55<05:51,  2.14step/s]Training:  62%|██████▎   | 1250/2000 [18:56<05:51,  2.13step/s]10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1008 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1402 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1155 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.0505 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1269 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1435 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1295 lr=5.000e-04
10:57:31 - trainer.t5-dialogsum-lora-main - INFO - step=1250 loss=0.1121 lr=5.000e-04
Training:  63%|██████▎   | 1251/2000 [18:56<05:51,  2.13step/s]Training:  63%|██████▎   | 1252/2000 [18:57<05:50,  2.13step/s]Training:  63%|██████▎   | 1253/2000 [18:57<05:50,  2.13step/s]Training:  63%|██████▎   | 1254/2000 [18:58<05:49,  2.13step/s]Training:  63%|██████▎   | 1255/2000 [18:58<05:49,  2.13step/s]Training:  63%|██████▎   | 1256/2000 [18:59<05:49,  2.13step/s]Training:  63%|██████▎   | 1257/2000 [18:59<05:48,  2.13step/s]Training:  63%|██████▎   | 1258/2000 [18:59<05:47,  2.13step/s]Training:  63%|██████▎   | 1259/2000 [19:00<05:47,  2.13step/s]Training:  63%|██████▎   | 1260/2000 [19:00<05:46,  2.13step/s]Training:  63%|██████▎   | 1261/2000 [19:01<05:46,  2.13step/s]Training:  63%|██████▎   | 1262/2000 [19:01<05:45,  2.13step/s]Training:  63%|██████▎   | 1263/2000 [19:02<05:45,  2.14step/s]Training:  63%|██████▎   | 1264/2000 [19:02<05:44,  2.14step/s]Training:  63%|██████▎   | 1265/2000 [19:03<05:44,  2.14step/s]Training:  63%|██████▎   | 1266/2000 [19:03<05:43,  2.14step/s]Training:  63%|██████▎   | 1267/2000 [19:04<05:43,  2.14step/s]Training:  63%|██████▎   | 1268/2000 [19:04<05:42,  2.13step/s]Training:  63%|██████▎   | 1269/2000 [19:05<05:42,  2.14step/s]Training:  64%|██████▎   | 1270/2000 [19:05<05:41,  2.14step/s]Training:  64%|██████▎   | 1271/2000 [19:06<05:41,  2.14step/s]Training:  64%|██████▎   | 1272/2000 [19:06<05:41,  2.13step/s]Training:  64%|██████▎   | 1273/2000 [19:07<05:40,  2.13step/s]Training:  64%|██████▎   | 1274/2000 [19:07<05:40,  2.13step/s]Training:  64%|██████▍   | 1275/2000 [19:07<05:39,  2.14step/s]Training:  64%|██████▍   | 1276/2000 [19:08<05:39,  2.14step/s]Training:  64%|██████▍   | 1277/2000 [19:08<05:38,  2.14step/s]Training:  64%|██████▍   | 1278/2000 [19:09<05:38,  2.14step/s]Training:  64%|██████▍   | 1279/2000 [19:09<05:37,  2.14step/s]Training:  64%|██████▍   | 1280/2000 [19:10<05:37,  2.13step/s]Training:  64%|██████▍   | 1281/2000 [19:10<05:36,  2.13step/s]Training:  64%|██████▍   | 1282/2000 [19:11<05:36,  2.13step/s]Training:  64%|██████▍   | 1283/2000 [19:11<05:35,  2.14step/s]Training:  64%|██████▍   | 1284/2000 [19:12<05:35,  2.14step/s]Training:  64%|██████▍   | 1285/2000 [19:12<05:34,  2.14step/s]Training:  64%|██████▍   | 1286/2000 [19:13<05:34,  2.14step/s]Training:  64%|██████▍   | 1287/2000 [19:13<05:33,  2.14step/s]Training:  64%|██████▍   | 1288/2000 [19:14<05:33,  2.14step/s]Training:  64%|██████▍   | 1289/2000 [19:14<05:32,  2.14step/s]Training:  64%|██████▍   | 1290/2000 [19:14<05:32,  2.14step/s]Training:  65%|██████▍   | 1291/2000 [19:15<05:31,  2.14step/s]Training:  65%|██████▍   | 1292/2000 [19:15<05:31,  2.14step/s]Training:  65%|██████▍   | 1293/2000 [19:16<05:30,  2.14step/s]Training:  65%|██████▍   | 1294/2000 [19:16<05:30,  2.14step/s]Training:  65%|██████▍   | 1295/2000 [19:17<05:29,  2.14step/s]Training:  65%|██████▍   | 1296/2000 [19:17<05:29,  2.14step/s]Training:  65%|██████▍   | 1297/2000 [19:18<05:29,  2.14step/s]Training:  65%|██████▍   | 1298/2000 [19:18<05:28,  2.14step/s]Training:  65%|██████▍   | 1299/2000 [19:19<05:28,  2.14step/s]Training:  65%|██████▌   | 1300/2000 [19:19<05:27,  2.14step/s]10:57:54 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.1002 lr=5.000e-04
10:57:54 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.0949 lr=5.000e-04
10:57:54 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.1250 lr=5.000e-04
10:57:54 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.1177 lr=5.000e-04
10:57:55 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.0829 lr=5.000e-04
10:57:55 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.1355 lr=5.000e-04
10:57:55 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.1246 lr=5.000e-04
10:57:55 - trainer.t5-dialogsum-lora-main - INFO - step=1300 loss=0.0780 lr=5.000e-04
Training:  65%|██████▌   | 1301/2000 [19:20<05:27,  2.14step/s]Training:  65%|██████▌   | 1302/2000 [19:20<05:26,  2.14step/s]Training:  65%|██████▌   | 1303/2000 [19:21<05:26,  2.14step/s]Training:  65%|██████▌   | 1304/2000 [19:21<05:25,  2.14step/s]Training:  65%|██████▌   | 1305/2000 [19:21<05:25,  2.14step/s]Training:  65%|██████▌   | 1306/2000 [19:22<05:24,  2.14step/s]Training:  65%|██████▌   | 1307/2000 [19:22<05:24,  2.14step/s]Training:  65%|██████▌   | 1308/2000 [19:23<05:23,  2.14step/s]Training:  65%|██████▌   | 1309/2000 [19:23<05:23,  2.14step/s]Training:  66%|██████▌   | 1310/2000 [19:24<05:23,  2.14step/s]Training:  66%|██████▌   | 1311/2000 [19:24<05:22,  2.14step/s]Training:  66%|██████▌   | 1312/2000 [19:25<05:22,  2.14step/s]Training:  66%|██████▌   | 1313/2000 [19:25<05:21,  2.14step/s]Training:  66%|██████▌   | 1314/2000 [19:26<05:21,  2.14step/s]Training:  66%|██████▌   | 1315/2000 [19:26<05:20,  2.14step/s]Training:  66%|██████▌   | 1316/2000 [19:27<05:20,  2.14step/s]Training:  66%|██████▌   | 1317/2000 [19:27<05:19,  2.13step/s]Training:  66%|██████▌   | 1318/2000 [19:28<05:19,  2.14step/s]Training:  66%|██████▌   | 1319/2000 [19:28<05:18,  2.14step/s]Training:  66%|██████▌   | 1320/2000 [19:29<05:18,  2.14step/s]Training:  66%|██████▌   | 1321/2000 [19:29<05:17,  2.14step/s]Training:  66%|██████▌   | 1322/2000 [19:29<05:17,  2.14step/s]Training:  66%|██████▌   | 1323/2000 [19:30<05:16,  2.14step/s]Training:  66%|██████▌   | 1324/2000 [19:30<05:16,  2.14step/s]Training:  66%|██████▋   | 1325/2000 [19:31<05:15,  2.14step/s]Training:  66%|██████▋   | 1326/2000 [19:31<05:15,  2.14step/s]Training:  66%|██████▋   | 1327/2000 [19:32<05:15,  2.14step/s]Training:  66%|██████▋   | 1328/2000 [19:32<05:14,  2.13step/s]Training:  66%|██████▋   | 1329/2000 [19:33<05:14,  2.13step/s]Training:  66%|██████▋   | 1330/2000 [19:33<05:13,  2.13step/s]Training:  67%|██████▋   | 1331/2000 [19:34<05:13,  2.13step/s]Training:  67%|██████▋   | 1332/2000 [19:34<05:13,  2.13step/s]Training:  67%|██████▋   | 1333/2000 [19:35<05:12,  2.13step/s]Training:  67%|██████▋   | 1334/2000 [19:35<05:11,  2.13step/s]Training:  67%|██████▋   | 1335/2000 [19:36<05:11,  2.13step/s]Training:  67%|██████▋   | 1336/2000 [19:36<05:11,  2.13step/s]Training:  67%|██████▋   | 1337/2000 [19:36<05:10,  2.14step/s]Training:  67%|██████▋   | 1338/2000 [19:37<05:09,  2.14step/s]Training:  67%|██████▋   | 1339/2000 [19:37<05:09,  2.14step/s]Training:  67%|██████▋   | 1340/2000 [19:38<05:09,  2.14step/s]Training:  67%|██████▋   | 1341/2000 [19:38<05:08,  2.14step/s]Training:  67%|██████▋   | 1342/2000 [19:39<05:08,  2.14step/s]Training:  67%|██████▋   | 1343/2000 [19:39<05:07,  2.14step/s]Training:  67%|██████▋   | 1344/2000 [19:40<05:07,  2.14step/s]Training:  67%|██████▋   | 1345/2000 [19:40<05:06,  2.14step/s]Training:  67%|██████▋   | 1346/2000 [19:41<05:06,  2.14step/s]Training:  67%|██████▋   | 1347/2000 [19:41<05:05,  2.14step/s]Training:  67%|██████▋   | 1348/2000 [19:42<05:05,  2.14step/s]Training:  67%|██████▋   | 1349/2000 [19:42<05:04,  2.14step/s]Training:  68%|██████▊   | 1350/2000 [19:43<05:04,  2.14step/s]10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1102 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1182 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1128 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1016 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1173 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1212 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1355 lr=5.000e-04
10:58:18 - trainer.t5-dialogsum-lora-main - INFO - step=1350 loss=0.1170 lr=5.000e-04
Training:  68%|██████▊   | 1351/2000 [19:43<05:03,  2.14step/s]Training:  68%|██████▊   | 1352/2000 [19:44<05:03,  2.14step/s]Training:  68%|██████▊   | 1353/2000 [19:44<05:02,  2.14step/s]Training:  68%|██████▊   | 1354/2000 [19:44<05:02,  2.13step/s]Training:  68%|██████▊   | 1355/2000 [19:45<05:02,  2.13step/s]Training:  68%|██████▊   | 1356/2000 [19:45<05:01,  2.14step/s]Training:  68%|██████▊   | 1357/2000 [19:46<05:01,  2.14step/s]Training:  68%|██████▊   | 1358/2000 [19:46<05:00,  2.14step/s]Training:  68%|██████▊   | 1359/2000 [19:47<05:00,  2.14step/s]Training:  68%|██████▊   | 1360/2000 [19:47<04:59,  2.14step/s]Training:  68%|██████▊   | 1361/2000 [19:48<04:59,  2.13step/s]Training:  68%|██████▊   | 1362/2000 [19:48<04:58,  2.13step/s]Training:  68%|██████▊   | 1363/2000 [19:49<04:58,  2.13step/s]Training:  68%|██████▊   | 1364/2000 [19:49<04:57,  2.14step/s]Training:  68%|██████▊   | 1365/2000 [19:50<04:57,  2.14step/s]Training:  68%|██████▊   | 1366/2000 [19:50<04:56,  2.14step/s]Training:  68%|██████▊   | 1367/2000 [19:51<04:56,  2.14step/s]Training:  68%|██████▊   | 1368/2000 [19:51<04:56,  2.13step/s]Training:  68%|██████▊   | 1369/2000 [19:51<04:55,  2.13step/s]Training:  68%|██████▊   | 1370/2000 [19:52<04:55,  2.13step/s]Training:  69%|██████▊   | 1371/2000 [19:52<04:54,  2.14step/s]Training:  69%|██████▊   | 1372/2000 [19:53<04:54,  2.14step/s]Training:  69%|██████▊   | 1373/2000 [19:53<04:53,  2.14step/s]Training:  69%|██████▊   | 1374/2000 [19:54<04:53,  2.14step/s]Training:  69%|██████▉   | 1375/2000 [19:54<04:52,  2.14step/s]Training:  69%|██████▉   | 1376/2000 [19:55<04:52,  2.14step/s]Training:  69%|██████▉   | 1377/2000 [19:55<04:51,  2.14step/s]Training:  69%|██████▉   | 1378/2000 [19:56<04:51,  2.14step/s]Training:  69%|██████▉   | 1379/2000 [19:56<04:50,  2.14step/s]Training:  69%|██████▉   | 1380/2000 [19:57<04:50,  2.14step/s]Training:  69%|██████▉   | 1381/2000 [19:57<04:49,  2.14step/s]Training:  69%|██████▉   | 1382/2000 [19:58<04:49,  2.14step/s]Training:  69%|██████▉   | 1383/2000 [19:58<04:48,  2.14step/s]Training:  69%|██████▉   | 1384/2000 [19:58<04:48,  2.14step/s]Training:  69%|██████▉   | 1385/2000 [19:59<04:47,  2.14step/s]Training:  69%|██████▉   | 1386/2000 [19:59<04:47,  2.14step/s]Training:  69%|██████▉   | 1387/2000 [20:00<04:46,  2.14step/s]Training:  69%|██████▉   | 1388/2000 [20:00<04:46,  2.14step/s]Training:  69%|██████▉   | 1389/2000 [20:01<04:46,  2.14step/s]Training:  70%|██████▉   | 1390/2000 [20:01<04:45,  2.14step/s]Training:  70%|██████▉   | 1391/2000 [20:02<04:45,  2.14step/s]Training:  70%|██████▉   | 1392/2000 [20:02<04:44,  2.14step/s]Training:  70%|██████▉   | 1393/2000 [20:03<04:44,  2.14step/s]Training:  70%|██████▉   | 1394/2000 [20:03<04:43,  2.14step/s]Training:  70%|██████▉   | 1395/2000 [20:04<04:43,  2.14step/s]Training:  70%|██████▉   | 1396/2000 [20:04<04:42,  2.14step/s]Training:  70%|██████▉   | 1397/2000 [20:05<04:42,  2.14step/s]Training:  70%|██████▉   | 1398/2000 [20:05<04:41,  2.14step/s]Training:  70%|██████▉   | 1399/2000 [20:06<04:41,  2.14step/s]Training:  70%|███████   | 1400/2000 [20:06<04:40,  2.14step/s]10:58:41 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.1034 lr=5.000e-04
10:58:51 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:58:51 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.0958 lr=5.000e-04
10:59:01 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:59:01 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.0927 lr=5.000e-04
10:59:11 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:59:11 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.0958 lr=5.000e-04
10:59:21 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:59:21 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.0893 lr=5.000e-04
10:59:31 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:59:31 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.0889 lr=5.000e-04
10:59:41 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:59:41 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.0816 lr=5.000e-04
10:59:51 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
10:59:51 - trainer.t5-dialogsum-lora-main - INFO - step=1400 loss=0.1229 lr=5.000e-04
11:00:01 - trainer.t5-dialogsum-lora-main - INFO - eval step=1400 loss=0.8004 ppl=2.23
Training:  70%|███████   | 1401/2000 [21:26<4:01:56, 24.23s/step]Training:  70%|███████   | 1402/2000 [21:26<2:50:28, 17.10s/step]Training:  70%|███████   | 1403/2000 [21:27<2:00:31, 12.11s/step]Training:  70%|███████   | 1404/2000 [21:27<1:25:37,  8.62s/step]Training:  70%|███████   | 1405/2000 [21:28<1:01:13,  6.17s/step]Training:  70%|███████   | 1406/2000 [21:28<44:10,  4.46s/step]  Training:  70%|███████   | 1407/2000 [21:28<32:15,  3.26s/step]Training:  70%|███████   | 1408/2000 [21:29<23:55,  2.43s/step]Training:  70%|███████   | 1409/2000 [21:29<18:06,  1.84s/step]Training:  70%|███████   | 1410/2000 [21:30<14:02,  1.43s/step]Training:  71%|███████   | 1411/2000 [21:30<11:11,  1.14s/step]Training:  71%|███████   | 1412/2000 [21:31<09:11,  1.07step/s]Training:  71%|███████   | 1413/2000 [21:31<07:47,  1.25step/s]Training:  71%|███████   | 1414/2000 [21:32<06:49,  1.43step/s]Training:  71%|███████   | 1415/2000 [21:32<06:08,  1.59step/s]Training:  71%|███████   | 1416/2000 [21:33<05:39,  1.72step/s]Training:  71%|███████   | 1417/2000 [21:33<05:19,  1.83step/s]Training:  71%|███████   | 1418/2000 [21:34<05:04,  1.91step/s]Training:  71%|███████   | 1419/2000 [21:34<04:54,  1.97step/s]Training:  71%|███████   | 1420/2000 [21:35<04:47,  2.02step/s]Training:  71%|███████   | 1421/2000 [21:35<04:41,  2.05step/s]Training:  71%|███████   | 1422/2000 [21:36<04:38,  2.08step/s]Training:  71%|███████   | 1423/2000 [21:36<04:35,  2.09step/s]Training:  71%|███████   | 1424/2000 [21:36<04:33,  2.11step/s]Training:  71%|███████▏  | 1425/2000 [21:37<04:31,  2.11step/s]Training:  71%|███████▏  | 1426/2000 [21:37<04:30,  2.12step/s]Training:  71%|███████▏  | 1427/2000 [21:38<04:29,  2.13step/s]Training:  71%|███████▏  | 1428/2000 [21:38<04:28,  2.13step/s]Training:  71%|███████▏  | 1429/2000 [21:39<04:27,  2.13step/s]Training:  72%|███████▏  | 1430/2000 [21:39<04:27,  2.13step/s]Training:  72%|███████▏  | 1431/2000 [21:40<04:26,  2.13step/s]Training:  72%|███████▏  | 1432/2000 [21:40<04:26,  2.13step/s]Training:  72%|███████▏  | 1433/2000 [21:41<04:25,  2.13step/s]Training:  72%|███████▏  | 1434/2000 [21:41<04:25,  2.14step/s]Training:  72%|███████▏  | 1435/2000 [21:42<04:24,  2.14step/s]Training:  72%|███████▏  | 1436/2000 [21:42<04:24,  2.14step/s]Training:  72%|███████▏  | 1437/2000 [21:43<04:23,  2.14step/s]Training:  72%|███████▏  | 1438/2000 [21:43<04:23,  2.14step/s]Training:  72%|███████▏  | 1439/2000 [21:43<04:23,  2.13step/s]Training:  72%|███████▏  | 1440/2000 [21:44<04:22,  2.13step/s]Training:  72%|███████▏  | 1441/2000 [21:44<04:22,  2.13step/s]Training:  72%|███████▏  | 1442/2000 [21:45<04:21,  2.13step/s]Training:  72%|███████▏  | 1443/2000 [21:45<04:20,  2.13step/s]Training:  72%|███████▏  | 1444/2000 [21:46<04:20,  2.14step/s]Training:  72%|███████▏  | 1445/2000 [21:46<04:19,  2.14step/s]Training:  72%|███████▏  | 1446/2000 [21:47<04:19,  2.14step/s]Training:  72%|███████▏  | 1447/2000 [21:47<04:18,  2.14step/s]Training:  72%|███████▏  | 1448/2000 [21:48<04:18,  2.14step/s]Training:  72%|███████▏  | 1449/2000 [21:48<04:18,  2.14step/s]Training:  72%|███████▎  | 1450/2000 [21:49<04:17,  2.14step/s]11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.0525 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.1119 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.0924 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.1738 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.0851 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.1226 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.1169 lr=5.000e-04
11:00:24 - trainer.t5-dialogsum-lora-main - INFO - step=1450 loss=0.0982 lr=5.000e-04
Training:  73%|███████▎  | 1451/2000 [21:49<04:17,  2.14step/s]Training:  73%|███████▎  | 1452/2000 [21:50<04:16,  2.14step/s]Training:  73%|███████▎  | 1453/2000 [21:50<04:16,  2.14step/s]Training:  73%|███████▎  | 1454/2000 [21:50<04:15,  2.14step/s]Training:  73%|███████▎  | 1455/2000 [21:51<04:15,  2.13step/s]Training:  73%|███████▎  | 1456/2000 [21:51<04:14,  2.14step/s]Training:  73%|███████▎  | 1457/2000 [21:52<04:14,  2.14step/s]Training:  73%|███████▎  | 1458/2000 [21:52<04:13,  2.14step/s]Training:  73%|███████▎  | 1459/2000 [21:53<04:13,  2.14step/s]Training:  73%|███████▎  | 1460/2000 [21:53<04:12,  2.14step/s]Training:  73%|███████▎  | 1461/2000 [21:54<04:12,  2.14step/s]Training:  73%|███████▎  | 1462/2000 [21:54<04:11,  2.14step/s]Training:  73%|███████▎  | 1463/2000 [21:55<04:11,  2.14step/s]Training:  73%|███████▎  | 1464/2000 [21:55<04:10,  2.14step/s]Training:  73%|███████▎  | 1465/2000 [21:56<04:10,  2.14step/s]Training:  73%|███████▎  | 1466/2000 [21:56<04:09,  2.14step/s]Training:  73%|███████▎  | 1467/2000 [21:57<04:09,  2.14step/s]Training:  73%|███████▎  | 1468/2000 [21:57<04:09,  2.14step/s]Training:  73%|███████▎  | 1469/2000 [21:58<04:08,  2.14step/s]Training:  74%|███████▎  | 1470/2000 [21:58<04:08,  2.14step/s]Training:  74%|███████▎  | 1471/2000 [21:58<04:07,  2.14step/s]Training:  74%|███████▎  | 1472/2000 [21:59<04:07,  2.14step/s]Training:  74%|███████▎  | 1473/2000 [21:59<04:06,  2.14step/s]Training:  74%|███████▎  | 1474/2000 [22:00<04:06,  2.14step/s]Training:  74%|███████▍  | 1475/2000 [22:00<04:05,  2.14step/s]Training:  74%|███████▍  | 1476/2000 [22:01<04:05,  2.14step/s]Training:  74%|███████▍  | 1477/2000 [22:01<04:04,  2.14step/s]Training:  74%|███████▍  | 1478/2000 [22:02<04:04,  2.14step/s]Training:  74%|███████▍  | 1479/2000 [22:02<04:03,  2.14step/s]Training:  74%|███████▍  | 1480/2000 [22:03<04:03,  2.14step/s]Training:  74%|███████▍  | 1481/2000 [22:03<04:02,  2.14step/s]Training:  74%|███████▍  | 1482/2000 [22:04<04:02,  2.14step/s]Training:  74%|███████▍  | 1483/2000 [22:04<04:01,  2.14step/s]Training:  74%|███████▍  | 1484/2000 [22:05<04:01,  2.14step/s]Training:  74%|███████▍  | 1485/2000 [22:05<04:01,  2.14step/s]Training:  74%|███████▍  | 1486/2000 [22:05<04:00,  2.14step/s]Training:  74%|███████▍  | 1487/2000 [22:06<04:00,  2.14step/s]Training:  74%|███████▍  | 1488/2000 [22:06<03:59,  2.14step/s]Training:  74%|███████▍  | 1489/2000 [22:07<03:59,  2.14step/s]Training:  74%|███████▍  | 1490/2000 [22:07<03:58,  2.14step/s]Training:  75%|███████▍  | 1491/2000 [22:08<03:58,  2.14step/s]Training:  75%|███████▍  | 1492/2000 [22:08<03:57,  2.14step/s]Training:  75%|███████▍  | 1493/2000 [22:09<03:57,  2.14step/s]Training:  75%|███████▍  | 1494/2000 [22:09<03:56,  2.14step/s]Training:  75%|███████▍  | 1495/2000 [22:10<03:56,  2.14step/s]Training:  75%|███████▍  | 1496/2000 [22:10<03:55,  2.14step/s]Training:  75%|███████▍  | 1497/2000 [22:11<03:55,  2.14step/s]Training:  75%|███████▍  | 1498/2000 [22:11<03:54,  2.14step/s]Training:  75%|███████▍  | 1499/2000 [22:12<03:54,  2.13step/s]Training:  75%|███████▌  | 1500/2000 [22:12<03:54,  2.13step/s]11:00:47 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.1131 lr=5.000e-04
11:00:47 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.1146 lr=5.000e-04
11:00:48 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.1161 lr=5.000e-04
11:00:48 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.0926 lr=5.000e-04
11:00:48 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.0688 lr=5.000e-04
11:00:49 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.1179 lr=5.000e-04
11:00:49 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.0615 lr=5.000e-04
11:00:49 - trainer.t5-dialogsum-lora-main - INFO - step=1500 loss=0.0754 lr=5.000e-04
Training:  75%|███████▌  | 1501/2000 [22:15<09:05,  1.09s/step]Training:  75%|███████▌  | 1502/2000 [22:15<07:31,  1.10step/s]Training:  75%|███████▌  | 1503/2000 [22:16<06:25,  1.29step/s]Training:  75%|███████▌  | 1504/2000 [22:16<05:38,  1.46step/s]Training:  75%|███████▌  | 1505/2000 [22:16<05:06,  1.62step/s]Training:  75%|███████▌  | 1506/2000 [22:17<04:43,  1.74step/s]Training:  75%|███████▌  | 1507/2000 [22:17<04:27,  1.85step/s]Training:  75%|███████▌  | 1508/2000 [22:18<04:15,  1.92step/s]Training:  75%|███████▌  | 1509/2000 [22:18<04:07,  1.98step/s]Training:  76%|███████▌  | 1510/2000 [22:19<04:01,  2.03step/s]Training:  76%|███████▌  | 1511/2000 [22:19<03:57,  2.06step/s]Training:  76%|███████▌  | 1512/2000 [22:20<03:54,  2.08step/s]Training:  76%|███████▌  | 1513/2000 [22:20<03:52,  2.10step/s]Training:  76%|███████▌  | 1514/2000 [22:21<03:50,  2.11step/s]Training:  76%|███████▌  | 1515/2000 [22:21<03:49,  2.12step/s]Training:  76%|███████▌  | 1516/2000 [22:22<03:47,  2.12step/s]Training:  76%|███████▌  | 1517/2000 [22:22<03:47,  2.13step/s]Training:  76%|███████▌  | 1518/2000 [22:23<03:46,  2.13step/s]Training:  76%|███████▌  | 1519/2000 [22:23<03:45,  2.13step/s]Training:  76%|███████▌  | 1520/2000 [22:23<03:44,  2.13step/s]Training:  76%|███████▌  | 1521/2000 [22:24<03:44,  2.13step/s]Training:  76%|███████▌  | 1522/2000 [22:24<03:43,  2.13step/s]Training:  76%|███████▌  | 1523/2000 [22:25<03:43,  2.14step/s]Training:  76%|███████▌  | 1524/2000 [22:25<03:42,  2.14step/s]Training:  76%|███████▋  | 1525/2000 [22:26<03:42,  2.14step/s]Training:  76%|███████▋  | 1526/2000 [22:26<03:41,  2.14step/s]Training:  76%|███████▋  | 1527/2000 [22:27<03:41,  2.14step/s]Training:  76%|███████▋  | 1528/2000 [22:27<03:40,  2.14step/s]Training:  76%|███████▋  | 1529/2000 [22:28<03:40,  2.14step/s]Training:  76%|███████▋  | 1530/2000 [22:28<03:39,  2.14step/s]Training:  77%|███████▋  | 1531/2000 [22:29<03:39,  2.14step/s]Training:  77%|███████▋  | 1532/2000 [22:29<03:38,  2.14step/s]Training:  77%|███████▋  | 1533/2000 [22:30<03:38,  2.14step/s]Training:  77%|███████▋  | 1534/2000 [22:30<03:38,  2.14step/s]Training:  77%|███████▋  | 1535/2000 [22:30<03:37,  2.14step/s]Training:  77%|███████▋  | 1536/2000 [22:31<03:37,  2.14step/s]Training:  77%|███████▋  | 1537/2000 [22:31<03:36,  2.14step/s]Training:  77%|███████▋  | 1538/2000 [22:32<03:36,  2.14step/s]Training:  77%|███████▋  | 1539/2000 [22:32<03:35,  2.14step/s]Training:  77%|███████▋  | 1540/2000 [22:33<03:35,  2.13step/s]Training:  77%|███████▋  | 1541/2000 [22:33<03:35,  2.13step/s]Training:  77%|███████▋  | 1542/2000 [22:34<03:34,  2.14step/s]Training:  77%|███████▋  | 1543/2000 [22:34<03:34,  2.14step/s]Training:  77%|███████▋  | 1544/2000 [22:35<03:33,  2.14step/s]Training:  77%|███████▋  | 1545/2000 [22:35<03:33,  2.14step/s]Training:  77%|███████▋  | 1546/2000 [22:36<03:32,  2.14step/s]Training:  77%|███████▋  | 1547/2000 [22:36<03:32,  2.14step/s]Training:  77%|███████▋  | 1548/2000 [22:37<03:31,  2.14step/s]Training:  77%|███████▋  | 1549/2000 [22:37<03:31,  2.14step/s]Training:  78%|███████▊  | 1550/2000 [22:38<03:30,  2.14step/s]11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.1067 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.1007 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.0906 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.1100 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.1600 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.0670 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.0948 lr=5.000e-04
11:01:13 - trainer.t5-dialogsum-lora-main - INFO - step=1550 loss=0.0874 lr=5.000e-04
Training:  78%|███████▊  | 1551/2000 [22:38<03:30,  2.14step/s]Training:  78%|███████▊  | 1552/2000 [22:38<03:29,  2.14step/s]Training:  78%|███████▊  | 1553/2000 [22:39<03:29,  2.14step/s]Training:  78%|███████▊  | 1554/2000 [22:39<03:28,  2.14step/s]Training:  78%|███████▊  | 1555/2000 [22:40<03:28,  2.13step/s]Training:  78%|███████▊  | 1556/2000 [22:40<03:27,  2.13step/s]Training:  78%|███████▊  | 1557/2000 [22:41<03:27,  2.14step/s]Training:  78%|███████▊  | 1558/2000 [22:41<03:27,  2.13step/s]Training:  78%|███████▊  | 1559/2000 [22:42<03:26,  2.13step/s]Training:  78%|███████▊  | 1560/2000 [22:42<03:26,  2.13step/s]Training:  78%|███████▊  | 1561/2000 [22:43<03:25,  2.14step/s]Training:  78%|███████▊  | 1562/2000 [22:43<03:25,  2.14step/s]Training:  78%|███████▊  | 1563/2000 [22:44<03:24,  2.14step/s]Training:  78%|███████▊  | 1564/2000 [22:44<03:24,  2.14step/s]Training:  78%|███████▊  | 1565/2000 [22:45<03:23,  2.14step/s]Training:  78%|███████▊  | 1566/2000 [22:45<03:23,  2.13step/s]Training:  78%|███████▊  | 1567/2000 [22:45<03:22,  2.14step/s]Training:  78%|███████▊  | 1568/2000 [22:46<03:22,  2.13step/s]Training:  78%|███████▊  | 1569/2000 [22:46<03:21,  2.13step/s]Training:  78%|███████▊  | 1570/2000 [22:47<03:21,  2.14step/s]Training:  79%|███████▊  | 1571/2000 [22:47<03:20,  2.14step/s]Training:  79%|███████▊  | 1572/2000 [22:48<03:20,  2.14step/s]Training:  79%|███████▊  | 1573/2000 [22:48<03:19,  2.14step/s]Training:  79%|███████▊  | 1574/2000 [22:49<03:19,  2.14step/s]Training:  79%|███████▉  | 1575/2000 [22:49<03:18,  2.14step/s]Training:  79%|███████▉  | 1576/2000 [22:50<03:18,  2.14step/s]Training:  79%|███████▉  | 1577/2000 [22:50<03:17,  2.14step/s]Training:  79%|███████▉  | 1578/2000 [22:51<03:17,  2.14step/s]Training:  79%|███████▉  | 1579/2000 [22:51<03:17,  2.14step/s]Training:  79%|███████▉  | 1580/2000 [22:52<03:16,  2.14step/s]Training:  79%|███████▉  | 1581/2000 [22:52<03:16,  2.14step/s]Training:  79%|███████▉  | 1582/2000 [22:53<03:15,  2.14step/s]Training:  79%|███████▉  | 1583/2000 [22:53<03:15,  2.14step/s]Training:  79%|███████▉  | 1584/2000 [22:53<03:14,  2.14step/s]Training:  79%|███████▉  | 1585/2000 [22:54<03:14,  2.14step/s]Training:  79%|███████▉  | 1586/2000 [22:54<03:13,  2.14step/s]Training:  79%|███████▉  | 1587/2000 [22:55<03:13,  2.14step/s]Training:  79%|███████▉  | 1588/2000 [22:55<03:12,  2.14step/s]Training:  79%|███████▉  | 1589/2000 [22:56<03:12,  2.14step/s]Training:  80%|███████▉  | 1590/2000 [22:56<03:11,  2.14step/s]Training:  80%|███████▉  | 1591/2000 [22:57<03:11,  2.14step/s]Training:  80%|███████▉  | 1592/2000 [22:57<03:10,  2.14step/s]Training:  80%|███████▉  | 1593/2000 [22:58<03:10,  2.14step/s]Training:  80%|███████▉  | 1594/2000 [22:58<03:10,  2.13step/s]Training:  80%|███████▉  | 1595/2000 [22:59<03:09,  2.13step/s]Training:  80%|███████▉  | 1596/2000 [22:59<03:09,  2.13step/s]Training:  80%|███████▉  | 1597/2000 [23:00<03:08,  2.13step/s]Training:  80%|███████▉  | 1598/2000 [23:00<03:08,  2.13step/s]Training:  80%|███████▉  | 1599/2000 [23:00<03:07,  2.14step/s]Training:  80%|████████  | 1600/2000 [23:01<03:07,  2.14step/s]11:01:36 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.1077 lr=5.000e-04
11:01:46 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:01:46 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.0947 lr=5.000e-04
11:01:56 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:01:56 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.1728 lr=5.000e-04
11:02:06 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:02:06 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.0495 lr=5.000e-04
11:02:16 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:02:16 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.1052 lr=5.000e-04
11:02:26 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:02:26 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.1795 lr=5.000e-04
11:02:36 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:02:36 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.0815 lr=5.000e-04
11:02:46 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
11:02:46 - trainer.t5-dialogsum-lora-main - INFO - step=1600 loss=0.0618 lr=5.000e-04
11:02:56 - trainer.t5-dialogsum-lora-main - INFO - eval step=1600 loss=0.8005 ppl=2.23
Training:  80%|████████  | 1601/2000 [24:21<2:41:06, 24.23s/step]Training:  80%|████████  | 1602/2000 [24:21<1:53:25, 17.10s/step]Training:  80%|████████  | 1603/2000 [24:22<1:20:07, 12.11s/step]Training:  80%|████████  | 1604/2000 [24:22<56:52,  8.62s/step]  Training:  80%|████████  | 1605/2000 [24:22<40:38,  6.17s/step]Training:  80%|████████  | 1606/2000 [24:23<29:17,  4.46s/step]Training:  80%|████████  | 1607/2000 [24:23<21:22,  3.26s/step]Training:  80%|████████  | 1608/2000 [24:24<15:50,  2.42s/step]Training:  80%|████████  | 1609/2000 [24:24<11:58,  1.84s/step]Training:  80%|████████  | 1610/2000 [24:25<09:16,  1.43s/step]Training:  81%|████████  | 1611/2000 [24:25<07:23,  1.14s/step]Training:  81%|████████  | 1612/2000 [24:26<06:03,  1.07step/s]Training:  81%|████████  | 1613/2000 [24:26<05:08,  1.25step/s]Training:  81%|████████  | 1614/2000 [24:27<04:29,  1.43step/s]Training:  81%|████████  | 1615/2000 [24:27<04:02,  1.59step/s]Training:  81%|████████  | 1616/2000 [24:28<03:43,  1.72step/s]Training:  81%|████████  | 1617/2000 [24:28<03:29,  1.83step/s]Training:  81%|████████  | 1618/2000 [24:29<03:19,  1.91step/s]Training:  81%|████████  | 1619/2000 [24:29<03:13,  1.97step/s]Training:  81%|████████  | 1620/2000 [24:29<03:08,  2.02step/s]Training:  81%|████████  | 1621/2000 [24:30<03:04,  2.05step/s]Training:  81%|████████  | 1622/2000 [24:30<03:02,  2.08step/s]Training:  81%|████████  | 1623/2000 [24:31<03:00,  2.09step/s]Training:  81%|████████  | 1624/2000 [24:31<02:58,  2.11step/s]Training:  81%|████████▏ | 1625/2000 [24:32<02:57,  2.12step/s]Training:  81%|████████▏ | 1626/2000 [24:32<02:56,  2.12step/s]Training:  81%|████████▏ | 1627/2000 [24:33<02:55,  2.12step/s]Training:  81%|████████▏ | 1628/2000 [24:33<02:54,  2.13step/s]Training:  81%|████████▏ | 1629/2000 [24:34<02:54,  2.13step/s]Training:  82%|████████▏ | 1630/2000 [24:34<02:53,  2.13step/s]Training:  82%|████████▏ | 1631/2000 [24:35<02:52,  2.13step/s]Training:  82%|████████▏ | 1632/2000 [24:35<02:52,  2.13step/s]Training:  82%|████████▏ | 1633/2000 [24:36<02:51,  2.13step/s]Training:  82%|████████▏ | 1634/2000 [24:36<02:51,  2.14step/s]Training:  82%|████████▏ | 1635/2000 [24:37<02:50,  2.14step/s]Training:  82%|████████▏ | 1636/2000 [24:37<02:50,  2.14step/s]Training:  82%|████████▏ | 1637/2000 [24:37<02:49,  2.14step/s]Training:  82%|████████▏ | 1638/2000 [24:38<02:49,  2.14step/s]Training:  82%|████████▏ | 1639/2000 [24:38<02:48,  2.14step/s]Training:  82%|████████▏ | 1640/2000 [24:39<02:48,  2.14step/s]Training:  82%|████████▏ | 1641/2000 [24:39<02:48,  2.14step/s]Training:  82%|████████▏ | 1642/2000 [24:40<02:47,  2.14step/s]Training:  82%|████████▏ | 1643/2000 [24:40<02:47,  2.14step/s]Training:  82%|████████▏ | 1644/2000 [24:41<02:46,  2.14step/s]Training:  82%|████████▏ | 1645/2000 [24:41<02:46,  2.14step/s]Training:  82%|████████▏ | 1646/2000 [24:42<02:45,  2.14step/s]Training:  82%|████████▏ | 1647/2000 [24:42<02:45,  2.13step/s]Training:  82%|████████▏ | 1648/2000 [24:43<02:44,  2.14step/s]Training:  82%|████████▏ | 1649/2000 [24:43<02:44,  2.14step/s]Training:  82%|████████▎ | 1650/2000 [24:44<02:43,  2.14step/s]11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.1459 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.1011 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.0874 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.1069 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.0700 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.1302 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.0918 lr=5.000e-04
11:03:19 - trainer.t5-dialogsum-lora-main - INFO - step=1650 loss=0.0797 lr=5.000e-04
Training:  83%|████████▎ | 1651/2000 [24:44<02:43,  2.14step/s]Training:  83%|████████▎ | 1652/2000 [24:44<02:42,  2.14step/s]Training:  83%|████████▎ | 1653/2000 [24:45<02:42,  2.14step/s]Training:  83%|████████▎ | 1654/2000 [24:45<02:41,  2.14step/s]Training:  83%|████████▎ | 1655/2000 [24:46<02:41,  2.14step/s]Training:  83%|████████▎ | 1656/2000 [24:46<02:41,  2.14step/s]Training:  83%|████████▎ | 1657/2000 [24:47<02:40,  2.13step/s]Training:  83%|████████▎ | 1658/2000 [24:47<02:40,  2.13step/s]Training:  83%|████████▎ | 1659/2000 [24:48<02:39,  2.13step/s]Training:  83%|████████▎ | 1660/2000 [24:48<02:39,  2.13step/s]Training:  83%|████████▎ | 1661/2000 [24:49<02:38,  2.13step/s]Training:  83%|████████▎ | 1662/2000 [24:49<02:38,  2.13step/s]Training:  83%|████████▎ | 1663/2000 [24:50<02:37,  2.14step/s]Training:  83%|████████▎ | 1664/2000 [24:50<02:37,  2.14step/s]Training:  83%|████████▎ | 1665/2000 [24:51<02:36,  2.14step/s]Training:  83%|████████▎ | 1666/2000 [24:51<02:36,  2.14step/s]Training:  83%|████████▎ | 1667/2000 [24:52<02:35,  2.14step/s]Training:  83%|████████▎ | 1668/2000 [24:52<02:35,  2.14step/s]Training:  83%|████████▎ | 1669/2000 [24:52<02:34,  2.14step/s]Training:  84%|████████▎ | 1670/2000 [24:53<02:34,  2.14step/s]Training:  84%|████████▎ | 1671/2000 [24:53<02:34,  2.14step/s]Training:  84%|████████▎ | 1672/2000 [24:54<02:33,  2.14step/s]Training:  84%|████████▎ | 1673/2000 [24:54<02:33,  2.14step/s]Training:  84%|████████▎ | 1674/2000 [24:55<02:32,  2.13step/s]Training:  84%|████████▍ | 1675/2000 [24:55<02:32,  2.13step/s]Training:  84%|████████▍ | 1676/2000 [24:56<02:31,  2.13step/s]Training:  84%|████████▍ | 1677/2000 [24:56<02:31,  2.14step/s]Training:  84%|████████▍ | 1678/2000 [24:57<02:30,  2.14step/s]Training:  84%|████████▍ | 1679/2000 [24:57<02:30,  2.14step/s]Training:  84%|████████▍ | 1680/2000 [24:58<02:29,  2.14step/s]Training:  84%|████████▍ | 1681/2000 [24:58<02:29,  2.14step/s]Training:  84%|████████▍ | 1682/2000 [24:59<02:28,  2.14step/s]Training:  84%|████████▍ | 1683/2000 [24:59<02:28,  2.14step/s]Training:  84%|████████▍ | 1684/2000 [24:59<02:27,  2.14step/s]Training:  84%|████████▍ | 1685/2000 [25:00<02:27,  2.14step/s]Training:  84%|████████▍ | 1686/2000 [25:00<02:27,  2.14step/s]Training:  84%|████████▍ | 1687/2000 [25:01<02:26,  2.13step/s]Training:  84%|████████▍ | 1688/2000 [25:01<02:26,  2.13step/s]Training:  84%|████████▍ | 1689/2000 [25:02<02:25,  2.14step/s]Training:  84%|████████▍ | 1690/2000 [25:02<02:25,  2.14step/s]Training:  85%|████████▍ | 1691/2000 [25:03<02:24,  2.14step/s]Training:  85%|████████▍ | 1692/2000 [25:03<02:24,  2.14step/s]Training:  85%|████████▍ | 1693/2000 [25:04<02:23,  2.14step/s]Training:  85%|████████▍ | 1694/2000 [25:04<02:23,  2.14step/s]Training:  85%|████████▍ | 1695/2000 [25:05<02:22,  2.14step/s]Training:  85%|████████▍ | 1696/2000 [25:05<02:22,  2.14step/s]Training:  85%|████████▍ | 1697/2000 [25:06<02:21,  2.14step/s]Training:  85%|████████▍ | 1698/2000 [25:06<02:21,  2.14step/s]Training:  85%|████████▍ | 1699/2000 [25:06<02:20,  2.14step/s]Training:  85%|████████▌ | 1700/2000 [25:07<02:20,  2.14step/s]11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.0920 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.1076 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.1020 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.1480 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.0872 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.1196 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.1230 lr=5.000e-04
11:03:42 - trainer.t5-dialogsum-lora-main - INFO - step=1700 loss=0.1262 lr=5.000e-04
Training:  85%|████████▌ | 1701/2000 [25:07<02:20,  2.14step/s]Training:  85%|████████▌ | 1702/2000 [25:08<02:19,  2.14step/s]Training:  85%|████████▌ | 1703/2000 [25:08<02:19,  2.14step/s]Training:  85%|████████▌ | 1704/2000 [25:09<02:18,  2.14step/s]Training:  85%|████████▌ | 1705/2000 [25:09<02:18,  2.14step/s]Training:  85%|████████▌ | 1706/2000 [25:10<02:17,  2.14step/s]Training:  85%|████████▌ | 1707/2000 [25:10<02:17,  2.14step/s]Training:  85%|████████▌ | 1708/2000 [25:11<02:16,  2.14step/s]Training:  85%|████████▌ | 1709/2000 [25:11<02:16,  2.14step/s]Training:  86%|████████▌ | 1710/2000 [25:12<02:15,  2.14step/s]Training:  86%|████████▌ | 1711/2000 [25:12<02:15,  2.14step/s]Training:  86%|████████▌ | 1712/2000 [25:13<02:14,  2.14step/s]Training:  86%|████████▌ | 1713/2000 [25:13<02:14,  2.14step/s]Training:  86%|████████▌ | 1714/2000 [25:14<02:13,  2.14step/s]Training:  86%|████████▌ | 1715/2000 [25:14<02:13,  2.14step/s]Training:  86%|████████▌ | 1716/2000 [25:14<02:12,  2.14step/s]Training:  86%|████████▌ | 1717/2000 [25:15<02:12,  2.14step/s]Training:  86%|████████▌ | 1718/2000 [25:15<02:12,  2.14step/s]Training:  86%|████████▌ | 1719/2000 [25:16<02:11,  2.14step/s]Training:  86%|████████▌ | 1720/2000 [25:16<02:11,  2.14step/s]Training:  86%|████████▌ | 1721/2000 [25:17<02:10,  2.14step/s]Training:  86%|████████▌ | 1722/2000 [25:17<02:10,  2.14step/s]Training:  86%|████████▌ | 1723/2000 [25:18<02:09,  2.14step/s]Training:  86%|████████▌ | 1724/2000 [25:18<02:09,  2.14step/s]Training:  86%|████████▋ | 1725/2000 [25:19<02:08,  2.14step/s]Training:  86%|████████▋ | 1726/2000 [25:19<02:08,  2.14step/s]Training:  86%|████████▋ | 1727/2000 [25:20<02:07,  2.14step/s]Training:  86%|████████▋ | 1728/2000 [25:20<02:07,  2.14step/s]Training:  86%|████████▋ | 1729/2000 [25:21<02:06,  2.14step/s]Training:  86%|████████▋ | 1730/2000 [25:21<02:06,  2.14step/s]Training:  87%|████████▋ | 1731/2000 [25:21<02:05,  2.14step/s]Training:  87%|████████▋ | 1732/2000 [25:22<02:05,  2.14step/s]Training:  87%|████████▋ | 1733/2000 [25:22<02:04,  2.14step/s]Training:  87%|████████▋ | 1734/2000 [25:23<02:04,  2.14step/s]Training:  87%|████████▋ | 1735/2000 [25:23<02:04,  2.14step/s]Training:  87%|████████▋ | 1736/2000 [25:24<02:03,  2.14step/s]Training:  87%|████████▋ | 1737/2000 [25:24<02:03,  2.14step/s]Training:  87%|████████▋ | 1738/2000 [25:25<02:02,  2.14step/s]Training:  87%|████████▋ | 1739/2000 [25:25<02:02,  2.14step/s]Training:  87%|████████▋ | 1740/2000 [25:26<02:01,  2.14step/s]Training:  87%|████████▋ | 1741/2000 [25:26<02:01,  2.14step/s]Training:  87%|████████▋ | 1742/2000 [25:27<02:00,  2.14step/s]Training:  87%|████████▋ | 1743/2000 [25:27<02:00,  2.14step/s]Training:  87%|████████▋ | 1744/2000 [25:28<01:59,  2.14step/s]Training:  87%|████████▋ | 1745/2000 [25:28<01:59,  2.14step/s]Training:  87%|████████▋ | 1746/2000 [25:28<01:58,  2.14step/s]Training:  87%|████████▋ | 1747/2000 [25:29<01:58,  2.14step/s]Training:  87%|████████▋ | 1748/2000 [25:29<01:57,  2.14step/s]Training:  87%|████████▋ | 1749/2000 [25:30<01:57,  2.14step/s]Training:  88%|████████▊ | 1750/2000 [25:30<01:57,  2.14step/s]11:04:05 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.0989 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.1529 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.0583 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.1219 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.0871 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.1314 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.0647 lr=5.000e-04
11:04:06 - trainer.t5-dialogsum-lora-main - INFO - step=1750 loss=0.0927 lr=5.000e-04
Training:  88%|████████▊ | 1751/2000 [25:31<01:56,  2.14step/s]Training:  88%|████████▊ | 1752/2000 [25:31<01:56,  2.14step/s]Training:  88%|████████▊ | 1753/2000 [25:32<01:55,  2.14step/s]Training:  88%|████████▊ | 1754/2000 [25:32<01:55,  2.14step/s]Training:  88%|████████▊ | 1755/2000 [25:33<01:54,  2.13step/s]Training:  88%|████████▊ | 1756/2000 [25:33<01:54,  2.14step/s]Training:  88%|████████▊ | 1757/2000 [25:34<01:53,  2.14step/s]Training:  88%|████████▊ | 1758/2000 [25:34<01:53,  2.14step/s]Training:  88%|████████▊ | 1759/2000 [25:35<01:52,  2.14step/s]Training:  88%|████████▊ | 1760/2000 [25:35<01:52,  2.14step/s]Training:  88%|████████▊ | 1761/2000 [25:36<01:51,  2.14step/s]Training:  88%|████████▊ | 1762/2000 [25:36<01:51,  2.13step/s]Training:  88%|████████▊ | 1763/2000 [25:36<01:50,  2.14step/s]Training:  88%|████████▊ | 1764/2000 [25:37<01:50,  2.14step/s]Training:  88%|████████▊ | 1765/2000 [25:37<01:50,  2.14step/s]Training:  88%|████████▊ | 1766/2000 [25:38<01:49,  2.14step/s]Training:  88%|████████▊ | 1767/2000 [25:38<01:49,  2.14step/s]Training:  88%|████████▊ | 1768/2000 [25:39<01:48,  2.14step/s]Training:  88%|████████▊ | 1769/2000 [25:39<01:48,  2.14step/s]Training:  88%|████████▊ | 1770/2000 [25:40<01:47,  2.14step/s]Training:  89%|████████▊ | 1771/2000 [25:40<01:47,  2.13step/s]Training:  89%|████████▊ | 1772/2000 [25:41<01:46,  2.14step/s]Training:  89%|████████▊ | 1773/2000 [25:41<01:46,  2.14step/s]Training:  89%|████████▊ | 1774/2000 [25:42<01:45,  2.14step/s]Training:  89%|████████▉ | 1775/2000 [25:42<01:45,  2.14step/s]Training:  89%|████████▉ | 1776/2000 [25:43<01:44,  2.14step/s]Training:  89%|████████▉ | 1777/2000 [25:43<01:44,  2.14step/s]Training:  89%|████████▉ | 1778/2000 [25:43<01:43,  2.14step/s]Training:  89%|████████▉ | 1779/2000 [25:44<01:43,  2.14step/s]Training:  89%|████████▉ | 1780/2000 [25:44<01:43,  2.14step/s]Training:  89%|████████▉ | 1781/2000 [25:45<01:42,  2.14step/s]Training:  89%|████████▉ | 1782/2000 [25:45<01:42,  2.14step/s]Training:  89%|████████▉ | 1783/2000 [25:46<01:41,  2.14step/s]Training:  89%|████████▉ | 1784/2000 [25:46<01:41,  2.14step/s]Training:  89%|████████▉ | 1785/2000 [25:47<01:40,  2.14step/s]Training:  89%|████████▉ | 1786/2000 [25:47<01:40,  2.14step/s]Training:  89%|████████▉ | 1787/2000 [25:48<01:39,  2.14step/s]Training:  89%|████████▉ | 1788/2000 [25:48<01:39,  2.14step/s]Training:  89%|████████▉ | 1789/2000 [25:49<01:38,  2.14step/s]Training:  90%|████████▉ | 1790/2000 [25:49<01:38,  2.14step/s]Training:  90%|████████▉ | 1791/2000 [25:50<01:37,  2.14step/s]Training:  90%|████████▉ | 1792/2000 [25:50<01:37,  2.14step/s]Training:  90%|████████▉ | 1793/2000 [25:50<01:36,  2.14step/s]Training:  90%|████████▉ | 1794/2000 [25:51<01:36,  2.14step/s]Training:  90%|████████▉ | 1795/2000 [25:51<01:35,  2.14step/s]Training:  90%|████████▉ | 1796/2000 [25:52<01:35,  2.14step/s]Training:  90%|████████▉ | 1797/2000 [25:52<01:35,  2.14step/s]Training:  90%|████████▉ | 1798/2000 [25:53<01:34,  2.14step/s]Training:  90%|████████▉ | 1799/2000 [25:53<01:34,  2.14step/s]Training:  90%|█████████ | 1800/2000 [25:54<01:33,  2.14step/s]11:04:29 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1302 lr=5.000e-04
11:04:39 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:04:39 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1253 lr=5.000e-04
11:04:49 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:04:49 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1739 lr=5.000e-04
11:04:59 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:04:59 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1388 lr=5.000e-04
11:05:09 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:05:09 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1098 lr=5.000e-04
11:05:19 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:05:19 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1213 lr=5.000e-04
11:05:29 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:05:29 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.1051 lr=5.000e-04
11:05:39 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
11:05:39 - trainer.t5-dialogsum-lora-main - INFO - step=1800 loss=0.0780 lr=5.000e-04
11:05:49 - trainer.t5-dialogsum-lora-main - INFO - eval step=1800 loss=0.7931 ppl=2.21
Training:  90%|█████████ | 1801/2000 [27:14<1:20:26, 24.25s/step]Training:  90%|█████████ | 1802/2000 [27:14<56:29, 17.12s/step]  Training:  90%|█████████ | 1803/2000 [27:14<39:48, 12.12s/step]Training:  90%|█████████ | 1804/2000 [27:15<28:10,  8.63s/step]Training:  90%|█████████ | 1805/2000 [27:15<20:04,  6.18s/step]Training:  90%|█████████ | 1806/2000 [27:16<14:26,  4.47s/step]Training:  90%|█████████ | 1807/2000 [27:16<10:30,  3.27s/step]Training:  90%|█████████ | 1808/2000 [27:17<07:46,  2.43s/step]Training:  90%|█████████ | 1809/2000 [27:17<05:51,  1.84s/step]Training:  90%|█████████ | 1810/2000 [27:18<04:31,  1.43s/step]Training:  91%|█████████ | 1811/2000 [27:18<03:35,  1.14s/step]Training:  91%|█████████ | 1812/2000 [27:19<02:56,  1.07step/s]Training:  91%|█████████ | 1813/2000 [27:19<02:29,  1.25step/s]Training:  91%|█████████ | 1814/2000 [27:20<02:09,  1.43step/s]Training:  91%|█████████ | 1815/2000 [27:20<01:56,  1.59step/s]Training:  91%|█████████ | 1816/2000 [27:21<01:46,  1.72step/s]Training:  91%|█████████ | 1817/2000 [27:21<01:40,  1.83step/s]Training:  91%|█████████ | 1818/2000 [27:21<01:35,  1.91step/s]Training:  91%|█████████ | 1819/2000 [27:22<01:31,  1.97step/s]Training:  91%|█████████ | 1820/2000 [27:22<01:29,  2.02step/s]Training:  91%|█████████ | 1821/2000 [27:23<01:27,  2.05step/s]Training:  91%|█████████ | 1822/2000 [27:23<01:25,  2.08step/s]Training:  91%|█████████ | 1823/2000 [27:24<01:24,  2.09step/s]Training:  91%|█████████ | 1824/2000 [27:24<01:23,  2.11step/s]Training:  91%|█████████▏| 1825/2000 [27:25<01:22,  2.11step/s]Training:  91%|█████████▏| 1826/2000 [27:25<01:22,  2.12step/s]Training:  91%|█████████▏| 1827/2000 [27:26<01:21,  2.12step/s]Training:  91%|█████████▏| 1828/2000 [27:26<01:20,  2.13step/s]Training:  91%|█████████▏| 1829/2000 [27:27<01:20,  2.13step/s]Training:  92%|█████████▏| 1830/2000 [27:27<01:19,  2.13step/s]Training:  92%|█████████▏| 1831/2000 [27:28<01:19,  2.13step/s]Training:  92%|█████████▏| 1832/2000 [27:28<01:18,  2.13step/s]Training:  92%|█████████▏| 1833/2000 [27:29<01:18,  2.13step/s]Training:  92%|█████████▏| 1834/2000 [27:29<01:17,  2.13step/s]Training:  92%|█████████▏| 1835/2000 [27:29<01:17,  2.13step/s]Training:  92%|█████████▏| 1836/2000 [27:30<01:16,  2.14step/s]Training:  92%|█████████▏| 1837/2000 [27:30<01:16,  2.14step/s]Training:  92%|█████████▏| 1838/2000 [27:31<01:15,  2.14step/s]Training:  92%|█████████▏| 1839/2000 [27:31<01:15,  2.14step/s]Training:  92%|█████████▏| 1840/2000 [27:32<01:14,  2.14step/s]Training:  92%|█████████▏| 1841/2000 [27:32<01:14,  2.14step/s]Training:  92%|█████████▏| 1842/2000 [27:33<01:14,  2.13step/s]Training:  92%|█████████▏| 1843/2000 [27:33<01:13,  2.13step/s]Training:  92%|█████████▏| 1844/2000 [27:34<01:13,  2.13step/s]Training:  92%|█████████▏| 1845/2000 [27:34<01:12,  2.14step/s]Training:  92%|█████████▏| 1846/2000 [27:35<01:12,  2.14step/s]Training:  92%|█████████▏| 1847/2000 [27:35<01:11,  2.14step/s]Training:  92%|█████████▏| 1848/2000 [27:36<01:11,  2.14step/s]Training:  92%|█████████▏| 1849/2000 [27:36<01:10,  2.14step/s]Training:  92%|█████████▎| 1850/2000 [27:36<01:10,  2.14step/s]11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.1990 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.0783 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.0864 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.1110 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.1322 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.1075 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.0741 lr=5.000e-04
11:06:12 - trainer.t5-dialogsum-lora-main - INFO - step=1850 loss=0.0904 lr=5.000e-04
Training:  93%|█████████▎| 1851/2000 [27:37<01:09,  2.13step/s]Training:  93%|█████████▎| 1852/2000 [27:37<01:09,  2.13step/s]Training:  93%|█████████▎| 1853/2000 [27:38<01:08,  2.14step/s]Training:  93%|█████████▎| 1854/2000 [27:38<01:08,  2.14step/s]Training:  93%|█████████▎| 1855/2000 [27:39<01:07,  2.14step/s]Training:  93%|█████████▎| 1856/2000 [27:39<01:07,  2.14step/s]Training:  93%|█████████▎| 1857/2000 [27:40<01:06,  2.14step/s]Training:  93%|█████████▎| 1858/2000 [27:40<01:06,  2.14step/s]Training:  93%|█████████▎| 1859/2000 [27:41<01:06,  2.14step/s]Training:  93%|█████████▎| 1860/2000 [27:41<01:05,  2.14step/s]Training:  93%|█████████▎| 1861/2000 [27:42<01:05,  2.14step/s]Training:  93%|█████████▎| 1862/2000 [27:42<01:04,  2.14step/s]Training:  93%|█████████▎| 1863/2000 [27:43<01:04,  2.14step/s]Training:  93%|█████████▎| 1864/2000 [27:43<01:03,  2.14step/s]Training:  93%|█████████▎| 1865/2000 [27:43<01:03,  2.14step/s]Training:  93%|█████████▎| 1866/2000 [27:44<01:02,  2.13step/s]Training:  93%|█████████▎| 1867/2000 [27:44<01:02,  2.14step/s]Training:  93%|█████████▎| 1868/2000 [27:45<01:01,  2.14step/s]Training:  93%|█████████▎| 1869/2000 [27:45<01:01,  2.14step/s]Training:  94%|█████████▎| 1870/2000 [27:46<01:00,  2.14step/s]Training:  94%|█████████▎| 1871/2000 [27:46<01:00,  2.14step/s]Training:  94%|█████████▎| 1872/2000 [27:47<00:59,  2.14step/s]Training:  94%|█████████▎| 1873/2000 [27:47<00:59,  2.14step/s]Training:  94%|█████████▎| 1874/2000 [27:48<00:58,  2.14step/s]Training:  94%|█████████▍| 1875/2000 [27:48<00:58,  2.14step/s]Training:  94%|█████████▍| 1876/2000 [27:49<00:58,  2.14step/s]Training:  94%|█████████▍| 1877/2000 [27:49<00:57,  2.14step/s]Training:  94%|█████████▍| 1878/2000 [27:50<00:57,  2.13step/s]Training:  94%|█████████▍| 1879/2000 [27:50<00:56,  2.14step/s]Training:  94%|█████████▍| 1880/2000 [27:51<00:56,  2.14step/s]Training:  94%|█████████▍| 1881/2000 [27:51<00:55,  2.14step/s]Training:  94%|█████████▍| 1882/2000 [27:51<00:55,  2.14step/s]Training:  94%|█████████▍| 1883/2000 [27:52<00:54,  2.14step/s]Training:  94%|█████████▍| 1884/2000 [27:52<00:54,  2.14step/s]Training:  94%|█████████▍| 1885/2000 [27:53<00:53,  2.14step/s]Training:  94%|█████████▍| 1886/2000 [27:53<00:53,  2.14step/s]Training:  94%|█████████▍| 1887/2000 [27:54<00:52,  2.14step/s]Training:  94%|█████████▍| 1888/2000 [27:54<00:52,  2.14step/s]Training:  94%|█████████▍| 1889/2000 [27:55<00:51,  2.14step/s]Training:  94%|█████████▍| 1890/2000 [27:55<00:51,  2.14step/s]Training:  95%|█████████▍| 1891/2000 [27:56<00:51,  2.14step/s]Training:  95%|█████████▍| 1892/2000 [27:56<00:50,  2.14step/s]Training:  95%|█████████▍| 1893/2000 [27:57<00:50,  2.14step/s]Training:  95%|█████████▍| 1894/2000 [27:57<00:49,  2.14step/s]Training:  95%|█████████▍| 1895/2000 [27:58<00:49,  2.14step/s]Training:  95%|█████████▍| 1896/2000 [27:58<00:48,  2.13step/s]Training:  95%|█████████▍| 1897/2000 [27:58<00:48,  2.13step/s]Training:  95%|█████████▍| 1898/2000 [27:59<00:47,  2.13step/s]Training:  95%|█████████▍| 1899/2000 [27:59<00:47,  2.13step/s]Training:  95%|█████████▌| 1900/2000 [28:00<00:46,  2.13step/s]11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.1299 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.1066 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.1137 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.1277 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.0913 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.0893 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.1224 lr=5.000e-04
11:06:35 - trainer.t5-dialogsum-lora-main - INFO - step=1900 loss=0.1583 lr=5.000e-04
Training:  95%|█████████▌| 1901/2000 [28:00<00:46,  2.13step/s]Training:  95%|█████████▌| 1902/2000 [28:01<00:45,  2.13step/s]Training:  95%|█████████▌| 1903/2000 [28:01<00:45,  2.13step/s]Training:  95%|█████████▌| 1904/2000 [28:02<00:44,  2.14step/s]Training:  95%|█████████▌| 1905/2000 [28:02<00:44,  2.14step/s]Training:  95%|█████████▌| 1906/2000 [28:03<00:44,  2.14step/s]Training:  95%|█████████▌| 1907/2000 [28:03<00:43,  2.14step/s]Training:  95%|█████████▌| 1908/2000 [28:04<00:43,  2.14step/s]Training:  95%|█████████▌| 1909/2000 [28:04<00:42,  2.14step/s]Training:  96%|█████████▌| 1910/2000 [28:05<00:42,  2.14step/s]Training:  96%|█████████▌| 1911/2000 [28:05<00:41,  2.14step/s]Training:  96%|█████████▌| 1912/2000 [28:06<00:41,  2.14step/s]Training:  96%|█████████▌| 1913/2000 [28:06<00:40,  2.14step/s]Training:  96%|█████████▌| 1914/2000 [28:06<00:40,  2.14step/s]Training:  96%|█████████▌| 1915/2000 [28:07<00:39,  2.14step/s]Training:  96%|█████████▌| 1916/2000 [28:07<00:39,  2.14step/s]Training:  96%|█████████▌| 1917/2000 [28:08<00:38,  2.14step/s]Training:  96%|█████████▌| 1918/2000 [28:08<00:38,  2.14step/s]Training:  96%|█████████▌| 1919/2000 [28:09<00:37,  2.14step/s]Training:  96%|█████████▌| 1920/2000 [28:09<00:37,  2.14step/s]Training:  96%|█████████▌| 1921/2000 [28:10<00:36,  2.14step/s]Training:  96%|█████████▌| 1922/2000 [28:10<00:36,  2.14step/s]Training:  96%|█████████▌| 1923/2000 [28:11<00:36,  2.14step/s]Training:  96%|█████████▌| 1924/2000 [28:11<00:35,  2.14step/s]Training:  96%|█████████▋| 1925/2000 [28:12<00:35,  2.14step/s]Training:  96%|█████████▋| 1926/2000 [28:12<00:34,  2.14step/s]Training:  96%|█████████▋| 1927/2000 [28:13<00:34,  2.14step/s]Training:  96%|█████████▋| 1928/2000 [28:13<00:33,  2.14step/s]Training:  96%|█████████▋| 1929/2000 [28:13<00:33,  2.14step/s]Training:  96%|█████████▋| 1930/2000 [28:14<00:32,  2.14step/s]Training:  97%|█████████▋| 1931/2000 [28:14<00:32,  2.14step/s]Training:  97%|█████████▋| 1932/2000 [28:15<00:31,  2.14step/s]Training:  97%|█████████▋| 1933/2000 [28:15<00:31,  2.14step/s]Training:  97%|█████████▋| 1934/2000 [28:16<00:30,  2.14step/s]Training:  97%|█████████▋| 1935/2000 [28:16<00:30,  2.14step/s]Training:  97%|█████████▋| 1936/2000 [28:17<00:29,  2.14step/s]Training:  97%|█████████▋| 1937/2000 [28:17<00:29,  2.14step/s]Training:  97%|█████████▋| 1938/2000 [28:18<00:29,  2.13step/s]Training:  97%|█████████▋| 1939/2000 [28:18<00:28,  2.13step/s]Training:  97%|█████████▋| 1940/2000 [28:19<00:28,  2.13step/s]Training:  97%|█████████▋| 1941/2000 [28:19<00:27,  2.13step/s]Training:  97%|█████████▋| 1942/2000 [28:20<00:27,  2.14step/s]Training:  97%|█████████▋| 1943/2000 [28:20<00:26,  2.14step/s]Training:  97%|█████████▋| 1944/2000 [28:20<00:26,  2.14step/s]Training:  97%|█████████▋| 1945/2000 [28:21<00:25,  2.14step/s]Training:  97%|█████████▋| 1946/2000 [28:21<00:25,  2.14step/s]Training:  97%|█████████▋| 1947/2000 [28:22<00:24,  2.14step/s]Training:  97%|█████████▋| 1948/2000 [28:22<00:24,  2.14step/s]Training:  97%|█████████▋| 1949/2000 [28:23<00:23,  2.14step/s]Training:  98%|█████████▊| 1950/2000 [28:23<00:23,  2.14step/s]11:06:58 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1438 lr=5.000e-04
11:06:58 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1229 lr=5.000e-04
11:06:59 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1805 lr=5.000e-04
11:06:59 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.0918 lr=5.000e-04
11:06:59 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1025 lr=5.000e-04
11:06:59 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1043 lr=5.000e-04
11:06:59 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1174 lr=5.000e-04
11:06:59 - trainer.t5-dialogsum-lora-main - INFO - step=1950 loss=0.1112 lr=5.000e-04
Training:  98%|█████████▊| 1951/2000 [28:24<00:22,  2.14step/s]Training:  98%|█████████▊| 1952/2000 [28:24<00:22,  2.14step/s]Training:  98%|█████████▊| 1953/2000 [28:25<00:22,  2.14step/s]Training:  98%|█████████▊| 1954/2000 [28:25<00:21,  2.14step/s]Training:  98%|█████████▊| 1955/2000 [28:26<00:21,  2.14step/s]Training:  98%|█████████▊| 1956/2000 [28:26<00:20,  2.14step/s]Training:  98%|█████████▊| 1957/2000 [28:27<00:20,  2.13step/s]Training:  98%|█████████▊| 1958/2000 [28:27<00:19,  2.13step/s]Training:  98%|█████████▊| 1959/2000 [28:28<00:19,  2.13step/s]Training:  98%|█████████▊| 1960/2000 [28:28<00:18,  2.14step/s]Training:  98%|█████████▊| 1961/2000 [28:28<00:18,  2.14step/s]Training:  98%|█████████▊| 1962/2000 [28:29<00:17,  2.14step/s]Training:  98%|█████████▊| 1963/2000 [28:29<00:17,  2.14step/s]Training:  98%|█████████▊| 1964/2000 [28:30<00:16,  2.14step/s]Training:  98%|█████████▊| 1965/2000 [28:30<00:16,  2.14step/s]Training:  98%|█████████▊| 1966/2000 [28:31<00:15,  2.14step/s]Training:  98%|█████████▊| 1967/2000 [28:31<00:15,  2.14step/s]Training:  98%|█████████▊| 1968/2000 [28:32<00:14,  2.14step/s]Training:  98%|█████████▊| 1969/2000 [28:32<00:14,  2.14step/s]Training:  98%|█████████▊| 1970/2000 [28:33<00:14,  2.14step/s]Training:  99%|█████████▊| 1971/2000 [28:33<00:13,  2.14step/s]Training:  99%|█████████▊| 1972/2000 [28:34<00:13,  2.14step/s]Training:  99%|█████████▊| 1973/2000 [28:34<00:12,  2.14step/s]Training:  99%|█████████▊| 1974/2000 [28:35<00:12,  2.14step/s]Training:  99%|█████████▉| 1975/2000 [28:35<00:11,  2.14step/s]Training:  99%|█████████▉| 1976/2000 [28:35<00:11,  2.14step/s]Training:  99%|█████████▉| 1977/2000 [28:36<00:10,  2.14step/s]Training:  99%|█████████▉| 1978/2000 [28:36<00:10,  2.14step/s]Training:  99%|█████████▉| 1979/2000 [28:37<00:09,  2.14step/s]Training:  99%|█████████▉| 1980/2000 [28:37<00:09,  2.14step/s]Training:  99%|█████████▉| 1981/2000 [28:38<00:08,  2.14step/s]Training:  99%|█████████▉| 1982/2000 [28:38<00:08,  2.14step/s]Training:  99%|█████████▉| 1983/2000 [28:39<00:07,  2.14step/s]Training:  99%|█████████▉| 1984/2000 [28:39<00:07,  2.14step/s]Training:  99%|█████████▉| 1985/2000 [28:40<00:07,  2.14step/s]Training:  99%|█████████▉| 1986/2000 [28:40<00:06,  2.14step/s]Training:  99%|█████████▉| 1987/2000 [28:41<00:06,  2.14step/s]Training:  99%|█████████▉| 1988/2000 [28:41<00:05,  2.14step/s]Training:  99%|█████████▉| 1989/2000 [28:42<00:05,  2.14step/s]Training: 100%|█████████▉| 1990/2000 [28:42<00:04,  2.14step/s]Training: 100%|█████████▉| 1991/2000 [28:42<00:04,  2.14step/s]Training: 100%|█████████▉| 1992/2000 [28:43<00:03,  2.14step/s]Training: 100%|█████████▉| 1993/2000 [28:43<00:03,  2.14step/s]Training: 100%|█████████▉| 1994/2000 [28:44<00:02,  2.14step/s]Training: 100%|█████████▉| 1995/2000 [28:44<00:02,  2.14step/s]Training: 100%|█████████▉| 1996/2000 [28:45<00:01,  2.14step/s]Training: 100%|█████████▉| 1997/2000 [28:45<00:01,  2.14step/s]Training: 100%|█████████▉| 1998/2000 [28:46<00:00,  2.13step/s]Training: 100%|█████████▉| 1999/2000 [28:46<00:00,  2.14step/s]Training: 100%|██████████| 2000/2000 [28:47<00:00,  2.14step/s]Training: 100%|██████████| 2000/2000 [28:47<00:00,  1.16step/s]

[11:07:23] Phase 2.4: Evaluating T5 DialogSum...
Processed 80 samples...
Processed 160 samples...
Processed 240 samples...
Processed 320 samples...
Processed 400 samples...
Processed 480 samples...
Processed 560 samples...
Processed 640 samples...
Processed 720 samples...
Processed 800 samples...
Processed 880 samples...
Processed 960 samples...
Processed 1040 samples...
Processed 1120 samples...
Processed 1200 samples...
Processed 1280 samples...
Processed 1360 samples...
Processed 1440 samples...
Downloading builder script: 0.00B [00:00, ?B/s]Downloading builder script: 6.14kB [00:00, 35.2MB/s]

ROUGE-1: 0.3925
ROUGE-2: 0.1348
ROUGE-L: 0.3154
Wrote ROUGE metrics to experiments/samsum_eval_metrics.csv

[11:09:01] Phase 2.5: Training GPT-2 + LoRA on GSM8K...
/home/ayman/modern_llm/.venv/lib/python3.12/site-packages/peft/tuners/lora/layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
  warnings.warn(
Training:   0%|          | 0/3000 [00:00<?, ?step/s]/home/ayman/modern_llm/src/modern_llm/training/trainer_base.py:137: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(dtype=autocast_dtype, enabled=self.use_amp):
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
11:09:09 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.2897 lr=2.000e-06
11:09:31 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
11:09:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.2350 lr=2.000e-06
11:09:54 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
11:09:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.2047 lr=2.000e-06
11:10:17 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
11:10:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.1980 lr=2.000e-06
11:10:40 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
11:10:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.2657 lr=2.000e-06
11:11:02 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
11:11:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.2423 lr=2.000e-06
11:11:25 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
11:11:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=0 loss=1.2732 lr=2.000e-06
11:11:48 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=0 loss=11.4991 ppl=98625.90
Training:   0%|          | 1/3000 [02:40<133:42:51, 160.51s/step]Training:   0%|          | 2/3000 [02:41<55:42:03, 66.89s/step]  Training:   0%|          | 3/3000 [02:43<30:46:08, 36.96s/step]Training:   0%|          | 4/3000 [02:44<19:03:29, 22.90s/step]Training:   0%|          | 5/3000 [02:45<12:35:08, 15.13s/step]Training:   0%|          | 6/3000 [02:47<8:41:04, 10.44s/step] Training:   0%|          | 7/3000 [02:48<6:12:34,  7.47s/step]Training:   0%|          | 8/3000 [02:49<4:35:15,  5.52s/step]Training:   0%|          | 9/3000 [02:51<3:30:08,  4.22s/step]Training:   0%|          | 10/3000 [02:52<2:45:55,  3.33s/step]Training:   0%|          | 11/3000 [02:53<2:15:39,  2.72s/step]Training:   0%|          | 12/3000 [02:55<1:54:45,  2.30s/step]Training:   0%|          | 13/3000 [02:56<1:40:16,  2.01s/step]Training:   0%|          | 14/3000 [02:58<1:30:12,  1.81s/step]Training:   0%|          | 15/3000 [02:59<1:23:12,  1.67s/step]Training:   1%|          | 16/3000 [03:00<1:18:18,  1.57s/step]Training:   1%|          | 17/3000 [03:02<1:14:53,  1.51s/step]Training:   1%|          | 18/3000 [03:03<1:12:28,  1.46s/step]Training:   1%|          | 19/3000 [03:04<1:10:47,  1.42s/step]Training:   1%|          | 20/3000 [03:06<1:09:35,  1.40s/step]Training:   1%|          | 21/3000 [03:07<1:08:45,  1.38s/step]Training:   1%|          | 22/3000 [03:08<1:08:09,  1.37s/step]Training:   1%|          | 23/3000 [03:10<1:07:44,  1.37s/step]Training:   1%|          | 24/3000 [03:11<1:07:26,  1.36s/step]Training:   1%|          | 25/3000 [03:12<1:07:14,  1.36s/step]Training:   1%|          | 26/3000 [03:14<1:07:04,  1.35s/step]Training:   1%|          | 27/3000 [03:15<1:06:56,  1.35s/step]Training:   1%|          | 28/3000 [03:16<1:06:51,  1.35s/step]Training:   1%|          | 29/3000 [03:18<1:06:47,  1.35s/step]Training:   1%|          | 30/3000 [03:19<1:06:44,  1.35s/step]Training:   1%|          | 31/3000 [03:20<1:06:41,  1.35s/step]Training:   1%|          | 32/3000 [03:22<1:06:39,  1.35s/step]Training:   1%|          | 33/3000 [03:23<1:06:36,  1.35s/step]Training:   1%|          | 34/3000 [03:24<1:06:34,  1.35s/step]Training:   1%|          | 35/3000 [03:26<1:06:32,  1.35s/step]Training:   1%|          | 36/3000 [03:27<1:06:31,  1.35s/step]Training:   1%|          | 37/3000 [03:28<1:06:29,  1.35s/step]Training:   1%|▏         | 38/3000 [03:30<1:06:28,  1.35s/step]Training:   1%|▏         | 39/3000 [03:31<1:06:26,  1.35s/step]Training:   1%|▏         | 40/3000 [03:33<1:06:25,  1.35s/step]Training:   1%|▏         | 41/3000 [03:34<1:06:24,  1.35s/step]Training:   1%|▏         | 42/3000 [03:35<1:06:22,  1.35s/step]Training:   1%|▏         | 43/3000 [03:37<1:06:22,  1.35s/step]Training:   1%|▏         | 44/3000 [03:38<1:06:20,  1.35s/step]Training:   2%|▏         | 45/3000 [03:39<1:06:19,  1.35s/step]Training:   2%|▏         | 46/3000 [03:41<1:06:17,  1.35s/step]Training:   2%|▏         | 47/3000 [03:42<1:06:17,  1.35s/step]Training:   2%|▏         | 48/3000 [03:43<1:06:15,  1.35s/step]Training:   2%|▏         | 49/3000 [03:45<1:06:13,  1.35s/step]Training:   2%|▏         | 50/3000 [03:46<1:06:12,  1.35s/step]11:12:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.2487 lr=1.020e-04
11:12:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.2498 lr=1.020e-04
11:12:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.2624 lr=1.020e-04
11:12:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.2094 lr=1.020e-04
11:12:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.2561 lr=1.020e-04
11:12:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.1807 lr=1.020e-04
11:12:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.2045 lr=1.020e-04
11:12:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=50 loss=0.3196 lr=1.020e-04
Training:   2%|▏         | 51/3000 [03:47<1:06:12,  1.35s/step]Training:   2%|▏         | 52/3000 [03:49<1:06:10,  1.35s/step]Training:   2%|▏         | 53/3000 [03:50<1:06:10,  1.35s/step]Training:   2%|▏         | 54/3000 [03:51<1:06:08,  1.35s/step]Training:   2%|▏         | 55/3000 [03:53<1:06:06,  1.35s/step]Training:   2%|▏         | 56/3000 [03:54<1:06:05,  1.35s/step]Training:   2%|▏         | 57/3000 [03:55<1:06:03,  1.35s/step]Training:   2%|▏         | 58/3000 [03:57<1:06:02,  1.35s/step]Training:   2%|▏         | 59/3000 [03:58<1:06:00,  1.35s/step]Training:   2%|▏         | 60/3000 [03:59<1:06:00,  1.35s/step]Training:   2%|▏         | 61/3000 [04:01<1:05:58,  1.35s/step]Training:   2%|▏         | 62/3000 [04:02<1:05:57,  1.35s/step]Training:   2%|▏         | 63/3000 [04:04<1:05:56,  1.35s/step]Training:   2%|▏         | 64/3000 [04:05<1:05:55,  1.35s/step]Training:   2%|▏         | 65/3000 [04:06<1:05:54,  1.35s/step]Training:   2%|▏         | 66/3000 [04:08<1:05:52,  1.35s/step]Training:   2%|▏         | 67/3000 [04:09<1:05:50,  1.35s/step]Training:   2%|▏         | 68/3000 [04:10<1:05:49,  1.35s/step]Training:   2%|▏         | 69/3000 [04:12<1:05:47,  1.35s/step]Training:   2%|▏         | 70/3000 [04:13<1:05:45,  1.35s/step]Training:   2%|▏         | 71/3000 [04:14<1:05:44,  1.35s/step]Training:   2%|▏         | 72/3000 [04:16<1:05:43,  1.35s/step]Training:   2%|▏         | 73/3000 [04:17<1:05:41,  1.35s/step]Training:   2%|▏         | 74/3000 [04:18<1:05:41,  1.35s/step]Training:   2%|▎         | 75/3000 [04:20<1:05:39,  1.35s/step]Training:   3%|▎         | 76/3000 [04:21<1:05:37,  1.35s/step]Training:   3%|▎         | 77/3000 [04:22<1:05:38,  1.35s/step]Training:   3%|▎         | 78/3000 [04:24<1:05:38,  1.35s/step]Training:   3%|▎         | 79/3000 [04:25<1:05:36,  1.35s/step]Training:   3%|▎         | 80/3000 [04:26<1:05:34,  1.35s/step]Training:   3%|▎         | 81/3000 [04:28<1:05:34,  1.35s/step]Training:   3%|▎         | 82/3000 [04:29<1:05:31,  1.35s/step]Training:   3%|▎         | 83/3000 [04:30<1:05:30,  1.35s/step]Training:   3%|▎         | 84/3000 [04:32<1:05:28,  1.35s/step]Training:   3%|▎         | 85/3000 [04:33<1:05:26,  1.35s/step]Training:   3%|▎         | 86/3000 [04:34<1:05:24,  1.35s/step]Training:   3%|▎         | 87/3000 [04:36<1:05:22,  1.35s/step]Training:   3%|▎         | 88/3000 [04:37<1:05:21,  1.35s/step]Training:   3%|▎         | 89/3000 [04:39<1:05:19,  1.35s/step]Training:   3%|▎         | 90/3000 [04:40<1:05:18,  1.35s/step]Training:   3%|▎         | 91/3000 [04:41<1:05:17,  1.35s/step]Training:   3%|▎         | 92/3000 [04:43<1:05:16,  1.35s/step]Training:   3%|▎         | 93/3000 [04:44<1:05:14,  1.35s/step]Training:   3%|▎         | 94/3000 [04:45<1:05:13,  1.35s/step]Training:   3%|▎         | 95/3000 [04:47<1:05:12,  1.35s/step]Training:   3%|▎         | 96/3000 [04:48<1:05:10,  1.35s/step]Training:   3%|▎         | 97/3000 [04:49<1:05:09,  1.35s/step]Training:   3%|▎         | 98/3000 [04:51<1:05:08,  1.35s/step]Training:   3%|▎         | 99/3000 [04:52<1:05:07,  1.35s/step]Training:   3%|▎         | 100/3000 [04:53<1:05:07,  1.35s/step]11:14:02 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.1711 lr=2.020e-04
11:14:02 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.2258 lr=2.020e-04
11:14:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.1912 lr=2.020e-04
11:14:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.1634 lr=2.020e-04
11:14:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.1953 lr=2.020e-04
11:14:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.2139 lr=2.020e-04
11:14:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.1582 lr=2.020e-04
11:14:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=100 loss=0.1657 lr=2.020e-04
Training:   3%|▎         | 101/3000 [04:55<1:05:05,  1.35s/step]Training:   3%|▎         | 102/3000 [04:56<1:05:03,  1.35s/step]Training:   3%|▎         | 103/3000 [04:57<1:05:03,  1.35s/step]Training:   3%|▎         | 104/3000 [04:59<1:05:02,  1.35s/step]Training:   4%|▎         | 105/3000 [05:00<1:05:01,  1.35s/step]Training:   4%|▎         | 106/3000 [05:01<1:04:58,  1.35s/step]Training:   4%|▎         | 107/3000 [05:03<1:04:57,  1.35s/step]Training:   4%|▎         | 108/3000 [05:04<1:04:54,  1.35s/step]Training:   4%|▎         | 109/3000 [05:05<1:04:53,  1.35s/step]Training:   4%|▎         | 110/3000 [05:07<1:04:51,  1.35s/step]Training:   4%|▎         | 111/3000 [05:08<1:04:50,  1.35s/step]Training:   4%|▎         | 112/3000 [05:10<1:04:48,  1.35s/step]Training:   4%|▍         | 113/3000 [05:11<1:04:47,  1.35s/step]Training:   4%|▍         | 114/3000 [05:12<1:04:46,  1.35s/step]Training:   4%|▍         | 115/3000 [05:14<1:04:45,  1.35s/step]Training:   4%|▍         | 116/3000 [05:15<1:04:44,  1.35s/step]Training:   4%|▍         | 117/3000 [05:16<1:04:42,  1.35s/step]Training:   4%|▍         | 118/3000 [05:18<1:04:41,  1.35s/step]Training:   4%|▍         | 119/3000 [05:19<1:04:40,  1.35s/step]Training:   4%|▍         | 120/3000 [05:20<1:04:38,  1.35s/step]Training:   4%|▍         | 121/3000 [05:22<1:04:37,  1.35s/step]Training:   4%|▍         | 122/3000 [05:23<1:04:36,  1.35s/step]Training:   4%|▍         | 123/3000 [05:24<1:04:35,  1.35s/step]Training:   4%|▍         | 124/3000 [05:26<1:04:33,  1.35s/step]Training:   4%|▍         | 125/3000 [05:27<1:04:32,  1.35s/step]Training:   4%|▍         | 126/3000 [05:28<1:04:32,  1.35s/step]Training:   4%|▍         | 127/3000 [05:30<1:04:29,  1.35s/step]Training:   4%|▍         | 128/3000 [05:31<1:04:28,  1.35s/step]Training:   4%|▍         | 129/3000 [05:32<1:04:26,  1.35s/step]Training:   4%|▍         | 130/3000 [05:34<1:04:24,  1.35s/step]Training:   4%|▍         | 131/3000 [05:35<1:04:23,  1.35s/step]Training:   4%|▍         | 132/3000 [05:36<1:04:22,  1.35s/step]Training:   4%|▍         | 133/3000 [05:38<1:04:21,  1.35s/step]Training:   4%|▍         | 134/3000 [05:39<1:04:19,  1.35s/step]Training:   4%|▍         | 135/3000 [05:40<1:04:18,  1.35s/step]Training:   5%|▍         | 136/3000 [05:42<1:04:17,  1.35s/step]Training:   5%|▍         | 137/3000 [05:43<1:04:17,  1.35s/step]Training:   5%|▍         | 138/3000 [05:45<1:04:14,  1.35s/step]Training:   5%|▍         | 139/3000 [05:46<1:04:13,  1.35s/step]Training:   5%|▍         | 140/3000 [05:47<1:04:12,  1.35s/step]Training:   5%|▍         | 141/3000 [05:49<1:04:10,  1.35s/step]Training:   5%|▍         | 142/3000 [05:50<1:04:08,  1.35s/step]Training:   5%|▍         | 143/3000 [05:51<1:04:07,  1.35s/step]Training:   5%|▍         | 144/3000 [05:53<1:04:06,  1.35s/step]Training:   5%|▍         | 145/3000 [05:54<1:04:05,  1.35s/step]Training:   5%|▍         | 146/3000 [05:55<1:04:03,  1.35s/step]Training:   5%|▍         | 147/3000 [05:57<1:04:02,  1.35s/step]Training:   5%|▍         | 148/3000 [05:58<1:04:00,  1.35s/step]Training:   5%|▍         | 149/3000 [05:59<1:04:00,  1.35s/step]Training:   5%|▌         | 150/3000 [06:01<1:03:58,  1.35s/step]11:15:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.2585 lr=3.000e-04
11:15:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.1513 lr=3.000e-04
11:15:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.1090 lr=3.000e-04
11:15:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.1733 lr=3.000e-04
11:15:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.1521 lr=3.000e-04
11:15:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.1349 lr=3.000e-04
11:15:11 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.1674 lr=3.000e-04
11:15:11 - trainer.gpt2-gsm8k-lora-main - INFO - step=150 loss=0.2510 lr=3.000e-04
Training:   5%|▌         | 151/3000 [06:02<1:03:57,  1.35s/step]Training:   5%|▌         | 152/3000 [06:03<1:03:56,  1.35s/step]Training:   5%|▌         | 153/3000 [06:05<1:03:54,  1.35s/step]Training:   5%|▌         | 154/3000 [06:06<1:03:52,  1.35s/step]Training:   5%|▌         | 155/3000 [06:07<1:03:51,  1.35s/step]Training:   5%|▌         | 156/3000 [06:09<1:03:49,  1.35s/step]Training:   5%|▌         | 157/3000 [06:10<1:03:48,  1.35s/step]Training:   5%|▌         | 158/3000 [06:11<1:03:48,  1.35s/step]Training:   5%|▌         | 159/3000 [06:13<1:03:47,  1.35s/step]Training:   5%|▌         | 160/3000 [06:14<1:03:45,  1.35s/step]Training:   5%|▌         | 161/3000 [06:16<1:03:43,  1.35s/step]Training:   5%|▌         | 162/3000 [06:17<1:03:42,  1.35s/step]Training:   5%|▌         | 163/3000 [06:18<1:03:41,  1.35s/step]Training:   5%|▌         | 164/3000 [06:20<1:03:39,  1.35s/step]Training:   6%|▌         | 165/3000 [06:21<1:03:37,  1.35s/step]Training:   6%|▌         | 166/3000 [06:22<1:03:36,  1.35s/step]Training:   6%|▌         | 167/3000 [06:24<1:03:34,  1.35s/step]Training:   6%|▌         | 168/3000 [06:25<1:03:33,  1.35s/step]Training:   6%|▌         | 169/3000 [06:26<1:03:32,  1.35s/step]Training:   6%|▌         | 170/3000 [06:28<1:03:32,  1.35s/step]Training:   6%|▌         | 171/3000 [06:29<1:03:30,  1.35s/step]Training:   6%|▌         | 172/3000 [06:30<1:03:28,  1.35s/step]Training:   6%|▌         | 173/3000 [06:32<1:03:27,  1.35s/step]Training:   6%|▌         | 174/3000 [06:33<1:03:26,  1.35s/step]Training:   6%|▌         | 175/3000 [06:34<1:03:24,  1.35s/step]Training:   6%|▌         | 176/3000 [06:36<1:03:23,  1.35s/step]Training:   6%|▌         | 177/3000 [06:37<1:03:21,  1.35s/step]Training:   6%|▌         | 178/3000 [06:38<1:03:21,  1.35s/step]Training:   6%|▌         | 179/3000 [06:40<1:03:20,  1.35s/step]Training:   6%|▌         | 180/3000 [06:41<1:03:18,  1.35s/step]Training:   6%|▌         | 181/3000 [06:42<1:03:17,  1.35s/step]Training:   6%|▌         | 182/3000 [06:44<1:03:15,  1.35s/step]Training:   6%|▌         | 183/3000 [06:45<1:03:14,  1.35s/step]Training:   6%|▌         | 184/3000 [06:46<1:03:13,  1.35s/step]Training:   6%|▌         | 185/3000 [06:48<1:03:11,  1.35s/step]Training:   6%|▌         | 186/3000 [06:49<1:03:10,  1.35s/step]Training:   6%|▌         | 187/3000 [06:51<1:03:08,  1.35s/step]Training:   6%|▋         | 188/3000 [06:52<1:03:07,  1.35s/step]Training:   6%|▋         | 189/3000 [06:53<1:03:11,  1.35s/step]Training:   6%|▋         | 190/3000 [06:55<1:03:08,  1.35s/step]Training:   6%|▋         | 191/3000 [06:56<1:03:05,  1.35s/step]Training:   6%|▋         | 192/3000 [06:57<1:03:03,  1.35s/step]Training:   6%|▋         | 193/3000 [06:59<1:03:01,  1.35s/step]Training:   6%|▋         | 194/3000 [07:00<1:03:02,  1.35s/step]Training:   6%|▋         | 195/3000 [07:01<1:03:00,  1.35s/step]Training:   7%|▋         | 196/3000 [07:03<1:02:59,  1.35s/step]Training:   7%|▋         | 197/3000 [07:04<1:02:57,  1.35s/step]Training:   7%|▋         | 198/3000 [07:05<1:02:55,  1.35s/step]Training:   7%|▋         | 199/3000 [07:07<1:02:53,  1.35s/step]Training:   7%|▋         | 200/3000 [07:08<1:02:54,  1.35s/step]11:16:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1657 lr=3.000e-04
11:16:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1935 lr=3.000e-04
11:16:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1345 lr=3.000e-04
11:16:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1670 lr=3.000e-04
11:16:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1852 lr=3.000e-04
11:16:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1657 lr=3.000e-04
11:16:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.2197 lr=3.000e-04
11:16:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=200 loss=0.1956 lr=3.000e-04
Training:   7%|▋         | 201/3000 [07:09<1:02:52,  1.35s/step]Training:   7%|▋         | 202/3000 [07:11<1:02:50,  1.35s/step]Training:   7%|▋         | 203/3000 [07:12<1:02:48,  1.35s/step]Training:   7%|▋         | 204/3000 [07:13<1:02:47,  1.35s/step]Training:   7%|▋         | 205/3000 [07:15<1:02:45,  1.35s/step]Training:   7%|▋         | 206/3000 [07:16<1:02:43,  1.35s/step]Training:   7%|▋         | 207/3000 [07:17<1:02:41,  1.35s/step]Training:   7%|▋         | 208/3000 [07:19<1:02:40,  1.35s/step]Training:   7%|▋         | 209/3000 [07:20<1:02:38,  1.35s/step]Training:   7%|▋         | 210/3000 [07:22<1:02:37,  1.35s/step]Training:   7%|▋         | 211/3000 [07:23<1:02:36,  1.35s/step]Training:   7%|▋         | 212/3000 [07:24<1:02:34,  1.35s/step]Training:   7%|▋         | 213/3000 [07:26<1:02:36,  1.35s/step]Training:   7%|▋         | 214/3000 [07:27<1:02:34,  1.35s/step]Training:   7%|▋         | 215/3000 [07:28<1:02:33,  1.35s/step]Training:   7%|▋         | 216/3000 [07:30<1:02:31,  1.35s/step]Training:   7%|▋         | 217/3000 [07:31<1:02:29,  1.35s/step]Training:   7%|▋         | 218/3000 [07:32<1:02:27,  1.35s/step]Training:   7%|▋         | 219/3000 [07:34<1:02:26,  1.35s/step]Training:   7%|▋         | 220/3000 [07:35<1:02:24,  1.35s/step]Training:   7%|▋         | 221/3000 [07:36<1:02:23,  1.35s/step]Training:   7%|▋         | 222/3000 [07:38<1:02:22,  1.35s/step]Training:   7%|▋         | 223/3000 [07:39<1:02:21,  1.35s/step]Training:   7%|▋         | 224/3000 [07:40<1:02:19,  1.35s/step]Training:   8%|▊         | 225/3000 [07:42<1:02:17,  1.35s/step]Training:   8%|▊         | 226/3000 [07:43<1:02:15,  1.35s/step]Training:   8%|▊         | 227/3000 [07:44<1:02:14,  1.35s/step]Training:   8%|▊         | 228/3000 [07:46<1:02:13,  1.35s/step]Training:   8%|▊         | 229/3000 [07:47<1:02:11,  1.35s/step]Training:   8%|▊         | 230/3000 [07:48<1:02:10,  1.35s/step]Training:   8%|▊         | 231/3000 [07:50<1:02:09,  1.35s/step]Training:   8%|▊         | 232/3000 [07:51<1:02:08,  1.35s/step]Training:   8%|▊         | 233/3000 [07:53<1:02:06,  1.35s/step]Training:   8%|▊         | 234/3000 [07:54<1:02:05,  1.35s/step]Training:   8%|▊         | 235/3000 [07:55<1:02:04,  1.35s/step]Training:   8%|▊         | 236/3000 [07:57<1:02:03,  1.35s/step]Training:   8%|▊         | 237/3000 [07:58<1:02:02,  1.35s/step]Training:   8%|▊         | 238/3000 [07:59<1:02:02,  1.35s/step]Training:   8%|▊         | 239/3000 [08:01<1:02:00,  1.35s/step]Training:   8%|▊         | 240/3000 [08:02<1:01:58,  1.35s/step]Training:   8%|▊         | 241/3000 [08:03<1:01:57,  1.35s/step]Training:   8%|▊         | 242/3000 [08:05<1:01:55,  1.35s/step]Training:   8%|▊         | 243/3000 [08:06<1:01:55,  1.35s/step]Training:   8%|▊         | 244/3000 [08:07<1:01:52,  1.35s/step]Training:   8%|▊         | 245/3000 [08:09<1:01:50,  1.35s/step]Training:   8%|▊         | 246/3000 [08:10<1:01:49,  1.35s/step]Training:   8%|▊         | 247/3000 [08:11<1:01:47,  1.35s/step]Training:   8%|▊         | 248/3000 [08:13<1:01:46,  1.35s/step]Training:   8%|▊         | 249/3000 [08:14<1:01:44,  1.35s/step]Training:   8%|▊         | 250/3000 [08:15<1:01:43,  1.35s/step]11:17:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1322 lr=3.000e-04
11:17:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.0964 lr=3.000e-04
11:17:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1437 lr=3.000e-04
11:17:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1359 lr=3.000e-04
11:17:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1432 lr=3.000e-04
11:17:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1551 lr=3.000e-04
11:17:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1131 lr=3.000e-04
11:17:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=250 loss=0.1071 lr=3.000e-04
Training:   8%|▊         | 251/3000 [08:17<1:01:42,  1.35s/step]Training:   8%|▊         | 252/3000 [08:18<1:01:40,  1.35s/step]Training:   8%|▊         | 253/3000 [08:19<1:01:38,  1.35s/step]Training:   8%|▊         | 254/3000 [08:21<1:01:37,  1.35s/step]Training:   8%|▊         | 255/3000 [08:22<1:01:36,  1.35s/step]Training:   9%|▊         | 256/3000 [08:23<1:01:35,  1.35s/step]Training:   9%|▊         | 257/3000 [08:25<1:01:34,  1.35s/step]Training:   9%|▊         | 258/3000 [08:26<1:01:33,  1.35s/step]Training:   9%|▊         | 259/3000 [08:28<1:01:32,  1.35s/step]Training:   9%|▊         | 260/3000 [08:29<1:01:32,  1.35s/step]Training:   9%|▊         | 261/3000 [08:30<1:01:30,  1.35s/step]Training:   9%|▊         | 262/3000 [08:32<1:01:28,  1.35s/step]Training:   9%|▉         | 263/3000 [08:33<1:01:28,  1.35s/step]Training:   9%|▉         | 264/3000 [08:34<1:01:27,  1.35s/step]Training:   9%|▉         | 265/3000 [08:36<1:01:25,  1.35s/step]Training:   9%|▉         | 266/3000 [08:37<1:01:23,  1.35s/step]Training:   9%|▉         | 267/3000 [08:38<1:01:21,  1.35s/step]Training:   9%|▉         | 268/3000 [08:40<1:01:19,  1.35s/step]Training:   9%|▉         | 269/3000 [08:41<1:01:18,  1.35s/step]Training:   9%|▉         | 270/3000 [08:42<1:01:17,  1.35s/step]Training:   9%|▉         | 271/3000 [08:44<1:01:15,  1.35s/step]Training:   9%|▉         | 272/3000 [08:45<1:01:14,  1.35s/step]Training:   9%|▉         | 273/3000 [08:46<1:01:12,  1.35s/step]Training:   9%|▉         | 274/3000 [08:48<1:01:11,  1.35s/step]Training:   9%|▉         | 275/3000 [08:49<1:01:10,  1.35s/step]Training:   9%|▉         | 276/3000 [08:50<1:01:08,  1.35s/step]Training:   9%|▉         | 277/3000 [08:52<1:01:07,  1.35s/step]Training:   9%|▉         | 278/3000 [08:53<1:01:05,  1.35s/step]Training:   9%|▉         | 279/3000 [08:54<1:01:05,  1.35s/step]Training:   9%|▉         | 280/3000 [08:56<1:01:04,  1.35s/step]Training:   9%|▉         | 281/3000 [08:57<1:01:02,  1.35s/step]Training:   9%|▉         | 282/3000 [08:59<1:01:01,  1.35s/step]Training:   9%|▉         | 283/3000 [09:00<1:01:01,  1.35s/step]Training:   9%|▉         | 284/3000 [09:01<1:00:59,  1.35s/step]Training:  10%|▉         | 285/3000 [09:03<1:00:58,  1.35s/step]Training:  10%|▉         | 286/3000 [09:04<1:00:55,  1.35s/step]Training:  10%|▉         | 287/3000 [09:05<1:00:54,  1.35s/step]Training:  10%|▉         | 288/3000 [09:07<1:00:52,  1.35s/step]Training:  10%|▉         | 289/3000 [09:08<1:00:50,  1.35s/step]Training:  10%|▉         | 290/3000 [09:09<1:00:49,  1.35s/step]Training:  10%|▉         | 291/3000 [09:11<1:00:47,  1.35s/step]Training:  10%|▉         | 292/3000 [09:12<1:00:46,  1.35s/step]Training:  10%|▉         | 293/3000 [09:13<1:00:45,  1.35s/step]Training:  10%|▉         | 294/3000 [09:15<1:00:43,  1.35s/step]Training:  10%|▉         | 295/3000 [09:16<1:00:42,  1.35s/step]Training:  10%|▉         | 296/3000 [09:17<1:00:41,  1.35s/step]Training:  10%|▉         | 297/3000 [09:19<1:00:39,  1.35s/step]Training:  10%|▉         | 298/3000 [09:20<1:00:38,  1.35s/step]Training:  10%|▉         | 299/3000 [09:21<1:00:37,  1.35s/step]Training:  10%|█         | 300/3000 [09:23<1:00:35,  1.35s/step]11:18:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.2098 lr=3.000e-04
11:18:54 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:18:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1407 lr=3.000e-04
11:19:16 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:19:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1008 lr=3.000e-04
11:19:38 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:19:39 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1444 lr=3.000e-04
11:20:01 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:20:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1221 lr=3.000e-04
11:20:23 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:20:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1451 lr=3.000e-04
11:20:45 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:20:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1278 lr=3.000e-04
11:21:08 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
11:21:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=300 loss=0.1099 lr=3.000e-04
11:21:30 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=300 loss=1.1958 ppl=3.31
Training:  10%|█         | 301/3000 [12:21<40:50:49, 54.48s/step]Training:  10%|█         | 302/3000 [12:23<28:53:10, 38.54s/step]Training:  10%|█         | 303/3000 [12:24<20:30:56, 27.38s/step]Training:  10%|█         | 304/3000 [12:25<14:39:31, 19.57s/step]Training:  10%|█         | 305/3000 [12:27<10:33:36, 14.11s/step]Training:  10%|█         | 306/3000 [12:28<7:41:30, 10.28s/step] Training:  10%|█         | 307/3000 [12:29<5:41:04,  7.60s/step]Training:  10%|█         | 308/3000 [12:31<4:16:47,  5.72s/step]Training:  10%|█         | 309/3000 [12:32<3:17:48,  4.41s/step]Training:  10%|█         | 310/3000 [12:33<2:36:31,  3.49s/step]Training:  10%|█         | 311/3000 [12:35<2:07:38,  2.85s/step]Training:  10%|█         | 312/3000 [12:36<1:47:24,  2.40s/step]Training:  10%|█         | 313/3000 [12:37<1:33:15,  2.08s/step]Training:  10%|█         | 314/3000 [12:39<1:23:20,  1.86s/step]Training:  10%|█         | 315/3000 [12:40<1:16:23,  1.71s/step]Training:  11%|█         | 316/3000 [12:41<1:11:31,  1.60s/step]Training:  11%|█         | 317/3000 [12:43<1:08:07,  1.52s/step]Training:  11%|█         | 318/3000 [12:44<1:05:43,  1.47s/step]Training:  11%|█         | 319/3000 [12:45<1:04:04,  1.43s/step]Training:  11%|█         | 320/3000 [12:47<1:02:52,  1.41s/step]Training:  11%|█         | 321/3000 [12:48<1:02:02,  1.39s/step]Training:  11%|█         | 322/3000 [12:50<1:01:26,  1.38s/step]Training:  11%|█         | 323/3000 [12:51<1:01:01,  1.37s/step]Training:  11%|█         | 324/3000 [12:52<1:00:43,  1.36s/step]Training:  11%|█         | 325/3000 [12:54<1:00:30,  1.36s/step]Training:  11%|█         | 326/3000 [12:55<1:00:20,  1.35s/step]Training:  11%|█         | 327/3000 [12:56<1:00:13,  1.35s/step]Training:  11%|█         | 328/3000 [12:58<1:00:07,  1.35s/step]Training:  11%|█         | 329/3000 [12:59<1:00:04,  1.35s/step]Training:  11%|█         | 330/3000 [13:00<1:00:00,  1.35s/step]Training:  11%|█         | 331/3000 [13:02<59:57,  1.35s/step]  Training:  11%|█         | 332/3000 [13:03<59:54,  1.35s/step]Training:  11%|█         | 333/3000 [13:04<59:52,  1.35s/step]Training:  11%|█         | 334/3000 [13:06<59:50,  1.35s/step]Training:  11%|█         | 335/3000 [13:07<59:49,  1.35s/step]Training:  11%|█         | 336/3000 [13:08<59:48,  1.35s/step]Training:  11%|█         | 337/3000 [13:10<59:46,  1.35s/step]Training:  11%|█▏        | 338/3000 [13:11<59:44,  1.35s/step]Training:  11%|█▏        | 339/3000 [13:12<59:43,  1.35s/step]Training:  11%|█▏        | 340/3000 [13:14<59:43,  1.35s/step]Training:  11%|█▏        | 341/3000 [13:15<59:41,  1.35s/step]Training:  11%|█▏        | 342/3000 [13:16<59:39,  1.35s/step]Training:  11%|█▏        | 343/3000 [13:18<59:38,  1.35s/step]Training:  11%|█▏        | 344/3000 [13:19<59:37,  1.35s/step]Training:  12%|█▏        | 345/3000 [13:20<59:35,  1.35s/step]Training:  12%|█▏        | 346/3000 [13:22<59:34,  1.35s/step]Training:  12%|█▏        | 347/3000 [13:23<59:35,  1.35s/step]Training:  12%|█▏        | 348/3000 [13:25<59:33,  1.35s/step]Training:  12%|█▏        | 349/3000 [13:26<59:30,  1.35s/step]Training:  12%|█▏        | 350/3000 [13:27<59:30,  1.35s/step]11:22:36 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1482 lr=3.000e-04
11:22:36 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1311 lr=3.000e-04
11:22:36 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1477 lr=3.000e-04
11:22:37 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1711 lr=3.000e-04
11:22:37 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1474 lr=3.000e-04
11:22:37 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1485 lr=3.000e-04
11:22:37 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1790 lr=3.000e-04
11:22:37 - trainer.gpt2-gsm8k-lora-main - INFO - step=350 loss=0.1135 lr=3.000e-04
Training:  12%|█▏        | 351/3000 [13:29<59:30,  1.35s/step]Training:  12%|█▏        | 352/3000 [13:30<59:28,  1.35s/step]Training:  12%|█▏        | 353/3000 [13:31<59:26,  1.35s/step]Training:  12%|█▏        | 354/3000 [13:33<59:23,  1.35s/step]Training:  12%|█▏        | 355/3000 [13:34<59:22,  1.35s/step]Training:  12%|█▏        | 356/3000 [13:35<59:21,  1.35s/step]Training:  12%|█▏        | 357/3000 [13:37<59:20,  1.35s/step]Training:  12%|█▏        | 358/3000 [13:38<59:19,  1.35s/step]Training:  12%|█▏        | 359/3000 [13:39<59:17,  1.35s/step]Training:  12%|█▏        | 360/3000 [13:41<59:15,  1.35s/step]Training:  12%|█▏        | 361/3000 [13:42<59:14,  1.35s/step]Training:  12%|█▏        | 362/3000 [13:43<59:13,  1.35s/step]Training:  12%|█▏        | 363/3000 [13:45<59:11,  1.35s/step]Training:  12%|█▏        | 364/3000 [13:46<59:09,  1.35s/step]Training:  12%|█▏        | 365/3000 [13:47<59:08,  1.35s/step]Training:  12%|█▏        | 366/3000 [13:49<59:07,  1.35s/step]Training:  12%|█▏        | 367/3000 [13:50<59:05,  1.35s/step]Training:  12%|█▏        | 368/3000 [13:51<59:05,  1.35s/step]Training:  12%|█▏        | 369/3000 [13:53<59:04,  1.35s/step]Training:  12%|█▏        | 370/3000 [13:54<59:04,  1.35s/step]Training:  12%|█▏        | 371/3000 [13:56<59:03,  1.35s/step]Training:  12%|█▏        | 372/3000 [13:57<59:01,  1.35s/step]Training:  12%|█▏        | 373/3000 [13:58<58:59,  1.35s/step]Training:  12%|█▏        | 374/3000 [14:00<58:58,  1.35s/step]Training:  12%|█▎        | 375/3000 [14:01<58:56,  1.35s/step]Training:  13%|█▎        | 376/3000 [14:02<58:55,  1.35s/step]Training:  13%|█▎        | 377/3000 [14:04<58:53,  1.35s/step]Training:  13%|█▎        | 378/3000 [14:05<58:51,  1.35s/step]Training:  13%|█▎        | 379/3000 [14:06<58:49,  1.35s/step]Training:  13%|█▎        | 380/3000 [14:08<58:48,  1.35s/step]Training:  13%|█▎        | 381/3000 [14:09<58:47,  1.35s/step]Training:  13%|█▎        | 382/3000 [14:10<58:46,  1.35s/step]Training:  13%|█▎        | 383/3000 [14:12<58:45,  1.35s/step]Training:  13%|█▎        | 384/3000 [14:13<58:43,  1.35s/step]Training:  13%|█▎        | 385/3000 [14:14<58:42,  1.35s/step]Training:  13%|█▎        | 386/3000 [14:16<58:40,  1.35s/step]Training:  13%|█▎        | 387/3000 [14:17<58:38,  1.35s/step]Training:  13%|█▎        | 388/3000 [14:18<58:37,  1.35s/step]Training:  13%|█▎        | 389/3000 [14:20<58:36,  1.35s/step]Training:  13%|█▎        | 390/3000 [14:21<58:34,  1.35s/step]Training:  13%|█▎        | 391/3000 [14:22<58:33,  1.35s/step]Training:  13%|█▎        | 392/3000 [14:24<58:32,  1.35s/step]Training:  13%|█▎        | 393/3000 [14:25<58:30,  1.35s/step]Training:  13%|█▎        | 394/3000 [14:26<58:29,  1.35s/step]Training:  13%|█▎        | 395/3000 [14:28<58:29,  1.35s/step]Training:  13%|█▎        | 396/3000 [14:29<58:28,  1.35s/step]Training:  13%|█▎        | 397/3000 [14:31<58:26,  1.35s/step]Training:  13%|█▎        | 398/3000 [14:32<58:24,  1.35s/step]Training:  13%|█▎        | 399/3000 [14:33<58:22,  1.35s/step]Training:  13%|█▎        | 400/3000 [14:35<58:22,  1.35s/step]11:23:43 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.1120 lr=3.000e-04
11:23:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.2009 lr=3.000e-04
11:23:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.1074 lr=3.000e-04
11:23:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.2126 lr=3.000e-04
11:23:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.1060 lr=3.000e-04
11:23:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.1770 lr=3.000e-04
11:23:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.2031 lr=3.000e-04
11:23:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=400 loss=0.1796 lr=3.000e-04
Training:  13%|█▎        | 401/3000 [14:36<58:21,  1.35s/step]Training:  13%|█▎        | 402/3000 [14:37<58:19,  1.35s/step]Training:  13%|█▎        | 403/3000 [14:39<58:19,  1.35s/step]Training:  13%|█▎        | 404/3000 [14:40<58:17,  1.35s/step]Training:  14%|█▎        | 405/3000 [14:41<58:15,  1.35s/step]Training:  14%|█▎        | 406/3000 [14:43<58:14,  1.35s/step]Training:  14%|█▎        | 407/3000 [14:44<58:13,  1.35s/step]Training:  14%|█▎        | 408/3000 [14:45<58:11,  1.35s/step]Training:  14%|█▎        | 409/3000 [14:47<58:09,  1.35s/step]Training:  14%|█▎        | 410/3000 [14:48<58:08,  1.35s/step]Training:  14%|█▎        | 411/3000 [14:49<58:07,  1.35s/step]Training:  14%|█▎        | 412/3000 [14:51<58:05,  1.35s/step]Training:  14%|█▍        | 413/3000 [14:52<58:03,  1.35s/step]Training:  14%|█▍        | 414/3000 [14:53<58:02,  1.35s/step]Training:  14%|█▍        | 415/3000 [14:55<58:00,  1.35s/step]Training:  14%|█▍        | 416/3000 [14:56<57:59,  1.35s/step]Training:  14%|█▍        | 417/3000 [14:57<57:57,  1.35s/step]Training:  14%|█▍        | 418/3000 [14:59<57:57,  1.35s/step]Training:  14%|█▍        | 419/3000 [15:00<57:57,  1.35s/step]Training:  14%|█▍        | 420/3000 [15:02<57:56,  1.35s/step]Training:  14%|█▍        | 421/3000 [15:03<57:54,  1.35s/step]Training:  14%|█▍        | 422/3000 [15:04<57:52,  1.35s/step]Training:  14%|█▍        | 423/3000 [15:06<57:51,  1.35s/step]Training:  14%|█▍        | 424/3000 [15:07<57:50,  1.35s/step]Training:  14%|█▍        | 425/3000 [15:08<57:49,  1.35s/step]Training:  14%|█▍        | 426/3000 [15:10<57:47,  1.35s/step]Training:  14%|█▍        | 427/3000 [15:11<57:45,  1.35s/step]Training:  14%|█▍        | 428/3000 [15:12<57:44,  1.35s/step]Training:  14%|█▍        | 429/3000 [15:14<57:42,  1.35s/step]Training:  14%|█▍        | 430/3000 [15:15<57:41,  1.35s/step]Training:  14%|█▍        | 431/3000 [15:16<57:42,  1.35s/step]Training:  14%|█▍        | 432/3000 [15:18<57:40,  1.35s/step]Training:  14%|█▍        | 433/3000 [15:19<57:38,  1.35s/step]Training:  14%|█▍        | 434/3000 [15:20<57:37,  1.35s/step]Training:  14%|█▍        | 435/3000 [15:22<57:35,  1.35s/step]Training:  15%|█▍        | 436/3000 [15:23<57:34,  1.35s/step]Training:  15%|█▍        | 437/3000 [15:24<57:32,  1.35s/step]Training:  15%|█▍        | 438/3000 [15:26<57:30,  1.35s/step]Training:  15%|█▍        | 439/3000 [15:27<57:29,  1.35s/step]Training:  15%|█▍        | 440/3000 [15:28<57:28,  1.35s/step]Training:  15%|█▍        | 441/3000 [15:30<57:27,  1.35s/step]Training:  15%|█▍        | 442/3000 [15:31<57:25,  1.35s/step]Training:  15%|█▍        | 443/3000 [15:32<57:24,  1.35s/step]Training:  15%|█▍        | 444/3000 [15:34<57:22,  1.35s/step]Training:  15%|█▍        | 445/3000 [15:35<57:21,  1.35s/step]Training:  15%|█▍        | 446/3000 [15:37<57:19,  1.35s/step]Training:  15%|█▍        | 447/3000 [15:38<57:17,  1.35s/step]Training:  15%|█▍        | 448/3000 [15:39<57:16,  1.35s/step]Training:  15%|█▍        | 449/3000 [15:41<57:15,  1.35s/step]Training:  15%|█▌        | 450/3000 [15:42<57:13,  1.35s/step]11:24:51 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.2080 lr=3.000e-04
11:24:51 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.1577 lr=3.000e-04
11:24:51 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.1849 lr=3.000e-04
11:24:51 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.2052 lr=3.000e-04
11:24:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.1184 lr=3.000e-04
11:24:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.1987 lr=3.000e-04
11:24:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.1334 lr=3.000e-04
11:24:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=450 loss=0.1378 lr=3.000e-04
Training:  15%|█▌        | 451/3000 [15:43<57:12,  1.35s/step]Training:  15%|█▌        | 452/3000 [15:45<57:11,  1.35s/step]Training:  15%|█▌        | 453/3000 [15:46<57:09,  1.35s/step]Training:  15%|█▌        | 454/3000 [15:47<57:08,  1.35s/step]Training:  15%|█▌        | 455/3000 [15:49<57:06,  1.35s/step]Training:  15%|█▌        | 456/3000 [15:50<57:05,  1.35s/step]Training:  15%|█▌        | 457/3000 [15:51<57:04,  1.35s/step]Training:  15%|█▌        | 458/3000 [15:53<57:03,  1.35s/step]Training:  15%|█▌        | 459/3000 [15:54<57:01,  1.35s/step]Training:  15%|█▌        | 460/3000 [15:55<57:00,  1.35s/step]Training:  15%|█▌        | 461/3000 [15:57<56:58,  1.35s/step]Training:  15%|█▌        | 462/3000 [15:58<56:57,  1.35s/step]Training:  15%|█▌        | 463/3000 [15:59<56:56,  1.35s/step]Training:  15%|█▌        | 464/3000 [16:01<56:55,  1.35s/step]Training:  16%|█▌        | 465/3000 [16:02<56:54,  1.35s/step]Training:  16%|█▌        | 466/3000 [16:03<56:53,  1.35s/step]Training:  16%|█▌        | 467/3000 [16:05<56:51,  1.35s/step]Training:  16%|█▌        | 468/3000 [16:06<56:49,  1.35s/step]Training:  16%|█▌        | 469/3000 [16:08<56:48,  1.35s/step]Training:  16%|█▌        | 470/3000 [16:09<56:47,  1.35s/step]Training:  16%|█▌        | 471/3000 [16:10<56:45,  1.35s/step]Training:  16%|█▌        | 472/3000 [16:12<56:44,  1.35s/step]Training:  16%|█▌        | 473/3000 [16:13<56:42,  1.35s/step]Training:  16%|█▌        | 474/3000 [16:14<56:41,  1.35s/step]Training:  16%|█▌        | 475/3000 [16:16<56:40,  1.35s/step]Training:  16%|█▌        | 476/3000 [16:17<56:38,  1.35s/step]Training:  16%|█▌        | 477/3000 [16:18<56:37,  1.35s/step]Training:  16%|█▌        | 478/3000 [16:20<56:36,  1.35s/step]Training:  16%|█▌        | 479/3000 [16:21<56:34,  1.35s/step]Training:  16%|█▌        | 480/3000 [16:22<56:33,  1.35s/step]Training:  16%|█▌        | 481/3000 [16:24<56:35,  1.35s/step]Training:  16%|█▌        | 482/3000 [16:25<56:33,  1.35s/step]Training:  16%|█▌        | 483/3000 [16:26<56:31,  1.35s/step]Training:  16%|█▌        | 484/3000 [16:28<56:30,  1.35s/step]Training:  16%|█▌        | 485/3000 [16:29<56:29,  1.35s/step]Training:  16%|█▌        | 486/3000 [16:30<56:28,  1.35s/step]Training:  16%|█▌        | 487/3000 [16:32<56:26,  1.35s/step]Training:  16%|█▋        | 488/3000 [16:33<56:25,  1.35s/step]Training:  16%|█▋        | 489/3000 [16:34<56:23,  1.35s/step]Training:  16%|█▋        | 490/3000 [16:36<56:21,  1.35s/step]Training:  16%|█▋        | 491/3000 [16:37<56:19,  1.35s/step]Training:  16%|█▋        | 492/3000 [16:38<56:17,  1.35s/step]Training:  16%|█▋        | 493/3000 [16:40<56:16,  1.35s/step]Training:  16%|█▋        | 494/3000 [16:41<56:15,  1.35s/step]Training:  16%|█▋        | 495/3000 [16:43<56:13,  1.35s/step]Training:  17%|█▋        | 496/3000 [16:44<56:12,  1.35s/step]Training:  17%|█▋        | 497/3000 [16:45<56:11,  1.35s/step]Training:  17%|█▋        | 498/3000 [16:47<56:09,  1.35s/step]Training:  17%|█▋        | 499/3000 [16:48<56:08,  1.35s/step]Training:  17%|█▋        | 500/3000 [16:49<56:06,  1.35s/step]11:25:58 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1251 lr=3.000e-04
11:25:58 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1340 lr=3.000e-04
11:25:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1338 lr=3.000e-04
11:25:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1842 lr=3.000e-04
11:25:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1540 lr=3.000e-04
11:25:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.2080 lr=3.000e-04
11:25:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1113 lr=3.000e-04
11:25:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=500 loss=0.1990 lr=3.000e-04
Training:  17%|█▋        | 501/3000 [16:51<56:06,  1.35s/step]Training:  17%|█▋        | 502/3000 [16:52<56:05,  1.35s/step]Training:  17%|█▋        | 503/3000 [16:53<56:05,  1.35s/step]Training:  17%|█▋        | 504/3000 [16:55<56:03,  1.35s/step]Training:  17%|█▋        | 505/3000 [16:56<56:01,  1.35s/step]Training:  17%|█▋        | 506/3000 [16:57<55:59,  1.35s/step]Training:  17%|█▋        | 507/3000 [16:59<55:59,  1.35s/step]Training:  17%|█▋        | 508/3000 [17:00<55:58,  1.35s/step]Training:  17%|█▋        | 509/3000 [17:01<55:56,  1.35s/step]Training:  17%|█▋        | 510/3000 [17:03<55:55,  1.35s/step]Training:  17%|█▋        | 511/3000 [17:04<55:52,  1.35s/step]Training:  17%|█▋        | 512/3000 [17:05<55:52,  1.35s/step]Training:  17%|█▋        | 513/3000 [17:07<55:50,  1.35s/step]Training:  17%|█▋        | 514/3000 [17:08<55:48,  1.35s/step]Training:  17%|█▋        | 515/3000 [17:09<55:47,  1.35s/step]Training:  17%|█▋        | 516/3000 [17:11<55:45,  1.35s/step]Training:  17%|█▋        | 517/3000 [17:12<55:43,  1.35s/step]Training:  17%|█▋        | 518/3000 [17:14<55:42,  1.35s/step]Training:  17%|█▋        | 519/3000 [17:15<55:41,  1.35s/step]Training:  17%|█▋        | 520/3000 [17:16<55:39,  1.35s/step]Training:  17%|█▋        | 521/3000 [17:18<55:38,  1.35s/step]Training:  17%|█▋        | 522/3000 [17:19<55:37,  1.35s/step]Training:  17%|█▋        | 523/3000 [17:20<55:35,  1.35s/step]Training:  17%|█▋        | 524/3000 [17:22<55:34,  1.35s/step]Training:  18%|█▊        | 525/3000 [17:23<55:33,  1.35s/step]Training:  18%|█▊        | 526/3000 [17:24<55:32,  1.35s/step]Training:  18%|█▊        | 527/3000 [17:26<55:32,  1.35s/step]Training:  18%|█▊        | 528/3000 [17:27<55:32,  1.35s/step]Training:  18%|█▊        | 529/3000 [17:28<55:30,  1.35s/step]Training:  18%|█▊        | 530/3000 [17:30<55:28,  1.35s/step]Training:  18%|█▊        | 531/3000 [17:31<55:26,  1.35s/step]Training:  18%|█▊        | 532/3000 [17:32<55:25,  1.35s/step]Training:  18%|█▊        | 533/3000 [17:34<55:25,  1.35s/step]Training:  18%|█▊        | 534/3000 [17:35<55:23,  1.35s/step]Training:  18%|█▊        | 535/3000 [17:36<55:20,  1.35s/step]Training:  18%|█▊        | 536/3000 [17:38<55:19,  1.35s/step]Training:  18%|█▊        | 537/3000 [17:39<55:17,  1.35s/step]Training:  18%|█▊        | 538/3000 [17:40<55:15,  1.35s/step]Training:  18%|█▊        | 539/3000 [17:42<55:14,  1.35s/step]Training:  18%|█▊        | 540/3000 [17:43<55:13,  1.35s/step]Training:  18%|█▊        | 541/3000 [17:44<55:12,  1.35s/step]Training:  18%|█▊        | 542/3000 [17:46<55:10,  1.35s/step]Training:  18%|█▊        | 543/3000 [17:47<55:09,  1.35s/step]Training:  18%|█▊        | 544/3000 [17:49<55:07,  1.35s/step]Training:  18%|█▊        | 545/3000 [17:50<55:06,  1.35s/step]Training:  18%|█▊        | 546/3000 [17:51<55:04,  1.35s/step]Training:  18%|█▊        | 547/3000 [17:53<55:06,  1.35s/step]Training:  18%|█▊        | 548/3000 [17:54<55:04,  1.35s/step]Training:  18%|█▊        | 549/3000 [17:55<55:03,  1.35s/step]Training:  18%|█▊        | 550/3000 [17:57<55:01,  1.35s/step]11:27:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.0830 lr=3.000e-04
11:27:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.1092 lr=3.000e-04
11:27:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.1079 lr=3.000e-04
11:27:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.2066 lr=3.000e-04
11:27:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.2154 lr=3.000e-04
11:27:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.1335 lr=3.000e-04
11:27:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.1337 lr=3.000e-04
11:27:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=550 loss=0.1661 lr=3.000e-04
Training:  18%|█▊        | 551/3000 [17:58<55:00,  1.35s/step]Training:  18%|█▊        | 552/3000 [17:59<55:00,  1.35s/step]Training:  18%|█▊        | 553/3000 [18:01<54:58,  1.35s/step]Training:  18%|█▊        | 554/3000 [18:02<54:56,  1.35s/step]Training:  18%|█▊        | 555/3000 [18:03<54:55,  1.35s/step]Training:  19%|█▊        | 556/3000 [18:05<54:53,  1.35s/step]Training:  19%|█▊        | 557/3000 [18:06<54:51,  1.35s/step]Training:  19%|█▊        | 558/3000 [18:07<54:49,  1.35s/step]Training:  19%|█▊        | 559/3000 [18:09<54:48,  1.35s/step]Training:  19%|█▊        | 560/3000 [18:10<54:46,  1.35s/step]Training:  19%|█▊        | 561/3000 [18:11<54:45,  1.35s/step]Training:  19%|█▊        | 562/3000 [18:13<54:43,  1.35s/step]Training:  19%|█▉        | 563/3000 [18:14<54:42,  1.35s/step]Training:  19%|█▉        | 564/3000 [18:15<54:40,  1.35s/step]Training:  19%|█▉        | 565/3000 [18:17<54:39,  1.35s/step]Training:  19%|█▉        | 566/3000 [18:18<54:39,  1.35s/step]Training:  19%|█▉        | 567/3000 [18:20<54:38,  1.35s/step]Training:  19%|█▉        | 568/3000 [18:21<54:36,  1.35s/step]Training:  19%|█▉        | 569/3000 [18:22<54:34,  1.35s/step]Training:  19%|█▉        | 570/3000 [18:24<54:34,  1.35s/step]Training:  19%|█▉        | 571/3000 [18:25<54:32,  1.35s/step]Training:  19%|█▉        | 572/3000 [18:26<54:30,  1.35s/step]Training:  19%|█▉        | 573/3000 [18:28<54:30,  1.35s/step]Training:  19%|█▉        | 574/3000 [18:29<54:28,  1.35s/step]Training:  19%|█▉        | 575/3000 [18:30<54:27,  1.35s/step]Training:  19%|█▉        | 576/3000 [18:32<54:25,  1.35s/step]Training:  19%|█▉        | 577/3000 [18:33<54:23,  1.35s/step]Training:  19%|█▉        | 578/3000 [18:34<54:22,  1.35s/step]Training:  19%|█▉        | 579/3000 [18:36<54:21,  1.35s/step]Training:  19%|█▉        | 580/3000 [18:37<54:19,  1.35s/step]Training:  19%|█▉        | 581/3000 [18:38<54:18,  1.35s/step]Training:  19%|█▉        | 582/3000 [18:40<54:19,  1.35s/step]Training:  19%|█▉        | 583/3000 [18:41<54:17,  1.35s/step]Training:  19%|█▉        | 584/3000 [18:42<54:15,  1.35s/step]Training:  20%|█▉        | 585/3000 [18:44<54:13,  1.35s/step]Training:  20%|█▉        | 586/3000 [18:45<54:11,  1.35s/step]Training:  20%|█▉        | 587/3000 [18:46<54:10,  1.35s/step]Training:  20%|█▉        | 588/3000 [18:48<54:08,  1.35s/step]Training:  20%|█▉        | 589/3000 [18:49<54:06,  1.35s/step]Training:  20%|█▉        | 590/3000 [18:51<54:05,  1.35s/step]Training:  20%|█▉        | 591/3000 [18:52<54:05,  1.35s/step]Training:  20%|█▉        | 592/3000 [18:53<54:03,  1.35s/step]Training:  20%|█▉        | 593/3000 [18:55<54:02,  1.35s/step]Training:  20%|█▉        | 594/3000 [18:56<54:00,  1.35s/step]Training:  20%|█▉        | 595/3000 [18:57<53:59,  1.35s/step]Training:  20%|█▉        | 596/3000 [18:59<53:57,  1.35s/step]Training:  20%|█▉        | 597/3000 [19:00<53:56,  1.35s/step]Training:  20%|█▉        | 598/3000 [19:01<53:55,  1.35s/step]Training:  20%|█▉        | 599/3000 [19:03<53:53,  1.35s/step]Training:  20%|██        | 600/3000 [19:04<53:52,  1.35s/step]11:28:13 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1295 lr=3.000e-04
11:28:35 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:28:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1625 lr=3.000e-04
11:28:57 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:28:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1376 lr=3.000e-04
11:29:20 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:29:20 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.0937 lr=3.000e-04
11:29:42 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:29:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1758 lr=3.000e-04
11:30:04 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:30:04 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1101 lr=3.000e-04
11:30:27 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:30:27 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1451 lr=3.000e-04
11:30:49 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
11:30:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=600 loss=0.1438 lr=3.000e-04
11:31:11 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=600 loss=1.1754 ppl=3.24
Training:  20%|██        | 601/3000 [22:02<36:18:26, 54.48s/step]Training:  20%|██        | 602/3000 [22:04<25:40:25, 38.54s/step]Training:  20%|██        | 603/3000 [22:05<18:13:58, 27.38s/step]Training:  20%|██        | 604/3000 [22:06<13:01:35, 19.57s/step]Training:  20%|██        | 605/3000 [22:08<9:23:00, 14.10s/step] Training:  20%|██        | 606/3000 [22:09<6:50:04, 10.28s/step]Training:  20%|██        | 607/3000 [22:11<5:03:02,  7.60s/step]Training:  20%|██        | 608/3000 [22:12<3:48:08,  5.72s/step]Training:  20%|██        | 609/3000 [22:13<2:55:43,  4.41s/step]Training:  20%|██        | 610/3000 [22:15<2:19:02,  3.49s/step]Training:  20%|██        | 611/3000 [22:16<1:53:21,  2.85s/step]Training:  20%|██        | 612/3000 [22:17<1:35:23,  2.40s/step]Training:  20%|██        | 613/3000 [22:19<1:22:50,  2.08s/step]Training:  20%|██        | 614/3000 [22:20<1:14:01,  1.86s/step]Training:  20%|██        | 615/3000 [22:21<1:07:51,  1.71s/step]Training:  21%|██        | 616/3000 [22:23<1:03:31,  1.60s/step]Training:  21%|██        | 617/3000 [22:24<1:00:29,  1.52s/step]Training:  21%|██        | 618/3000 [22:25<58:24,  1.47s/step]  Training:  21%|██        | 619/3000 [22:27<56:53,  1.43s/step]Training:  21%|██        | 620/3000 [22:28<55:50,  1.41s/step]Training:  21%|██        | 621/3000 [22:29<55:05,  1.39s/step]Training:  21%|██        | 622/3000 [22:31<54:33,  1.38s/step]Training:  21%|██        | 623/3000 [22:32<54:11,  1.37s/step]Training:  21%|██        | 624/3000 [22:33<53:54,  1.36s/step]Training:  21%|██        | 625/3000 [22:35<53:42,  1.36s/step]Training:  21%|██        | 626/3000 [22:36<53:33,  1.35s/step]Training:  21%|██        | 627/3000 [22:37<53:27,  1.35s/step]Training:  21%|██        | 628/3000 [22:39<53:22,  1.35s/step]Training:  21%|██        | 629/3000 [22:40<53:21,  1.35s/step]Training:  21%|██        | 630/3000 [22:42<53:17,  1.35s/step]Training:  21%|██        | 631/3000 [22:43<53:14,  1.35s/step]Training:  21%|██        | 632/3000 [22:44<53:12,  1.35s/step]Training:  21%|██        | 633/3000 [22:46<53:09,  1.35s/step]Training:  21%|██        | 634/3000 [22:47<53:07,  1.35s/step]Training:  21%|██        | 635/3000 [22:48<53:06,  1.35s/step]Training:  21%|██        | 636/3000 [22:50<53:04,  1.35s/step]Training:  21%|██        | 637/3000 [22:51<53:03,  1.35s/step]Training:  21%|██▏       | 638/3000 [22:52<53:01,  1.35s/step]Training:  21%|██▏       | 639/3000 [22:54<52:59,  1.35s/step]Training:  21%|██▏       | 640/3000 [22:55<52:58,  1.35s/step]Training:  21%|██▏       | 641/3000 [22:56<52:56,  1.35s/step]Training:  21%|██▏       | 642/3000 [22:58<52:55,  1.35s/step]Training:  21%|██▏       | 643/3000 [22:59<52:54,  1.35s/step]Training:  21%|██▏       | 644/3000 [23:00<52:53,  1.35s/step]Training:  22%|██▏       | 645/3000 [23:02<52:51,  1.35s/step]Training:  22%|██▏       | 646/3000 [23:03<52:49,  1.35s/step]Training:  22%|██▏       | 647/3000 [23:04<52:48,  1.35s/step]Training:  22%|██▏       | 648/3000 [23:06<52:47,  1.35s/step]Training:  22%|██▏       | 649/3000 [23:07<52:45,  1.35s/step]Training:  22%|██▏       | 650/3000 [23:08<52:44,  1.35s/step]11:32:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.2295 lr=3.000e-04
11:32:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.1059 lr=3.000e-04
11:32:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.1243 lr=3.000e-04
11:32:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.2173 lr=3.000e-04
11:32:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.1077 lr=3.000e-04
11:32:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.1816 lr=3.000e-04
11:32:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.1123 lr=3.000e-04
11:32:19 - trainer.gpt2-gsm8k-lora-main - INFO - step=650 loss=0.1247 lr=3.000e-04
Training:  22%|██▏       | 651/3000 [23:10<52:43,  1.35s/step]Training:  22%|██▏       | 652/3000 [23:11<52:41,  1.35s/step]Training:  22%|██▏       | 653/3000 [23:12<52:40,  1.35s/step]Training:  22%|██▏       | 654/3000 [23:14<52:38,  1.35s/step]Training:  22%|██▏       | 655/3000 [23:15<52:37,  1.35s/step]Training:  22%|██▏       | 656/3000 [23:17<52:36,  1.35s/step]Training:  22%|██▏       | 657/3000 [23:18<52:34,  1.35s/step]Training:  22%|██▏       | 658/3000 [23:19<52:33,  1.35s/step]Training:  22%|██▏       | 659/3000 [23:21<52:31,  1.35s/step]Training:  22%|██▏       | 660/3000 [23:22<52:31,  1.35s/step]Training:  22%|██▏       | 661/3000 [23:23<52:33,  1.35s/step]Training:  22%|██▏       | 662/3000 [23:25<52:31,  1.35s/step]Training:  22%|██▏       | 663/3000 [23:26<52:28,  1.35s/step]Training:  22%|██▏       | 664/3000 [23:27<52:27,  1.35s/step]Training:  22%|██▏       | 665/3000 [23:29<52:25,  1.35s/step]Training:  22%|██▏       | 666/3000 [23:30<52:24,  1.35s/step]Training:  22%|██▏       | 667/3000 [23:31<52:22,  1.35s/step]Training:  22%|██▏       | 668/3000 [23:33<52:21,  1.35s/step]Training:  22%|██▏       | 669/3000 [23:34<52:19,  1.35s/step]Training:  22%|██▏       | 670/3000 [23:35<52:17,  1.35s/step]Training:  22%|██▏       | 671/3000 [23:37<52:16,  1.35s/step]Training:  22%|██▏       | 672/3000 [23:38<52:14,  1.35s/step]Training:  22%|██▏       | 673/3000 [23:39<52:12,  1.35s/step]Training:  22%|██▏       | 674/3000 [23:41<52:11,  1.35s/step]Training:  22%|██▎       | 675/3000 [23:42<52:10,  1.35s/step]Training:  23%|██▎       | 676/3000 [23:43<52:08,  1.35s/step]Training:  23%|██▎       | 677/3000 [23:45<52:07,  1.35s/step]Training:  23%|██▎       | 678/3000 [23:46<52:06,  1.35s/step]Training:  23%|██▎       | 679/3000 [23:47<52:04,  1.35s/step]Training:  23%|██▎       | 680/3000 [23:49<52:03,  1.35s/step]Training:  23%|██▎       | 681/3000 [23:50<52:02,  1.35s/step]Training:  23%|██▎       | 682/3000 [23:52<52:01,  1.35s/step]Training:  23%|██▎       | 683/3000 [23:53<52:00,  1.35s/step]Training:  23%|██▎       | 684/3000 [23:54<51:59,  1.35s/step]Training:  23%|██▎       | 685/3000 [23:56<51:57,  1.35s/step]Training:  23%|██▎       | 686/3000 [23:57<51:56,  1.35s/step]Training:  23%|██▎       | 687/3000 [23:58<51:54,  1.35s/step]Training:  23%|██▎       | 688/3000 [24:00<51:54,  1.35s/step]Training:  23%|██▎       | 689/3000 [24:01<51:53,  1.35s/step]Training:  23%|██▎       | 690/3000 [24:02<51:52,  1.35s/step]Training:  23%|██▎       | 691/3000 [24:04<51:50,  1.35s/step]Training:  23%|██▎       | 692/3000 [24:05<51:48,  1.35s/step]Training:  23%|██▎       | 693/3000 [24:06<51:47,  1.35s/step]Training:  23%|██▎       | 694/3000 [24:08<51:45,  1.35s/step]Training:  23%|██▎       | 695/3000 [24:09<51:43,  1.35s/step]Training:  23%|██▎       | 696/3000 [24:10<51:42,  1.35s/step]Training:  23%|██▎       | 697/3000 [24:12<51:40,  1.35s/step]Training:  23%|██▎       | 698/3000 [24:13<51:39,  1.35s/step]Training:  23%|██▎       | 699/3000 [24:14<51:38,  1.35s/step]Training:  23%|██▎       | 700/3000 [24:16<51:36,  1.35s/step]11:33:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1914 lr=3.000e-04
11:33:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1993 lr=3.000e-04
11:33:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1758 lr=3.000e-04
11:33:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1145 lr=3.000e-04
11:33:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1493 lr=3.000e-04
11:33:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1334 lr=3.000e-04
11:33:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.0968 lr=3.000e-04
11:33:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=700 loss=0.1319 lr=3.000e-04
Training:  23%|██▎       | 701/3000 [24:17<51:36,  1.35s/step]Training:  23%|██▎       | 702/3000 [24:18<51:34,  1.35s/step]Training:  23%|██▎       | 703/3000 [24:20<51:33,  1.35s/step]Training:  23%|██▎       | 704/3000 [24:21<51:32,  1.35s/step]Training:  24%|██▎       | 705/3000 [24:23<51:30,  1.35s/step]Training:  24%|██▎       | 706/3000 [24:24<51:28,  1.35s/step]Training:  24%|██▎       | 707/3000 [24:25<51:27,  1.35s/step]Training:  24%|██▎       | 708/3000 [24:27<51:26,  1.35s/step]Training:  24%|██▎       | 709/3000 [24:28<51:25,  1.35s/step]Training:  24%|██▎       | 710/3000 [24:29<51:25,  1.35s/step]Training:  24%|██▎       | 711/3000 [24:31<51:23,  1.35s/step]Training:  24%|██▎       | 712/3000 [24:32<51:21,  1.35s/step]Training:  24%|██▍       | 713/3000 [24:33<51:19,  1.35s/step]Training:  24%|██▍       | 714/3000 [24:35<51:18,  1.35s/step]Training:  24%|██▍       | 715/3000 [24:36<51:16,  1.35s/step]Training:  24%|██▍       | 716/3000 [24:37<51:15,  1.35s/step]Training:  24%|██▍       | 717/3000 [24:39<51:13,  1.35s/step]Training:  24%|██▍       | 718/3000 [24:40<51:12,  1.35s/step]Training:  24%|██▍       | 719/3000 [24:41<51:11,  1.35s/step]Training:  24%|██▍       | 720/3000 [24:43<51:09,  1.35s/step]Training:  24%|██▍       | 721/3000 [24:44<51:08,  1.35s/step]Training:  24%|██▍       | 722/3000 [24:45<51:07,  1.35s/step]Training:  24%|██▍       | 723/3000 [24:47<51:05,  1.35s/step]Training:  24%|██▍       | 724/3000 [24:48<51:03,  1.35s/step]Training:  24%|██▍       | 725/3000 [24:49<51:02,  1.35s/step]Training:  24%|██▍       | 726/3000 [24:51<51:01,  1.35s/step]Training:  24%|██▍       | 727/3000 [24:52<51:00,  1.35s/step]Training:  24%|██▍       | 728/3000 [24:53<50:58,  1.35s/step]Training:  24%|██▍       | 729/3000 [24:55<50:57,  1.35s/step]Training:  24%|██▍       | 730/3000 [24:56<50:56,  1.35s/step]Training:  24%|██▍       | 731/3000 [24:58<50:56,  1.35s/step]Training:  24%|██▍       | 732/3000 [24:59<50:55,  1.35s/step]Training:  24%|██▍       | 733/3000 [25:00<50:53,  1.35s/step]Training:  24%|██▍       | 734/3000 [25:02<50:52,  1.35s/step]Training:  24%|██▍       | 735/3000 [25:03<50:51,  1.35s/step]Training:  25%|██▍       | 736/3000 [25:04<50:50,  1.35s/step]Training:  25%|██▍       | 737/3000 [25:06<50:48,  1.35s/step]Training:  25%|██▍       | 738/3000 [25:07<50:47,  1.35s/step]Training:  25%|██▍       | 739/3000 [25:08<50:45,  1.35s/step]Training:  25%|██▍       | 740/3000 [25:10<50:43,  1.35s/step]Training:  25%|██▍       | 741/3000 [25:11<50:42,  1.35s/step]Training:  25%|██▍       | 742/3000 [25:12<50:40,  1.35s/step]Training:  25%|██▍       | 743/3000 [25:14<50:39,  1.35s/step]Training:  25%|██▍       | 744/3000 [25:15<50:37,  1.35s/step]Training:  25%|██▍       | 745/3000 [25:16<50:37,  1.35s/step]Training:  25%|██▍       | 746/3000 [25:18<50:35,  1.35s/step]Training:  25%|██▍       | 747/3000 [25:19<50:34,  1.35s/step]Training:  25%|██▍       | 748/3000 [25:20<50:32,  1.35s/step]Training:  25%|██▍       | 749/3000 [25:22<50:31,  1.35s/step]Training:  25%|██▌       | 750/3000 [25:23<50:29,  1.35s/step]11:34:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1720 lr=3.000e-04
11:34:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1779 lr=3.000e-04
11:34:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.0836 lr=3.000e-04
11:34:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1674 lr=3.000e-04
11:34:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1193 lr=3.000e-04
11:34:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1530 lr=3.000e-04
11:34:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1194 lr=3.000e-04
11:34:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=750 loss=0.1088 lr=3.000e-04
Training:  25%|██▌       | 751/3000 [25:24<50:29,  1.35s/step]Training:  25%|██▌       | 752/3000 [25:26<50:29,  1.35s/step]Training:  25%|██▌       | 753/3000 [25:27<50:28,  1.35s/step]Training:  25%|██▌       | 754/3000 [25:29<50:26,  1.35s/step]Training:  25%|██▌       | 755/3000 [25:30<50:24,  1.35s/step]Training:  25%|██▌       | 756/3000 [25:31<50:22,  1.35s/step]Training:  25%|██▌       | 757/3000 [25:33<50:20,  1.35s/step]Training:  25%|██▌       | 758/3000 [25:34<50:19,  1.35s/step]Training:  25%|██▌       | 759/3000 [25:35<50:17,  1.35s/step]Training:  25%|██▌       | 760/3000 [25:37<50:16,  1.35s/step]Training:  25%|██▌       | 761/3000 [25:38<50:14,  1.35s/step]Training:  25%|██▌       | 762/3000 [25:39<50:13,  1.35s/step]Training:  25%|██▌       | 763/3000 [25:41<50:12,  1.35s/step]Training:  25%|██▌       | 764/3000 [25:42<50:11,  1.35s/step]Training:  26%|██▌       | 765/3000 [25:43<50:09,  1.35s/step]Training:  26%|██▌       | 766/3000 [25:45<50:07,  1.35s/step]Training:  26%|██▌       | 767/3000 [25:46<50:06,  1.35s/step]Training:  26%|██▌       | 768/3000 [25:47<50:05,  1.35s/step]Training:  26%|██▌       | 769/3000 [25:49<50:03,  1.35s/step]Training:  26%|██▌       | 770/3000 [25:50<50:02,  1.35s/step]Training:  26%|██▌       | 771/3000 [25:51<50:02,  1.35s/step]Training:  26%|██▌       | 772/3000 [25:53<50:00,  1.35s/step]Training:  26%|██▌       | 773/3000 [25:54<50:00,  1.35s/step]Training:  26%|██▌       | 774/3000 [25:55<49:58,  1.35s/step]Training:  26%|██▌       | 775/3000 [25:57<49:56,  1.35s/step]Training:  26%|██▌       | 776/3000 [25:58<49:55,  1.35s/step]Training:  26%|██▌       | 777/3000 [25:59<49:54,  1.35s/step]Training:  26%|██▌       | 778/3000 [26:01<49:52,  1.35s/step]Training:  26%|██▌       | 779/3000 [26:02<49:51,  1.35s/step]Training:  26%|██▌       | 780/3000 [26:04<49:49,  1.35s/step]Training:  26%|██▌       | 781/3000 [26:05<49:48,  1.35s/step]Training:  26%|██▌       | 782/3000 [26:06<49:46,  1.35s/step]Training:  26%|██▌       | 783/3000 [26:08<49:45,  1.35s/step]Training:  26%|██▌       | 784/3000 [26:09<49:43,  1.35s/step]Training:  26%|██▌       | 785/3000 [26:10<49:42,  1.35s/step]Training:  26%|██▌       | 786/3000 [26:12<49:40,  1.35s/step]Training:  26%|██▌       | 787/3000 [26:13<49:39,  1.35s/step]Training:  26%|██▋       | 788/3000 [26:14<49:38,  1.35s/step]Training:  26%|██▋       | 789/3000 [26:16<49:36,  1.35s/step]Training:  26%|██▋       | 790/3000 [26:17<49:35,  1.35s/step]Training:  26%|██▋       | 791/3000 [26:18<49:34,  1.35s/step]Training:  26%|██▋       | 792/3000 [26:20<49:33,  1.35s/step]Training:  26%|██▋       | 793/3000 [26:21<49:31,  1.35s/step]Training:  26%|██▋       | 794/3000 [26:22<49:31,  1.35s/step]Training:  26%|██▋       | 795/3000 [26:24<49:29,  1.35s/step]Training:  27%|██▋       | 796/3000 [26:25<49:28,  1.35s/step]Training:  27%|██▋       | 797/3000 [26:26<49:26,  1.35s/step]Training:  27%|██▋       | 798/3000 [26:28<49:25,  1.35s/step]Training:  27%|██▋       | 799/3000 [26:29<49:24,  1.35s/step]Training:  27%|██▋       | 800/3000 [26:30<49:23,  1.35s/step]11:35:39 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.1989 lr=3.000e-04
11:35:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.1704 lr=3.000e-04
11:35:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.1337 lr=3.000e-04
11:35:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.1413 lr=3.000e-04
11:35:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.2183 lr=3.000e-04
11:35:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.2411 lr=3.000e-04
11:35:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.1114 lr=3.000e-04
11:35:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=800 loss=0.1424 lr=3.000e-04
Training:  27%|██▋       | 801/3000 [26:32<49:22,  1.35s/step]Training:  27%|██▋       | 802/3000 [26:33<49:20,  1.35s/step]Training:  27%|██▋       | 803/3000 [26:34<49:19,  1.35s/step]Training:  27%|██▋       | 804/3000 [26:36<49:17,  1.35s/step]Training:  27%|██▋       | 805/3000 [26:37<49:15,  1.35s/step]Training:  27%|██▋       | 806/3000 [26:39<49:14,  1.35s/step]Training:  27%|██▋       | 807/3000 [26:40<49:13,  1.35s/step]Training:  27%|██▋       | 808/3000 [26:41<49:11,  1.35s/step]Training:  27%|██▋       | 809/3000 [26:43<49:11,  1.35s/step]Training:  27%|██▋       | 810/3000 [26:44<49:10,  1.35s/step]Training:  27%|██▋       | 811/3000 [26:45<49:08,  1.35s/step]Training:  27%|██▋       | 812/3000 [26:47<49:06,  1.35s/step]Training:  27%|██▋       | 813/3000 [26:48<49:04,  1.35s/step]Training:  27%|██▋       | 814/3000 [26:49<49:03,  1.35s/step]Training:  27%|██▋       | 815/3000 [26:51<49:03,  1.35s/step]Training:  27%|██▋       | 816/3000 [26:52<49:01,  1.35s/step]Training:  27%|██▋       | 817/3000 [26:53<48:59,  1.35s/step]Training:  27%|██▋       | 818/3000 [26:55<48:58,  1.35s/step]Training:  27%|██▋       | 819/3000 [26:56<48:57,  1.35s/step]Training:  27%|██▋       | 820/3000 [26:57<48:55,  1.35s/step]Training:  27%|██▋       | 821/3000 [26:59<48:54,  1.35s/step]Training:  27%|██▋       | 822/3000 [27:00<48:53,  1.35s/step]Training:  27%|██▋       | 823/3000 [27:01<48:52,  1.35s/step]Training:  27%|██▋       | 824/3000 [27:03<48:50,  1.35s/step]Training:  28%|██▊       | 825/3000 [27:04<48:48,  1.35s/step]Training:  28%|██▊       | 826/3000 [27:05<48:47,  1.35s/step]Training:  28%|██▊       | 827/3000 [27:07<48:46,  1.35s/step]Training:  28%|██▊       | 828/3000 [27:08<48:44,  1.35s/step]Training:  28%|██▊       | 829/3000 [27:10<48:43,  1.35s/step]Training:  28%|██▊       | 830/3000 [27:11<48:42,  1.35s/step]Training:  28%|██▊       | 831/3000 [27:12<48:40,  1.35s/step]Training:  28%|██▊       | 832/3000 [27:14<48:39,  1.35s/step]Training:  28%|██▊       | 833/3000 [27:15<48:38,  1.35s/step]Training:  28%|██▊       | 834/3000 [27:16<48:36,  1.35s/step]Training:  28%|██▊       | 835/3000 [27:18<48:35,  1.35s/step]Training:  28%|██▊       | 836/3000 [27:19<48:34,  1.35s/step]Training:  28%|██▊       | 837/3000 [27:20<48:33,  1.35s/step]Training:  28%|██▊       | 838/3000 [27:22<48:31,  1.35s/step]Training:  28%|██▊       | 839/3000 [27:23<48:30,  1.35s/step]Training:  28%|██▊       | 840/3000 [27:24<48:28,  1.35s/step]Training:  28%|██▊       | 841/3000 [27:26<48:31,  1.35s/step]Training:  28%|██▊       | 842/3000 [27:27<48:28,  1.35s/step]Training:  28%|██▊       | 843/3000 [27:28<48:26,  1.35s/step]Training:  28%|██▊       | 844/3000 [27:30<48:24,  1.35s/step]Training:  28%|██▊       | 845/3000 [27:31<48:23,  1.35s/step]Training:  28%|██▊       | 846/3000 [27:32<48:21,  1.35s/step]Training:  28%|██▊       | 847/3000 [27:34<48:19,  1.35s/step]Training:  28%|██▊       | 848/3000 [27:35<48:18,  1.35s/step]Training:  28%|██▊       | 849/3000 [27:36<48:16,  1.35s/step]Training:  28%|██▊       | 850/3000 [27:38<48:15,  1.35s/step]11:36:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1296 lr=3.000e-04
11:36:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1686 lr=3.000e-04
11:36:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1399 lr=3.000e-04
11:36:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1741 lr=3.000e-04
11:36:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1344 lr=3.000e-04
11:36:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1467 lr=3.000e-04
11:36:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1237 lr=3.000e-04
11:36:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=850 loss=0.1188 lr=3.000e-04
Training:  28%|██▊       | 851/3000 [27:39<48:14,  1.35s/step]Training:  28%|██▊       | 852/3000 [27:40<48:12,  1.35s/step]Training:  28%|██▊       | 853/3000 [27:42<48:11,  1.35s/step]Training:  28%|██▊       | 854/3000 [27:43<48:09,  1.35s/step]Training:  28%|██▊       | 855/3000 [27:45<48:08,  1.35s/step]Training:  29%|██▊       | 856/3000 [27:46<48:07,  1.35s/step]Training:  29%|██▊       | 857/3000 [27:47<48:07,  1.35s/step]Training:  29%|██▊       | 858/3000 [27:49<48:05,  1.35s/step]Training:  29%|██▊       | 859/3000 [27:50<48:03,  1.35s/step]Training:  29%|██▊       | 860/3000 [27:51<48:02,  1.35s/step]Training:  29%|██▊       | 861/3000 [27:53<48:00,  1.35s/step]Training:  29%|██▊       | 862/3000 [27:54<47:59,  1.35s/step]Training:  29%|██▉       | 863/3000 [27:55<47:58,  1.35s/step]Training:  29%|██▉       | 864/3000 [27:57<47:57,  1.35s/step]Training:  29%|██▉       | 865/3000 [27:58<47:55,  1.35s/step]Training:  29%|██▉       | 866/3000 [27:59<47:54,  1.35s/step]Training:  29%|██▉       | 867/3000 [28:01<47:53,  1.35s/step]Training:  29%|██▉       | 868/3000 [28:02<47:51,  1.35s/step]Training:  29%|██▉       | 869/3000 [28:03<47:50,  1.35s/step]Training:  29%|██▉       | 870/3000 [28:05<47:48,  1.35s/step]Training:  29%|██▉       | 871/3000 [28:06<47:48,  1.35s/step]Training:  29%|██▉       | 872/3000 [28:07<47:46,  1.35s/step]Training:  29%|██▉       | 873/3000 [28:09<47:45,  1.35s/step]Training:  29%|██▉       | 874/3000 [28:10<47:44,  1.35s/step]Training:  29%|██▉       | 875/3000 [28:11<47:42,  1.35s/step]Training:  29%|██▉       | 876/3000 [28:13<47:40,  1.35s/step]Training:  29%|██▉       | 877/3000 [28:14<47:39,  1.35s/step]Training:  29%|██▉       | 878/3000 [28:16<47:38,  1.35s/step]Training:  29%|██▉       | 879/3000 [28:17<47:36,  1.35s/step]Training:  29%|██▉       | 880/3000 [28:18<47:34,  1.35s/step]Training:  29%|██▉       | 881/3000 [28:20<47:33,  1.35s/step]Training:  29%|██▉       | 882/3000 [28:21<47:32,  1.35s/step]Training:  29%|██▉       | 883/3000 [28:22<47:30,  1.35s/step]Training:  29%|██▉       | 884/3000 [28:24<47:30,  1.35s/step]Training:  30%|██▉       | 885/3000 [28:25<47:28,  1.35s/step]Training:  30%|██▉       | 886/3000 [28:26<47:27,  1.35s/step]Training:  30%|██▉       | 887/3000 [28:28<47:26,  1.35s/step]Training:  30%|██▉       | 888/3000 [28:29<47:24,  1.35s/step]Training:  30%|██▉       | 889/3000 [28:30<47:23,  1.35s/step]Training:  30%|██▉       | 890/3000 [28:32<47:21,  1.35s/step]Training:  30%|██▉       | 891/3000 [28:33<47:19,  1.35s/step]Training:  30%|██▉       | 892/3000 [28:34<47:18,  1.35s/step]Training:  30%|██▉       | 893/3000 [28:36<47:17,  1.35s/step]Training:  30%|██▉       | 894/3000 [28:37<47:15,  1.35s/step]Training:  30%|██▉       | 895/3000 [28:38<47:14,  1.35s/step]Training:  30%|██▉       | 896/3000 [28:40<47:13,  1.35s/step]Training:  30%|██▉       | 897/3000 [28:41<47:11,  1.35s/step]Training:  30%|██▉       | 898/3000 [28:42<47:11,  1.35s/step]Training:  30%|██▉       | 899/3000 [28:44<47:09,  1.35s/step]Training:  30%|███       | 900/3000 [28:45<47:08,  1.35s/step]11:37:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.1191 lr=3.000e-04
11:38:16 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:38:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.1156 lr=3.000e-04
11:38:38 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:38:39 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.1457 lr=3.000e-04
11:39:01 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:39:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.2112 lr=3.000e-04
11:39:23 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:39:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.1367 lr=3.000e-04
11:39:45 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:39:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.0928 lr=3.000e-04
11:40:08 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:40:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.1401 lr=3.000e-04
11:40:30 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
11:40:30 - trainer.gpt2-gsm8k-lora-main - INFO - step=900 loss=0.1087 lr=3.000e-04
11:40:52 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=900 loss=1.1659 ppl=3.21
Training:  30%|███       | 901/3000 [31:44<31:46:09, 54.49s/step]Training:  30%|███       | 902/3000 [31:45<22:27:48, 38.55s/step]Training:  30%|███       | 903/3000 [31:46<15:57:07, 27.39s/step]Training:  30%|███       | 904/3000 [31:48<11:23:46, 19.57s/step]Training:  30%|███       | 905/3000 [31:49<8:12:31, 14.11s/step] Training:  30%|███       | 906/3000 [31:50<5:58:41, 10.28s/step]Training:  30%|███       | 907/3000 [31:52<4:25:04,  7.60s/step]Training:  30%|███       | 908/3000 [31:53<3:19:32,  5.72s/step]Training:  30%|███       | 909/3000 [31:54<2:33:41,  4.41s/step]Training:  30%|███       | 910/3000 [31:56<2:01:37,  3.49s/step]Training:  30%|███       | 911/3000 [31:57<1:39:09,  2.85s/step]Training:  30%|███       | 912/3000 [31:58<1:23:26,  2.40s/step]Training:  30%|███       | 913/3000 [32:00<1:12:27,  2.08s/step]Training:  30%|███       | 914/3000 [32:01<1:04:44,  1.86s/step]Training:  30%|███       | 915/3000 [32:02<59:20,  1.71s/step]  Training:  31%|███       | 916/3000 [32:04<55:32,  1.60s/step]Training:  31%|███       | 917/3000 [32:05<52:53,  1.52s/step]Training:  31%|███       | 918/3000 [32:07<51:01,  1.47s/step]Training:  31%|███       | 919/3000 [32:08<49:42,  1.43s/step]Training:  31%|███       | 920/3000 [32:09<48:47,  1.41s/step]Training:  31%|███       | 921/3000 [32:11<48:07,  1.39s/step]Training:  31%|███       | 922/3000 [32:12<47:39,  1.38s/step]Training:  31%|███       | 923/3000 [32:13<47:20,  1.37s/step]Training:  31%|███       | 924/3000 [32:15<47:05,  1.36s/step]Training:  31%|███       | 925/3000 [32:16<46:55,  1.36s/step]Training:  31%|███       | 926/3000 [32:17<46:47,  1.35s/step]Training:  31%|███       | 927/3000 [32:19<46:42,  1.35s/step]Training:  31%|███       | 928/3000 [32:20<46:37,  1.35s/step]Training:  31%|███       | 929/3000 [32:21<46:34,  1.35s/step]Training:  31%|███       | 930/3000 [32:23<46:30,  1.35s/step]Training:  31%|███       | 931/3000 [32:24<46:28,  1.35s/step]Training:  31%|███       | 932/3000 [32:25<46:28,  1.35s/step]Training:  31%|███       | 933/3000 [32:27<46:26,  1.35s/step]Training:  31%|███       | 934/3000 [32:28<46:25,  1.35s/step]Training:  31%|███       | 935/3000 [32:29<46:24,  1.35s/step]Training:  31%|███       | 936/3000 [32:31<46:22,  1.35s/step]Training:  31%|███       | 937/3000 [32:32<46:19,  1.35s/step]Training:  31%|███▏      | 938/3000 [32:33<46:17,  1.35s/step]Training:  31%|███▏      | 939/3000 [32:35<46:16,  1.35s/step]Training:  31%|███▏      | 940/3000 [32:36<46:14,  1.35s/step]Training:  31%|███▏      | 941/3000 [32:37<46:13,  1.35s/step]Training:  31%|███▏      | 942/3000 [32:39<46:12,  1.35s/step]Training:  31%|███▏      | 943/3000 [32:40<46:10,  1.35s/step]Training:  31%|███▏      | 944/3000 [32:42<46:08,  1.35s/step]Training:  32%|███▏      | 945/3000 [32:43<46:07,  1.35s/step]Training:  32%|███▏      | 946/3000 [32:44<46:06,  1.35s/step]Training:  32%|███▏      | 947/3000 [32:46<46:04,  1.35s/step]Training:  32%|███▏      | 948/3000 [32:47<46:03,  1.35s/step]Training:  32%|███▏      | 949/3000 [32:48<46:02,  1.35s/step]Training:  32%|███▏      | 950/3000 [32:50<46:00,  1.35s/step]11:41:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1278 lr=3.000e-04
11:41:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1353 lr=3.000e-04
11:41:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1325 lr=3.000e-04
11:41:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1571 lr=3.000e-04
11:41:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1269 lr=3.000e-04
11:41:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1445 lr=3.000e-04
11:42:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.1167 lr=3.000e-04
11:42:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=950 loss=0.0960 lr=3.000e-04
Training:  32%|███▏      | 951/3000 [32:51<46:00,  1.35s/step]Training:  32%|███▏      | 952/3000 [32:52<45:58,  1.35s/step]Training:  32%|███▏      | 953/3000 [32:54<45:57,  1.35s/step]Training:  32%|███▏      | 954/3000 [32:55<45:55,  1.35s/step]Training:  32%|███▏      | 955/3000 [32:56<45:54,  1.35s/step]Training:  32%|███▏      | 956/3000 [32:58<45:53,  1.35s/step]Training:  32%|███▏      | 957/3000 [32:59<45:52,  1.35s/step]Training:  32%|███▏      | 958/3000 [33:00<45:50,  1.35s/step]Training:  32%|███▏      | 959/3000 [33:02<45:49,  1.35s/step]Training:  32%|███▏      | 960/3000 [33:03<45:47,  1.35s/step]Training:  32%|███▏      | 961/3000 [33:04<45:46,  1.35s/step]Training:  32%|███▏      | 962/3000 [33:06<45:44,  1.35s/step]Training:  32%|███▏      | 963/3000 [33:07<45:43,  1.35s/step]Training:  32%|███▏      | 964/3000 [33:08<45:41,  1.35s/step]Training:  32%|███▏      | 965/3000 [33:10<45:40,  1.35s/step]Training:  32%|███▏      | 966/3000 [33:11<45:39,  1.35s/step]Training:  32%|███▏      | 967/3000 [33:13<45:37,  1.35s/step]Training:  32%|███▏      | 968/3000 [33:14<45:36,  1.35s/step]Training:  32%|███▏      | 969/3000 [33:15<45:34,  1.35s/step]Training:  32%|███▏      | 970/3000 [33:17<45:33,  1.35s/step]Training:  32%|███▏      | 971/3000 [33:18<45:32,  1.35s/step]Training:  32%|███▏      | 972/3000 [33:19<45:30,  1.35s/step]Training:  32%|███▏      | 973/3000 [33:21<45:29,  1.35s/step]Training:  32%|███▏      | 974/3000 [33:22<45:28,  1.35s/step]Training:  32%|███▎      | 975/3000 [33:23<45:27,  1.35s/step]Training:  33%|███▎      | 976/3000 [33:25<45:26,  1.35s/step]Training:  33%|███▎      | 977/3000 [33:26<45:25,  1.35s/step]Training:  33%|███▎      | 978/3000 [33:27<45:23,  1.35s/step]Training:  33%|███▎      | 979/3000 [33:29<45:22,  1.35s/step]Training:  33%|███▎      | 980/3000 [33:30<45:20,  1.35s/step]Training:  33%|███▎      | 981/3000 [33:31<45:19,  1.35s/step]Training:  33%|███▎      | 982/3000 [33:33<45:17,  1.35s/step]Training:  33%|███▎      | 983/3000 [33:34<45:16,  1.35s/step]Training:  33%|███▎      | 984/3000 [33:35<45:14,  1.35s/step]Training:  33%|███▎      | 985/3000 [33:37<45:13,  1.35s/step]Training:  33%|███▎      | 986/3000 [33:38<45:12,  1.35s/step]Training:  33%|███▎      | 987/3000 [33:39<45:11,  1.35s/step]Training:  33%|███▎      | 988/3000 [33:41<45:09,  1.35s/step]Training:  33%|███▎      | 989/3000 [33:42<45:08,  1.35s/step]Training:  33%|███▎      | 990/3000 [33:43<45:06,  1.35s/step]Training:  33%|███▎      | 991/3000 [33:45<45:05,  1.35s/step]Training:  33%|███▎      | 992/3000 [33:46<45:03,  1.35s/step]Training:  33%|███▎      | 993/3000 [33:48<45:02,  1.35s/step]Training:  33%|███▎      | 994/3000 [33:49<45:01,  1.35s/step]Training:  33%|███▎      | 995/3000 [33:50<44:59,  1.35s/step]Training:  33%|███▎      | 996/3000 [33:52<44:58,  1.35s/step]Training:  33%|███▎      | 997/3000 [33:53<44:57,  1.35s/step]Training:  33%|███▎      | 998/3000 [33:54<44:57,  1.35s/step]Training:  33%|███▎      | 999/3000 [33:56<44:55,  1.35s/step]Training:  33%|███▎      | 1000/3000 [33:57<44:54,  1.35s/step]11:43:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1194 lr=3.000e-04
11:43:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1432 lr=3.000e-04
11:43:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1892 lr=3.000e-04
11:43:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1467 lr=3.000e-04
11:43:09 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1958 lr=3.000e-04
11:43:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.0799 lr=3.000e-04
11:43:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1634 lr=3.000e-04
11:43:11 - trainer.gpt2-gsm8k-lora-main - INFO - step=1000 loss=0.1062 lr=3.000e-04
Training:  33%|███▎      | 1001/3000 [34:03<1:32:52,  2.79s/step]Training:  33%|███▎      | 1002/3000 [34:04<1:18:26,  2.36s/step]Training:  33%|███▎      | 1003/3000 [34:06<1:08:19,  2.05s/step]Training:  33%|███▎      | 1004/3000 [34:07<1:01:14,  1.84s/step]Training:  34%|███▎      | 1005/3000 [34:08<56:16,  1.69s/step]  Training:  34%|███▎      | 1006/3000 [34:10<52:48,  1.59s/step]Training:  34%|███▎      | 1007/3000 [34:11<50:21,  1.52s/step]Training:  34%|███▎      | 1008/3000 [34:13<48:38,  1.47s/step]Training:  34%|███▎      | 1009/3000 [34:14<47:26,  1.43s/step]Training:  34%|███▎      | 1010/3000 [34:15<46:35,  1.40s/step]Training:  34%|███▎      | 1011/3000 [34:17<45:59,  1.39s/step]Training:  34%|███▎      | 1012/3000 [34:18<45:33,  1.37s/step]Training:  34%|███▍      | 1013/3000 [34:19<45:14,  1.37s/step]Training:  34%|███▍      | 1014/3000 [34:21<45:02,  1.36s/step]Training:  34%|███▍      | 1015/3000 [34:22<44:52,  1.36s/step]Training:  34%|███▍      | 1016/3000 [34:23<44:47,  1.35s/step]Training:  34%|███▍      | 1017/3000 [34:25<44:42,  1.35s/step]Training:  34%|███▍      | 1018/3000 [34:26<44:37,  1.35s/step]Training:  34%|███▍      | 1019/3000 [34:27<44:33,  1.35s/step]Training:  34%|███▍      | 1020/3000 [34:29<44:30,  1.35s/step]Training:  34%|███▍      | 1021/3000 [34:30<44:27,  1.35s/step]Training:  34%|███▍      | 1022/3000 [34:31<44:25,  1.35s/step]Training:  34%|███▍      | 1023/3000 [34:33<44:23,  1.35s/step]Training:  34%|███▍      | 1024/3000 [34:34<44:22,  1.35s/step]Training:  34%|███▍      | 1025/3000 [34:35<44:20,  1.35s/step]Training:  34%|███▍      | 1026/3000 [34:37<44:18,  1.35s/step]Training:  34%|███▍      | 1027/3000 [34:38<44:17,  1.35s/step]Training:  34%|███▍      | 1028/3000 [34:39<44:16,  1.35s/step]Training:  34%|███▍      | 1029/3000 [34:41<44:14,  1.35s/step]Training:  34%|███▍      | 1030/3000 [34:42<44:13,  1.35s/step]Training:  34%|███▍      | 1031/3000 [34:44<44:11,  1.35s/step]Training:  34%|███▍      | 1032/3000 [34:45<44:10,  1.35s/step]Training:  34%|███▍      | 1033/3000 [34:46<44:08,  1.35s/step]Training:  34%|███▍      | 1034/3000 [34:48<44:07,  1.35s/step]Training:  34%|███▍      | 1035/3000 [34:49<44:06,  1.35s/step]Training:  35%|███▍      | 1036/3000 [34:50<44:05,  1.35s/step]Training:  35%|███▍      | 1037/3000 [34:52<44:05,  1.35s/step]Training:  35%|███▍      | 1038/3000 [34:53<44:03,  1.35s/step]Training:  35%|███▍      | 1039/3000 [34:54<44:02,  1.35s/step]Training:  35%|███▍      | 1040/3000 [34:56<44:00,  1.35s/step]Training:  35%|███▍      | 1041/3000 [34:57<43:59,  1.35s/step]Training:  35%|███▍      | 1042/3000 [34:58<43:57,  1.35s/step]Training:  35%|███▍      | 1043/3000 [35:00<43:57,  1.35s/step]Training:  35%|███▍      | 1044/3000 [35:01<43:55,  1.35s/step]Training:  35%|███▍      | 1045/3000 [35:02<43:53,  1.35s/step]Training:  35%|███▍      | 1046/3000 [35:04<43:52,  1.35s/step]Training:  35%|███▍      | 1047/3000 [35:05<43:50,  1.35s/step]Training:  35%|███▍      | 1048/3000 [35:06<43:49,  1.35s/step]Training:  35%|███▍      | 1049/3000 [35:08<43:47,  1.35s/step]Training:  35%|███▌      | 1050/3000 [35:09<43:45,  1.35s/step]11:44:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.0838 lr=3.000e-04
11:44:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1137 lr=3.000e-04
11:44:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1379 lr=3.000e-04
11:44:19 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1102 lr=3.000e-04
11:44:19 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1215 lr=3.000e-04
11:44:19 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1811 lr=3.000e-04
11:44:19 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1159 lr=3.000e-04
11:44:19 - trainer.gpt2-gsm8k-lora-main - INFO - step=1050 loss=0.1092 lr=3.000e-04
Training:  35%|███▌      | 1051/3000 [35:10<43:45,  1.35s/step]Training:  35%|███▌      | 1052/3000 [35:12<43:43,  1.35s/step]Training:  35%|███▌      | 1053/3000 [35:13<43:42,  1.35s/step]Training:  35%|███▌      | 1054/3000 [35:14<43:40,  1.35s/step]Training:  35%|███▌      | 1055/3000 [35:16<43:39,  1.35s/step]Training:  35%|███▌      | 1056/3000 [35:17<43:38,  1.35s/step]Training:  35%|███▌      | 1057/3000 [35:19<43:36,  1.35s/step]Training:  35%|███▌      | 1058/3000 [35:20<43:36,  1.35s/step]Training:  35%|███▌      | 1059/3000 [35:21<43:34,  1.35s/step]Training:  35%|███▌      | 1060/3000 [35:23<43:33,  1.35s/step]Training:  35%|███▌      | 1061/3000 [35:24<43:33,  1.35s/step]Training:  35%|███▌      | 1062/3000 [35:25<43:31,  1.35s/step]Training:  35%|███▌      | 1063/3000 [35:27<43:29,  1.35s/step]Training:  35%|███▌      | 1064/3000 [35:28<43:28,  1.35s/step]Training:  36%|███▌      | 1065/3000 [35:29<43:26,  1.35s/step]Training:  36%|███▌      | 1066/3000 [35:31<43:24,  1.35s/step]Training:  36%|███▌      | 1067/3000 [35:32<43:23,  1.35s/step]Training:  36%|███▌      | 1068/3000 [35:33<43:21,  1.35s/step]Training:  36%|███▌      | 1069/3000 [35:35<43:20,  1.35s/step]Training:  36%|███▌      | 1070/3000 [35:36<43:19,  1.35s/step]Training:  36%|███▌      | 1071/3000 [35:37<43:17,  1.35s/step]Training:  36%|███▌      | 1072/3000 [35:39<43:16,  1.35s/step]Training:  36%|███▌      | 1073/3000 [35:40<43:15,  1.35s/step]Training:  36%|███▌      | 1074/3000 [35:41<43:13,  1.35s/step]Training:  36%|███▌      | 1075/3000 [35:43<43:12,  1.35s/step]Training:  36%|███▌      | 1076/3000 [35:44<43:10,  1.35s/step]Training:  36%|███▌      | 1077/3000 [35:45<43:09,  1.35s/step]Training:  36%|███▌      | 1078/3000 [35:47<43:08,  1.35s/step]Training:  36%|███▌      | 1079/3000 [35:48<43:06,  1.35s/step]Training:  36%|███▌      | 1080/3000 [35:50<43:05,  1.35s/step]Training:  36%|███▌      | 1081/3000 [35:51<43:04,  1.35s/step]Training:  36%|███▌      | 1082/3000 [35:52<43:03,  1.35s/step]Training:  36%|███▌      | 1083/3000 [35:54<43:02,  1.35s/step]Training:  36%|███▌      | 1084/3000 [35:55<43:02,  1.35s/step]Training:  36%|███▌      | 1085/3000 [35:56<43:00,  1.35s/step]Training:  36%|███▌      | 1086/3000 [35:58<42:58,  1.35s/step]Training:  36%|███▌      | 1087/3000 [35:59<42:57,  1.35s/step]Training:  36%|███▋      | 1088/3000 [36:00<42:55,  1.35s/step]Training:  36%|███▋      | 1089/3000 [36:02<42:53,  1.35s/step]Training:  36%|███▋      | 1090/3000 [36:03<42:52,  1.35s/step]Training:  36%|███▋      | 1091/3000 [36:04<42:51,  1.35s/step]Training:  36%|███▋      | 1092/3000 [36:06<42:49,  1.35s/step]Training:  36%|███▋      | 1093/3000 [36:07<42:48,  1.35s/step]Training:  36%|███▋      | 1094/3000 [36:08<42:46,  1.35s/step]Training:  36%|███▋      | 1095/3000 [36:10<42:45,  1.35s/step]Training:  37%|███▋      | 1096/3000 [36:11<42:44,  1.35s/step]Training:  37%|███▋      | 1097/3000 [36:12<42:43,  1.35s/step]Training:  37%|███▋      | 1098/3000 [36:14<42:42,  1.35s/step]Training:  37%|███▋      | 1099/3000 [36:15<42:40,  1.35s/step]Training:  37%|███▋      | 1100/3000 [36:16<42:39,  1.35s/step]11:45:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.1807 lr=3.000e-04
11:45:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.1318 lr=3.000e-04
11:45:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.1624 lr=3.000e-04
11:45:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.1808 lr=3.000e-04
11:45:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.1054 lr=3.000e-04
11:45:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.0947 lr=3.000e-04
11:45:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.0897 lr=3.000e-04
11:45:27 - trainer.gpt2-gsm8k-lora-main - INFO - step=1100 loss=0.0885 lr=3.000e-04
Training:  37%|███▋      | 1101/3000 [36:18<42:38,  1.35s/step]Training:  37%|███▋      | 1102/3000 [36:19<42:37,  1.35s/step]Training:  37%|███▋      | 1103/3000 [36:20<42:36,  1.35s/step]Training:  37%|███▋      | 1104/3000 [36:22<42:34,  1.35s/step]Training:  37%|███▋      | 1105/3000 [36:23<42:33,  1.35s/step]Training:  37%|███▋      | 1106/3000 [36:25<42:31,  1.35s/step]Training:  37%|███▋      | 1107/3000 [36:26<42:29,  1.35s/step]Training:  37%|███▋      | 1108/3000 [36:27<42:28,  1.35s/step]Training:  37%|███▋      | 1109/3000 [36:29<42:27,  1.35s/step]Training:  37%|███▋      | 1110/3000 [36:30<42:25,  1.35s/step]Training:  37%|███▋      | 1111/3000 [36:31<42:24,  1.35s/step]Training:  37%|███▋      | 1112/3000 [36:33<42:28,  1.35s/step]Training:  37%|███▋      | 1113/3000 [36:34<42:26,  1.35s/step]Training:  37%|███▋      | 1114/3000 [36:35<42:23,  1.35s/step]Training:  37%|███▋      | 1115/3000 [36:37<42:20,  1.35s/step]Training:  37%|███▋      | 1116/3000 [36:38<42:18,  1.35s/step]Training:  37%|███▋      | 1117/3000 [36:39<42:17,  1.35s/step]Training:  37%|███▋      | 1118/3000 [36:41<42:15,  1.35s/step]Training:  37%|███▋      | 1119/3000 [36:42<42:14,  1.35s/step]Training:  37%|███▋      | 1120/3000 [36:43<42:12,  1.35s/step]Training:  37%|███▋      | 1121/3000 [36:45<42:11,  1.35s/step]Training:  37%|███▋      | 1122/3000 [36:46<42:09,  1.35s/step]Training:  37%|███▋      | 1123/3000 [36:47<42:08,  1.35s/step]Training:  37%|███▋      | 1124/3000 [36:49<42:06,  1.35s/step]Training:  38%|███▊      | 1125/3000 [36:50<42:05,  1.35s/step]Training:  38%|███▊      | 1126/3000 [36:51<42:04,  1.35s/step]Training:  38%|███▊      | 1127/3000 [36:53<42:05,  1.35s/step]Training:  38%|███▊      | 1128/3000 [36:54<42:03,  1.35s/step]Training:  38%|███▊      | 1129/3000 [36:56<42:01,  1.35s/step]Training:  38%|███▊      | 1130/3000 [36:57<41:59,  1.35s/step]Training:  38%|███▊      | 1131/3000 [36:58<41:57,  1.35s/step]Training:  38%|███▊      | 1132/3000 [37:00<41:57,  1.35s/step]Training:  38%|███▊      | 1133/3000 [37:01<41:56,  1.35s/step]Training:  38%|███▊      | 1134/3000 [37:02<41:54,  1.35s/step]Training:  38%|███▊      | 1135/3000 [37:04<41:52,  1.35s/step]Training:  38%|███▊      | 1136/3000 [37:05<41:50,  1.35s/step]Training:  38%|███▊      | 1137/3000 [37:06<41:49,  1.35s/step]Training:  38%|███▊      | 1138/3000 [37:08<41:47,  1.35s/step]Training:  38%|███▊      | 1139/3000 [37:09<41:46,  1.35s/step]Training:  38%|███▊      | 1140/3000 [37:10<41:45,  1.35s/step]Training:  38%|███▊      | 1141/3000 [37:12<41:43,  1.35s/step]Training:  38%|███▊      | 1142/3000 [37:13<41:42,  1.35s/step]Training:  38%|███▊      | 1143/3000 [37:14<41:41,  1.35s/step]Training:  38%|███▊      | 1144/3000 [37:16<41:39,  1.35s/step]Training:  38%|███▊      | 1145/3000 [37:17<41:38,  1.35s/step]Training:  38%|███▊      | 1146/3000 [37:18<41:36,  1.35s/step]Training:  38%|███▊      | 1147/3000 [37:20<41:35,  1.35s/step]Training:  38%|███▊      | 1148/3000 [37:21<41:35,  1.35s/step]Training:  38%|███▊      | 1149/3000 [37:22<41:33,  1.35s/step]Training:  38%|███▊      | 1150/3000 [37:24<41:31,  1.35s/step]11:46:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.1313 lr=3.000e-04
11:46:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.0900 lr=3.000e-04
11:46:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.1619 lr=3.000e-04
11:46:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.1709 lr=3.000e-04
11:46:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.1895 lr=3.000e-04
11:46:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.1840 lr=3.000e-04
11:46:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.1647 lr=3.000e-04
11:46:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1150 loss=0.0939 lr=3.000e-04
Training:  38%|███▊      | 1151/3000 [37:25<41:32,  1.35s/step]Training:  38%|███▊      | 1152/3000 [37:27<41:31,  1.35s/step]Training:  38%|███▊      | 1153/3000 [37:28<41:29,  1.35s/step]Training:  38%|███▊      | 1154/3000 [37:29<41:27,  1.35s/step]Training:  38%|███▊      | 1155/3000 [37:31<41:26,  1.35s/step]Training:  39%|███▊      | 1156/3000 [37:32<41:25,  1.35s/step]Training:  39%|███▊      | 1157/3000 [37:33<41:23,  1.35s/step]Training:  39%|███▊      | 1158/3000 [37:35<41:21,  1.35s/step]Training:  39%|███▊      | 1159/3000 [37:36<41:19,  1.35s/step]Training:  39%|███▊      | 1160/3000 [37:37<41:18,  1.35s/step]Training:  39%|███▊      | 1161/3000 [37:39<41:17,  1.35s/step]Training:  39%|███▊      | 1162/3000 [37:40<41:15,  1.35s/step]Training:  39%|███▉      | 1163/3000 [37:41<41:13,  1.35s/step]Training:  39%|███▉      | 1164/3000 [37:43<41:12,  1.35s/step]Training:  39%|███▉      | 1165/3000 [37:44<41:11,  1.35s/step]Training:  39%|███▉      | 1166/3000 [37:45<41:10,  1.35s/step]Training:  39%|███▉      | 1167/3000 [37:47<41:08,  1.35s/step]Training:  39%|███▉      | 1168/3000 [37:48<41:07,  1.35s/step]Training:  39%|███▉      | 1169/3000 [37:49<41:05,  1.35s/step]Training:  39%|███▉      | 1170/3000 [37:51<41:04,  1.35s/step]Training:  39%|███▉      | 1171/3000 [37:52<41:03,  1.35s/step]Training:  39%|███▉      | 1172/3000 [37:53<41:02,  1.35s/step]Training:  39%|███▉      | 1173/3000 [37:55<41:00,  1.35s/step]Training:  39%|███▉      | 1174/3000 [37:56<40:59,  1.35s/step]Training:  39%|███▉      | 1175/3000 [37:57<40:57,  1.35s/step]Training:  39%|███▉      | 1176/3000 [37:59<40:57,  1.35s/step]Training:  39%|███▉      | 1177/3000 [38:00<40:56,  1.35s/step]Training:  39%|███▉      | 1178/3000 [38:02<40:54,  1.35s/step]Training:  39%|███▉      | 1179/3000 [38:03<40:53,  1.35s/step]Training:  39%|███▉      | 1180/3000 [38:04<40:52,  1.35s/step]Training:  39%|███▉      | 1181/3000 [38:06<40:51,  1.35s/step]Training:  39%|███▉      | 1182/3000 [38:07<40:49,  1.35s/step]Training:  39%|███▉      | 1183/3000 [38:08<40:47,  1.35s/step]Training:  39%|███▉      | 1184/3000 [38:10<40:46,  1.35s/step]Training:  40%|███▉      | 1185/3000 [38:11<40:44,  1.35s/step]Training:  40%|███▉      | 1186/3000 [38:12<40:42,  1.35s/step]Training:  40%|███▉      | 1187/3000 [38:14<40:41,  1.35s/step]Training:  40%|███▉      | 1188/3000 [38:15<40:40,  1.35s/step]Training:  40%|███▉      | 1189/3000 [38:16<40:38,  1.35s/step]Training:  40%|███▉      | 1190/3000 [38:18<40:37,  1.35s/step]Training:  40%|███▉      | 1191/3000 [38:19<40:36,  1.35s/step]Training:  40%|███▉      | 1192/3000 [38:20<40:34,  1.35s/step]Training:  40%|███▉      | 1193/3000 [38:22<40:33,  1.35s/step]Training:  40%|███▉      | 1194/3000 [38:23<40:31,  1.35s/step]Training:  40%|███▉      | 1195/3000 [38:24<40:30,  1.35s/step]Training:  40%|███▉      | 1196/3000 [38:26<40:29,  1.35s/step]Training:  40%|███▉      | 1197/3000 [38:27<40:28,  1.35s/step]Training:  40%|███▉      | 1198/3000 [38:28<40:27,  1.35s/step]Training:  40%|███▉      | 1199/3000 [38:30<40:25,  1.35s/step]Training:  40%|████      | 1200/3000 [38:31<40:24,  1.35s/step]11:47:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.1575 lr=3.000e-04
11:48:02 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:48:02 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.1235 lr=3.000e-04
11:48:25 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:48:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.2195 lr=3.000e-04
11:48:47 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:48:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.1514 lr=3.000e-04
11:49:09 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:49:09 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.1723 lr=3.000e-04
11:49:32 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:49:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.2749 lr=3.000e-04
11:49:54 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:49:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.1214 lr=3.000e-04
11:50:16 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
11:50:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=1200 loss=0.1009 lr=3.000e-04
11:50:38 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1200 loss=1.1646 ppl=3.20
Training:  40%|████      | 1201/3000 [41:30<27:13:47, 54.49s/step]Training:  40%|████      | 1202/3000 [41:31<19:15:07, 38.55s/step]Training:  40%|████      | 1203/3000 [41:32<13:40:14, 27.39s/step]Training:  40%|████      | 1204/3000 [41:34<9:45:56, 19.57s/step] Training:  40%|████      | 1205/3000 [41:35<7:02:00, 14.11s/step]Training:  40%|████      | 1206/3000 [41:36<5:07:19, 10.28s/step]Training:  40%|████      | 1207/3000 [41:38<3:47:04,  7.60s/step]Training:  40%|████      | 1208/3000 [41:39<2:50:55,  5.72s/step]Training:  40%|████      | 1209/3000 [41:40<2:11:39,  4.41s/step]Training:  40%|████      | 1210/3000 [41:42<1:44:09,  3.49s/step]Training:  40%|████      | 1211/3000 [41:43<1:24:55,  2.85s/step]Training:  40%|████      | 1212/3000 [41:44<1:11:26,  2.40s/step]Training:  40%|████      | 1213/3000 [41:46<1:02:00,  2.08s/step]Training:  40%|████      | 1214/3000 [41:47<55:24,  1.86s/step]  Training:  40%|████      | 1215/3000 [41:49<50:46,  1.71s/step]Training:  41%|████      | 1216/3000 [41:50<47:32,  1.60s/step]Training:  41%|████      | 1217/3000 [41:51<45:16,  1.52s/step]Training:  41%|████      | 1218/3000 [41:53<43:41,  1.47s/step]Training:  41%|████      | 1219/3000 [41:54<42:34,  1.43s/step]Training:  41%|████      | 1220/3000 [41:55<41:46,  1.41s/step]Training:  41%|████      | 1221/3000 [41:57<41:12,  1.39s/step]Training:  41%|████      | 1222/3000 [41:58<40:47,  1.38s/step]Training:  41%|████      | 1223/3000 [41:59<40:31,  1.37s/step]Training:  41%|████      | 1224/3000 [42:01<40:18,  1.36s/step]Training:  41%|████      | 1225/3000 [42:02<40:09,  1.36s/step]Training:  41%|████      | 1226/3000 [42:03<40:02,  1.35s/step]Training:  41%|████      | 1227/3000 [42:05<39:56,  1.35s/step]Training:  41%|████      | 1228/3000 [42:06<39:52,  1.35s/step]Training:  41%|████      | 1229/3000 [42:07<39:49,  1.35s/step]Training:  41%|████      | 1230/3000 [42:09<39:46,  1.35s/step]Training:  41%|████      | 1231/3000 [42:10<39:44,  1.35s/step]Training:  41%|████      | 1232/3000 [42:11<39:42,  1.35s/step]Training:  41%|████      | 1233/3000 [42:13<39:40,  1.35s/step]Training:  41%|████      | 1234/3000 [42:14<39:39,  1.35s/step]Training:  41%|████      | 1235/3000 [42:15<39:37,  1.35s/step]Training:  41%|████      | 1236/3000 [42:17<39:36,  1.35s/step]Training:  41%|████      | 1237/3000 [42:18<39:34,  1.35s/step]Training:  41%|████▏     | 1238/3000 [42:19<39:33,  1.35s/step]Training:  41%|████▏     | 1239/3000 [42:21<39:31,  1.35s/step]Training:  41%|████▏     | 1240/3000 [42:22<39:30,  1.35s/step]Training:  41%|████▏     | 1241/3000 [42:24<39:30,  1.35s/step]Training:  41%|████▏     | 1242/3000 [42:25<39:29,  1.35s/step]Training:  41%|████▏     | 1243/3000 [42:26<39:29,  1.35s/step]Training:  41%|████▏     | 1244/3000 [42:28<39:27,  1.35s/step]Training:  42%|████▏     | 1245/3000 [42:29<39:25,  1.35s/step]Training:  42%|████▏     | 1246/3000 [42:30<39:23,  1.35s/step]Training:  42%|████▏     | 1247/3000 [42:32<39:21,  1.35s/step]Training:  42%|████▏     | 1248/3000 [42:33<39:20,  1.35s/step]Training:  42%|████▏     | 1249/3000 [42:34<39:18,  1.35s/step]Training:  42%|████▏     | 1250/3000 [42:36<39:16,  1.35s/step]11:51:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.1044 lr=3.000e-04
11:51:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.1614 lr=3.000e-04
11:51:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.1098 lr=3.000e-04
11:51:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.0968 lr=3.000e-04
11:51:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.1500 lr=3.000e-04
11:51:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.1558 lr=3.000e-04
11:51:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.1395 lr=3.000e-04
11:51:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=1250 loss=0.2483 lr=3.000e-04
Training:  42%|████▏     | 1251/3000 [42:37<39:16,  1.35s/step]Training:  42%|████▏     | 1252/3000 [42:38<39:14,  1.35s/step]Training:  42%|████▏     | 1253/3000 [42:40<39:12,  1.35s/step]Training:  42%|████▏     | 1254/3000 [42:41<39:11,  1.35s/step]Training:  42%|████▏     | 1255/3000 [42:42<39:09,  1.35s/step]Training:  42%|████▏     | 1256/3000 [42:44<39:08,  1.35s/step]Training:  42%|████▏     | 1257/3000 [42:45<39:07,  1.35s/step]Training:  42%|████▏     | 1258/3000 [42:46<39:05,  1.35s/step]Training:  42%|████▏     | 1259/3000 [42:48<39:05,  1.35s/step]Training:  42%|████▏     | 1260/3000 [42:49<39:03,  1.35s/step]Training:  42%|████▏     | 1261/3000 [42:50<39:02,  1.35s/step]Training:  42%|████▏     | 1262/3000 [42:52<39:01,  1.35s/step]Training:  42%|████▏     | 1263/3000 [42:53<38:59,  1.35s/step]Training:  42%|████▏     | 1264/3000 [42:55<38:57,  1.35s/step]Training:  42%|████▏     | 1265/3000 [42:56<38:56,  1.35s/step]Training:  42%|████▏     | 1266/3000 [42:57<38:54,  1.35s/step]Training:  42%|████▏     | 1267/3000 [42:59<38:53,  1.35s/step]Training:  42%|████▏     | 1268/3000 [43:00<38:53,  1.35s/step]Training:  42%|████▏     | 1269/3000 [43:01<38:51,  1.35s/step]Training:  42%|████▏     | 1270/3000 [43:03<38:49,  1.35s/step]Training:  42%|████▏     | 1271/3000 [43:04<38:48,  1.35s/step]Training:  42%|████▏     | 1272/3000 [43:05<38:46,  1.35s/step]Training:  42%|████▏     | 1273/3000 [43:07<38:45,  1.35s/step]Training:  42%|████▏     | 1274/3000 [43:08<38:44,  1.35s/step]Training:  42%|████▎     | 1275/3000 [43:09<38:42,  1.35s/step]Training:  43%|████▎     | 1276/3000 [43:11<38:41,  1.35s/step]Training:  43%|████▎     | 1277/3000 [43:12<38:40,  1.35s/step]Training:  43%|████▎     | 1278/3000 [43:13<38:38,  1.35s/step]Training:  43%|████▎     | 1279/3000 [43:15<38:37,  1.35s/step]Training:  43%|████▎     | 1280/3000 [43:16<38:37,  1.35s/step]Training:  43%|████▎     | 1281/3000 [43:17<38:35,  1.35s/step]Training:  43%|████▎     | 1282/3000 [43:19<38:33,  1.35s/step]Training:  43%|████▎     | 1283/3000 [43:20<38:32,  1.35s/step]Training:  43%|████▎     | 1284/3000 [43:21<38:31,  1.35s/step]Training:  43%|████▎     | 1285/3000 [43:23<38:29,  1.35s/step]Training:  43%|████▎     | 1286/3000 [43:24<38:28,  1.35s/step]Training:  43%|████▎     | 1287/3000 [43:25<38:27,  1.35s/step]Training:  43%|████▎     | 1288/3000 [43:27<38:25,  1.35s/step]Training:  43%|████▎     | 1289/3000 [43:28<38:24,  1.35s/step]Training:  43%|████▎     | 1290/3000 [43:30<38:23,  1.35s/step]Training:  43%|████▎     | 1291/3000 [43:31<38:21,  1.35s/step]Training:  43%|████▎     | 1292/3000 [43:32<38:20,  1.35s/step]Training:  43%|████▎     | 1293/3000 [43:34<38:19,  1.35s/step]Training:  43%|████▎     | 1294/3000 [43:35<38:17,  1.35s/step]Training:  43%|████▎     | 1295/3000 [43:36<38:16,  1.35s/step]Training:  43%|████▎     | 1296/3000 [43:38<38:14,  1.35s/step]Training:  43%|████▎     | 1297/3000 [43:39<38:13,  1.35s/step]Training:  43%|████▎     | 1298/3000 [43:40<38:11,  1.35s/step]Training:  43%|████▎     | 1299/3000 [43:42<38:10,  1.35s/step]Training:  43%|████▎     | 1300/3000 [43:43<38:09,  1.35s/step]11:52:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1595 lr=3.000e-04
11:52:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.0937 lr=3.000e-04
11:52:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1336 lr=3.000e-04
11:52:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1055 lr=3.000e-04
11:52:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1629 lr=3.000e-04
11:52:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1574 lr=3.000e-04
11:52:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1392 lr=3.000e-04
11:52:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=1300 loss=0.1968 lr=3.000e-04
Training:  43%|████▎     | 1301/3000 [43:44<38:09,  1.35s/step]Training:  43%|████▎     | 1302/3000 [43:46<38:07,  1.35s/step]Training:  43%|████▎     | 1303/3000 [43:47<38:06,  1.35s/step]Training:  43%|████▎     | 1304/3000 [43:48<38:04,  1.35s/step]Training:  44%|████▎     | 1305/3000 [43:50<38:03,  1.35s/step]Training:  44%|████▎     | 1306/3000 [43:51<38:01,  1.35s/step]Training:  44%|████▎     | 1307/3000 [43:52<38:00,  1.35s/step]Training:  44%|████▎     | 1308/3000 [43:54<37:59,  1.35s/step]Training:  44%|████▎     | 1309/3000 [43:55<37:57,  1.35s/step]Training:  44%|████▎     | 1310/3000 [43:56<37:56,  1.35s/step]Training:  44%|████▎     | 1311/3000 [43:58<37:54,  1.35s/step]Training:  44%|████▎     | 1312/3000 [43:59<37:53,  1.35s/step]Training:  44%|████▍     | 1313/3000 [44:01<37:52,  1.35s/step]Training:  44%|████▍     | 1314/3000 [44:02<37:50,  1.35s/step]Training:  44%|████▍     | 1315/3000 [44:03<37:49,  1.35s/step]Training:  44%|████▍     | 1316/3000 [44:05<37:47,  1.35s/step]Training:  44%|████▍     | 1317/3000 [44:06<37:46,  1.35s/step]Training:  44%|████▍     | 1318/3000 [44:07<37:44,  1.35s/step]Training:  44%|████▍     | 1319/3000 [44:09<37:43,  1.35s/step]Training:  44%|████▍     | 1320/3000 [44:10<37:42,  1.35s/step]Training:  44%|████▍     | 1321/3000 [44:11<37:40,  1.35s/step]Training:  44%|████▍     | 1322/3000 [44:13<37:39,  1.35s/step]Training:  44%|████▍     | 1323/3000 [44:14<37:38,  1.35s/step]Training:  44%|████▍     | 1324/3000 [44:15<37:36,  1.35s/step]Training:  44%|████▍     | 1325/3000 [44:17<37:35,  1.35s/step]Training:  44%|████▍     | 1326/3000 [44:18<37:34,  1.35s/step]Training:  44%|████▍     | 1327/3000 [44:19<37:32,  1.35s/step]Training:  44%|████▍     | 1328/3000 [44:21<37:31,  1.35s/step]Training:  44%|████▍     | 1329/3000 [44:22<37:29,  1.35s/step]Training:  44%|████▍     | 1330/3000 [44:23<37:28,  1.35s/step]Training:  44%|████▍     | 1331/3000 [44:25<37:28,  1.35s/step]Training:  44%|████▍     | 1332/3000 [44:26<37:26,  1.35s/step]Training:  44%|████▍     | 1333/3000 [44:27<37:25,  1.35s/step]Training:  44%|████▍     | 1334/3000 [44:29<37:24,  1.35s/step]Training:  44%|████▍     | 1335/3000 [44:30<37:22,  1.35s/step]Training:  45%|████▍     | 1336/3000 [44:31<37:21,  1.35s/step]Training:  45%|████▍     | 1337/3000 [44:33<37:20,  1.35s/step]Training:  45%|████▍     | 1338/3000 [44:34<37:18,  1.35s/step]Training:  45%|████▍     | 1339/3000 [44:36<37:16,  1.35s/step]Training:  45%|████▍     | 1340/3000 [44:37<37:15,  1.35s/step]Training:  45%|████▍     | 1341/3000 [44:38<37:14,  1.35s/step]Training:  45%|████▍     | 1342/3000 [44:40<37:12,  1.35s/step]Training:  45%|████▍     | 1343/3000 [44:41<37:12,  1.35s/step]Training:  45%|████▍     | 1344/3000 [44:42<37:10,  1.35s/step]Training:  45%|████▍     | 1345/3000 [44:44<37:08,  1.35s/step]Training:  45%|████▍     | 1346/3000 [44:45<37:07,  1.35s/step]Training:  45%|████▍     | 1347/3000 [44:46<37:06,  1.35s/step]Training:  45%|████▍     | 1348/3000 [44:48<37:04,  1.35s/step]Training:  45%|████▍     | 1349/3000 [44:49<37:04,  1.35s/step]Training:  45%|████▌     | 1350/3000 [44:50<37:02,  1.35s/step]11:53:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1617 lr=3.000e-04
11:53:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1786 lr=3.000e-04
11:54:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1288 lr=3.000e-04
11:54:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1636 lr=3.000e-04
11:54:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1096 lr=3.000e-04
11:54:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1016 lr=3.000e-04
11:54:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1694 lr=3.000e-04
11:54:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=1350 loss=0.1565 lr=3.000e-04
Training:  45%|████▌     | 1351/3000 [44:52<37:02,  1.35s/step]Training:  45%|████▌     | 1352/3000 [44:53<37:00,  1.35s/step]Training:  45%|████▌     | 1353/3000 [44:54<36:58,  1.35s/step]Training:  45%|████▌     | 1354/3000 [44:56<36:56,  1.35s/step]Training:  45%|████▌     | 1355/3000 [44:57<36:55,  1.35s/step]Training:  45%|████▌     | 1356/3000 [44:58<36:53,  1.35s/step]Training:  45%|████▌     | 1357/3000 [45:00<36:53,  1.35s/step]Training:  45%|████▌     | 1358/3000 [45:01<36:51,  1.35s/step]Training:  45%|████▌     | 1359/3000 [45:02<36:50,  1.35s/step]Training:  45%|████▌     | 1360/3000 [45:04<36:48,  1.35s/step]Training:  45%|████▌     | 1361/3000 [45:05<36:47,  1.35s/step]Training:  45%|████▌     | 1362/3000 [45:07<36:46,  1.35s/step]Training:  45%|████▌     | 1363/3000 [45:08<36:44,  1.35s/step]Training:  45%|████▌     | 1364/3000 [45:09<36:44,  1.35s/step]Training:  46%|████▌     | 1365/3000 [45:11<36:43,  1.35s/step]Training:  46%|████▌     | 1366/3000 [45:12<36:41,  1.35s/step]Training:  46%|████▌     | 1367/3000 [45:13<36:39,  1.35s/step]Training:  46%|████▌     | 1368/3000 [45:15<36:38,  1.35s/step]Training:  46%|████▌     | 1369/3000 [45:16<36:36,  1.35s/step]Training:  46%|████▌     | 1370/3000 [45:17<36:35,  1.35s/step]Training:  46%|████▌     | 1371/3000 [45:19<36:33,  1.35s/step]Training:  46%|████▌     | 1372/3000 [45:20<36:32,  1.35s/step]Training:  46%|████▌     | 1373/3000 [45:21<36:30,  1.35s/step]Training:  46%|████▌     | 1374/3000 [45:23<36:31,  1.35s/step]Training:  46%|████▌     | 1375/3000 [45:24<36:29,  1.35s/step]Training:  46%|████▌     | 1376/3000 [45:25<36:28,  1.35s/step]Training:  46%|████▌     | 1377/3000 [45:27<36:26,  1.35s/step]Training:  46%|████▌     | 1378/3000 [45:28<36:25,  1.35s/step]Training:  46%|████▌     | 1379/3000 [45:29<36:24,  1.35s/step]Training:  46%|████▌     | 1380/3000 [45:31<36:22,  1.35s/step]Training:  46%|████▌     | 1381/3000 [45:32<36:20,  1.35s/step]Training:  46%|████▌     | 1382/3000 [45:33<36:19,  1.35s/step]Training:  46%|████▌     | 1383/3000 [45:35<36:17,  1.35s/step]Training:  46%|████▌     | 1384/3000 [45:36<36:16,  1.35s/step]Training:  46%|████▌     | 1385/3000 [45:37<36:15,  1.35s/step]Training:  46%|████▌     | 1386/3000 [45:39<36:13,  1.35s/step]Training:  46%|████▌     | 1387/3000 [45:40<36:12,  1.35s/step]Training:  46%|████▋     | 1388/3000 [45:42<36:10,  1.35s/step]Training:  46%|████▋     | 1389/3000 [45:43<36:09,  1.35s/step]Training:  46%|████▋     | 1390/3000 [45:44<36:08,  1.35s/step]Training:  46%|████▋     | 1391/3000 [45:46<36:06,  1.35s/step]Training:  46%|████▋     | 1392/3000 [45:47<36:05,  1.35s/step]Training:  46%|████▋     | 1393/3000 [45:48<36:04,  1.35s/step]Training:  46%|████▋     | 1394/3000 [45:50<36:02,  1.35s/step]Training:  46%|████▋     | 1395/3000 [45:51<36:01,  1.35s/step]Training:  47%|████▋     | 1396/3000 [45:52<36:00,  1.35s/step]Training:  47%|████▋     | 1397/3000 [45:54<35:59,  1.35s/step]Training:  47%|████▋     | 1398/3000 [45:55<35:57,  1.35s/step]Training:  47%|████▋     | 1399/3000 [45:56<35:56,  1.35s/step]Training:  47%|████▋     | 1400/3000 [45:58<35:55,  1.35s/step]11:55:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1179 lr=3.000e-04
11:55:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1379 lr=3.000e-04
11:55:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1201 lr=3.000e-04
11:55:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1202 lr=3.000e-04
11:55:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1369 lr=3.000e-04
11:55:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1426 lr=3.000e-04
11:55:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.2248 lr=3.000e-04
11:55:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1400 loss=0.1641 lr=3.000e-04
Training:  47%|████▋     | 1401/3000 [45:59<35:54,  1.35s/step]Training:  47%|████▋     | 1402/3000 [46:00<35:53,  1.35s/step]Training:  47%|████▋     | 1403/3000 [46:02<35:51,  1.35s/step]Training:  47%|████▋     | 1404/3000 [46:03<35:49,  1.35s/step]Training:  47%|████▋     | 1405/3000 [46:04<35:48,  1.35s/step]Training:  47%|████▋     | 1406/3000 [46:06<35:47,  1.35s/step]Training:  47%|████▋     | 1407/3000 [46:07<35:45,  1.35s/step]Training:  47%|████▋     | 1408/3000 [46:08<35:44,  1.35s/step]Training:  47%|████▋     | 1409/3000 [46:10<35:42,  1.35s/step]Training:  47%|████▋     | 1410/3000 [46:11<35:41,  1.35s/step]Training:  47%|████▋     | 1411/3000 [46:13<35:39,  1.35s/step]Training:  47%|████▋     | 1412/3000 [46:14<35:38,  1.35s/step]Training:  47%|████▋     | 1413/3000 [46:15<35:37,  1.35s/step]Training:  47%|████▋     | 1414/3000 [46:17<35:36,  1.35s/step]Training:  47%|████▋     | 1415/3000 [46:18<35:34,  1.35s/step]Training:  47%|████▋     | 1416/3000 [46:19<35:33,  1.35s/step]Training:  47%|████▋     | 1417/3000 [46:21<35:31,  1.35s/step]Training:  47%|████▋     | 1418/3000 [46:22<35:30,  1.35s/step]Training:  47%|████▋     | 1419/3000 [46:23<35:28,  1.35s/step]Training:  47%|████▋     | 1420/3000 [46:25<35:27,  1.35s/step]Training:  47%|████▋     | 1421/3000 [46:26<35:26,  1.35s/step]Training:  47%|████▋     | 1422/3000 [46:27<35:25,  1.35s/step]Training:  47%|████▋     | 1423/3000 [46:29<35:23,  1.35s/step]Training:  47%|████▋     | 1424/3000 [46:30<35:22,  1.35s/step]Training:  48%|████▊     | 1425/3000 [46:31<35:20,  1.35s/step]Training:  48%|████▊     | 1426/3000 [46:33<35:20,  1.35s/step]Training:  48%|████▊     | 1427/3000 [46:34<35:18,  1.35s/step]Training:  48%|████▊     | 1428/3000 [46:35<35:17,  1.35s/step]Training:  48%|████▊     | 1429/3000 [46:37<35:15,  1.35s/step]Training:  48%|████▊     | 1430/3000 [46:38<35:14,  1.35s/step]Training:  48%|████▊     | 1431/3000 [46:39<35:13,  1.35s/step]Training:  48%|████▊     | 1432/3000 [46:41<35:12,  1.35s/step]Training:  48%|████▊     | 1433/3000 [46:42<35:10,  1.35s/step]Training:  48%|████▊     | 1434/3000 [46:43<35:09,  1.35s/step]Training:  48%|████▊     | 1435/3000 [46:45<35:07,  1.35s/step]Training:  48%|████▊     | 1436/3000 [46:46<35:06,  1.35s/step]Training:  48%|████▊     | 1437/3000 [46:48<35:05,  1.35s/step]Training:  48%|████▊     | 1438/3000 [46:49<35:03,  1.35s/step]Training:  48%|████▊     | 1439/3000 [46:50<35:02,  1.35s/step]Training:  48%|████▊     | 1440/3000 [46:52<35:01,  1.35s/step]Training:  48%|████▊     | 1441/3000 [46:53<34:59,  1.35s/step]Training:  48%|████▊     | 1442/3000 [46:54<34:58,  1.35s/step]Training:  48%|████▊     | 1443/3000 [46:56<34:57,  1.35s/step]Training:  48%|████▊     | 1444/3000 [46:57<34:56,  1.35s/step]Training:  48%|████▊     | 1445/3000 [46:58<34:54,  1.35s/step]Training:  48%|████▊     | 1446/3000 [47:00<34:53,  1.35s/step]Training:  48%|████▊     | 1447/3000 [47:01<34:52,  1.35s/step]Training:  48%|████▊     | 1448/3000 [47:02<34:51,  1.35s/step]Training:  48%|████▊     | 1449/3000 [47:04<34:49,  1.35s/step]Training:  48%|████▊     | 1450/3000 [47:05<34:47,  1.35s/step]11:56:14 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.1621 lr=3.000e-04
11:56:14 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.1191 lr=3.000e-04
11:56:14 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.0998 lr=3.000e-04
11:56:14 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.1210 lr=3.000e-04
11:56:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.2113 lr=3.000e-04
11:56:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.1528 lr=3.000e-04
11:56:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.1684 lr=3.000e-04
11:56:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1450 loss=0.1831 lr=3.000e-04
Training:  48%|████▊     | 1451/3000 [47:06<34:46,  1.35s/step]Training:  48%|████▊     | 1452/3000 [47:08<34:44,  1.35s/step]Training:  48%|████▊     | 1453/3000 [47:09<34:43,  1.35s/step]Training:  48%|████▊     | 1454/3000 [47:10<34:42,  1.35s/step]Training:  48%|████▊     | 1455/3000 [47:12<34:40,  1.35s/step]Training:  49%|████▊     | 1456/3000 [47:13<34:39,  1.35s/step]Training:  49%|████▊     | 1457/3000 [47:14<34:37,  1.35s/step]Training:  49%|████▊     | 1458/3000 [47:16<34:36,  1.35s/step]Training:  49%|████▊     | 1459/3000 [47:17<34:35,  1.35s/step]Training:  49%|████▊     | 1460/3000 [47:19<34:34,  1.35s/step]Training:  49%|████▊     | 1461/3000 [47:20<34:32,  1.35s/step]Training:  49%|████▊     | 1462/3000 [47:21<34:31,  1.35s/step]Training:  49%|████▉     | 1463/3000 [47:23<34:29,  1.35s/step]Training:  49%|████▉     | 1464/3000 [47:24<34:29,  1.35s/step]Training:  49%|████▉     | 1465/3000 [47:25<34:28,  1.35s/step]Training:  49%|████▉     | 1466/3000 [47:27<34:27,  1.35s/step]Training:  49%|████▉     | 1467/3000 [47:28<34:26,  1.35s/step]Training:  49%|████▉     | 1468/3000 [47:29<34:24,  1.35s/step]Training:  49%|████▉     | 1469/3000 [47:31<34:23,  1.35s/step]Training:  49%|████▉     | 1470/3000 [47:32<34:21,  1.35s/step]Training:  49%|████▉     | 1471/3000 [47:33<34:20,  1.35s/step]Training:  49%|████▉     | 1472/3000 [47:35<34:18,  1.35s/step]Training:  49%|████▉     | 1473/3000 [47:36<34:17,  1.35s/step]Training:  49%|████▉     | 1474/3000 [47:37<34:15,  1.35s/step]Training:  49%|████▉     | 1475/3000 [47:39<34:13,  1.35s/step]Training:  49%|████▉     | 1476/3000 [47:40<34:12,  1.35s/step]Training:  49%|████▉     | 1477/3000 [47:41<34:10,  1.35s/step]Training:  49%|████▉     | 1478/3000 [47:43<34:09,  1.35s/step]Training:  49%|████▉     | 1479/3000 [47:44<34:08,  1.35s/step]Training:  49%|████▉     | 1480/3000 [47:45<34:07,  1.35s/step]Training:  49%|████▉     | 1481/3000 [47:47<34:05,  1.35s/step]Training:  49%|████▉     | 1482/3000 [47:48<34:04,  1.35s/step]Training:  49%|████▉     | 1483/3000 [47:49<34:02,  1.35s/step]Training:  49%|████▉     | 1484/3000 [47:51<34:01,  1.35s/step]Training:  50%|████▉     | 1485/3000 [47:52<34:00,  1.35s/step]Training:  50%|████▉     | 1486/3000 [47:54<34:00,  1.35s/step]Training:  50%|████▉     | 1487/3000 [47:55<33:58,  1.35s/step]Training:  50%|████▉     | 1488/3000 [47:56<33:57,  1.35s/step]Training:  50%|████▉     | 1489/3000 [47:58<33:55,  1.35s/step]Training:  50%|████▉     | 1490/3000 [47:59<33:55,  1.35s/step]Training:  50%|████▉     | 1491/3000 [48:00<33:53,  1.35s/step]Training:  50%|████▉     | 1492/3000 [48:02<33:51,  1.35s/step]Training:  50%|████▉     | 1493/3000 [48:03<33:50,  1.35s/step]Training:  50%|████▉     | 1494/3000 [48:04<33:48,  1.35s/step]Training:  50%|████▉     | 1495/3000 [48:06<33:46,  1.35s/step]Training:  50%|████▉     | 1496/3000 [48:07<33:45,  1.35s/step]Training:  50%|████▉     | 1497/3000 [48:08<33:43,  1.35s/step]Training:  50%|████▉     | 1498/3000 [48:10<33:42,  1.35s/step]Training:  50%|████▉     | 1499/3000 [48:11<33:41,  1.35s/step]Training:  50%|█████     | 1500/3000 [48:12<33:40,  1.35s/step]11:57:21 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1725 lr=3.000e-04
11:57:43 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:57:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1307 lr=3.000e-04
11:58:06 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:58:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1308 lr=3.000e-04
11:58:28 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:58:28 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1402 lr=3.000e-04
11:58:50 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:58:51 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1167 lr=3.000e-04
11:59:13 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:59:13 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.0900 lr=3.000e-04
11:59:35 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:59:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1205 lr=3.000e-04
11:59:57 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
11:59:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=1500 loss=0.1801 lr=3.000e-04
12:00:20 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1500 loss=1.1517 ppl=3.16
Training:  50%|█████     | 1501/3000 [51:11<22:41:26, 54.49s/step]Training:  50%|█████     | 1502/3000 [51:12<16:02:27, 38.55s/step]Training:  50%|█████     | 1503/3000 [51:14<11:23:21, 27.39s/step]Training:  50%|█████     | 1504/3000 [51:15<8:08:05, 19.58s/step] Training:  50%|█████     | 1505/3000 [51:16<5:51:30, 14.11s/step]Training:  50%|█████     | 1506/3000 [51:18<4:15:56, 10.28s/step]Training:  50%|█████     | 1507/3000 [51:19<3:09:05,  7.60s/step]Training:  50%|█████     | 1508/3000 [51:20<2:22:20,  5.72s/step]Training:  50%|█████     | 1509/3000 [51:22<1:49:36,  4.41s/step]Training:  50%|█████     | 1510/3000 [51:23<1:26:42,  3.49s/step]Training:  50%|█████     | 1511/3000 [51:24<1:10:40,  2.85s/step]Training:  50%|█████     | 1512/3000 [51:26<59:27,  2.40s/step]  Training:  50%|█████     | 1513/3000 [51:27<51:36,  2.08s/step]Training:  50%|█████     | 1514/3000 [51:28<46:07,  1.86s/step]Training:  50%|█████     | 1515/3000 [51:30<42:15,  1.71s/step]Training:  51%|█████     | 1516/3000 [51:31<39:33,  1.60s/step]Training:  51%|█████     | 1517/3000 [51:32<37:39,  1.52s/step]Training:  51%|█████     | 1518/3000 [51:34<36:19,  1.47s/step]Training:  51%|█████     | 1519/3000 [51:35<35:22,  1.43s/step]Training:  51%|█████     | 1520/3000 [51:36<34:42,  1.41s/step]Training:  51%|█████     | 1521/3000 [51:38<34:14,  1.39s/step]Training:  51%|█████     | 1522/3000 [51:39<33:54,  1.38s/step]Training:  51%|█████     | 1523/3000 [51:41<33:39,  1.37s/step]Training:  51%|█████     | 1524/3000 [51:42<33:29,  1.36s/step]Training:  51%|█████     | 1525/3000 [51:43<33:21,  1.36s/step]Training:  51%|█████     | 1526/3000 [51:45<33:15,  1.35s/step]Training:  51%|█████     | 1527/3000 [51:46<33:10,  1.35s/step]Training:  51%|█████     | 1528/3000 [51:47<33:07,  1.35s/step]Training:  51%|█████     | 1529/3000 [51:49<33:04,  1.35s/step]Training:  51%|█████     | 1530/3000 [51:50<33:02,  1.35s/step]Training:  51%|█████     | 1531/3000 [51:51<33:00,  1.35s/step]Training:  51%|█████     | 1532/3000 [51:53<32:58,  1.35s/step]Training:  51%|█████     | 1533/3000 [51:54<32:56,  1.35s/step]Training:  51%|█████     | 1534/3000 [51:55<32:54,  1.35s/step]Training:  51%|█████     | 1535/3000 [51:57<32:53,  1.35s/step]Training:  51%|█████     | 1536/3000 [51:58<32:51,  1.35s/step]Training:  51%|█████     | 1537/3000 [51:59<32:50,  1.35s/step]Training:  51%|█████▏    | 1538/3000 [52:01<32:49,  1.35s/step]Training:  51%|█████▏    | 1539/3000 [52:02<32:47,  1.35s/step]Training:  51%|█████▏    | 1540/3000 [52:03<32:46,  1.35s/step]Training:  51%|█████▏    | 1541/3000 [52:05<32:44,  1.35s/step]Training:  51%|█████▏    | 1542/3000 [52:06<32:43,  1.35s/step]Training:  51%|█████▏    | 1543/3000 [52:07<32:41,  1.35s/step]Training:  51%|█████▏    | 1544/3000 [52:09<32:40,  1.35s/step]Training:  52%|█████▏    | 1545/3000 [52:10<32:39,  1.35s/step]Training:  52%|█████▏    | 1546/3000 [52:11<32:37,  1.35s/step]Training:  52%|█████▏    | 1547/3000 [52:13<32:36,  1.35s/step]Training:  52%|█████▏    | 1548/3000 [52:14<32:34,  1.35s/step]Training:  52%|█████▏    | 1549/3000 [52:16<32:34,  1.35s/step]Training:  52%|█████▏    | 1550/3000 [52:17<32:32,  1.35s/step]12:01:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.0933 lr=3.000e-04
12:01:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1231 lr=3.000e-04
12:01:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1115 lr=3.000e-04
12:01:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1022 lr=3.000e-04
12:01:26 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1214 lr=3.000e-04
12:01:27 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1100 lr=3.000e-04
12:01:27 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1782 lr=3.000e-04
12:01:27 - trainer.gpt2-gsm8k-lora-main - INFO - step=1550 loss=0.1342 lr=3.000e-04
Training:  52%|█████▏    | 1551/3000 [52:18<32:31,  1.35s/step]Training:  52%|█████▏    | 1552/3000 [52:20<32:29,  1.35s/step]Training:  52%|█████▏    | 1553/3000 [52:21<32:28,  1.35s/step]Training:  52%|█████▏    | 1554/3000 [52:22<32:26,  1.35s/step]Training:  52%|█████▏    | 1555/3000 [52:24<32:25,  1.35s/step]Training:  52%|█████▏    | 1556/3000 [52:25<32:25,  1.35s/step]Training:  52%|█████▏    | 1557/3000 [52:26<32:25,  1.35s/step]Training:  52%|█████▏    | 1558/3000 [52:28<32:23,  1.35s/step]Training:  52%|█████▏    | 1559/3000 [52:29<32:21,  1.35s/step]Training:  52%|█████▏    | 1560/3000 [52:30<32:20,  1.35s/step]Training:  52%|█████▏    | 1561/3000 [52:32<32:18,  1.35s/step]Training:  52%|█████▏    | 1562/3000 [52:33<32:17,  1.35s/step]Training:  52%|█████▏    | 1563/3000 [52:34<32:15,  1.35s/step]Training:  52%|█████▏    | 1564/3000 [52:36<32:14,  1.35s/step]Training:  52%|█████▏    | 1565/3000 [52:37<32:12,  1.35s/step]Training:  52%|█████▏    | 1566/3000 [52:38<32:11,  1.35s/step]Training:  52%|█████▏    | 1567/3000 [52:40<32:09,  1.35s/step]Training:  52%|█████▏    | 1568/3000 [52:41<32:08,  1.35s/step]Training:  52%|█████▏    | 1569/3000 [52:42<32:07,  1.35s/step]Training:  52%|█████▏    | 1570/3000 [52:44<32:06,  1.35s/step]Training:  52%|█████▏    | 1571/3000 [52:45<32:04,  1.35s/step]Training:  52%|█████▏    | 1572/3000 [52:47<32:02,  1.35s/step]Training:  52%|█████▏    | 1573/3000 [52:48<32:01,  1.35s/step]Training:  52%|█████▏    | 1574/3000 [52:49<32:00,  1.35s/step]Training:  52%|█████▎    | 1575/3000 [52:51<31:58,  1.35s/step]Training:  53%|█████▎    | 1576/3000 [52:52<31:57,  1.35s/step]Training:  53%|█████▎    | 1577/3000 [52:53<31:56,  1.35s/step]Training:  53%|█████▎    | 1578/3000 [52:55<31:54,  1.35s/step]Training:  53%|█████▎    | 1579/3000 [52:56<31:53,  1.35s/step]Training:  53%|█████▎    | 1580/3000 [52:57<31:52,  1.35s/step]Training:  53%|█████▎    | 1581/3000 [52:59<31:50,  1.35s/step]Training:  53%|█████▎    | 1582/3000 [53:00<31:50,  1.35s/step]Training:  53%|█████▎    | 1583/3000 [53:01<31:48,  1.35s/step]Training:  53%|█████▎    | 1584/3000 [53:03<31:47,  1.35s/step]Training:  53%|█████▎    | 1585/3000 [53:04<31:45,  1.35s/step]Training:  53%|█████▎    | 1586/3000 [53:05<31:44,  1.35s/step]Training:  53%|█████▎    | 1587/3000 [53:07<31:42,  1.35s/step]Training:  53%|█████▎    | 1588/3000 [53:08<31:41,  1.35s/step]Training:  53%|█████▎    | 1589/3000 [53:09<31:39,  1.35s/step]Training:  53%|█████▎    | 1590/3000 [53:11<31:38,  1.35s/step]Training:  53%|█████▎    | 1591/3000 [53:12<31:37,  1.35s/step]Training:  53%|█████▎    | 1592/3000 [53:13<31:36,  1.35s/step]Training:  53%|█████▎    | 1593/3000 [53:15<31:35,  1.35s/step]Training:  53%|█████▎    | 1594/3000 [53:16<31:33,  1.35s/step]Training:  53%|█████▎    | 1595/3000 [53:17<31:32,  1.35s/step]Training:  53%|█████▎    | 1596/3000 [53:19<31:30,  1.35s/step]Training:  53%|█████▎    | 1597/3000 [53:20<31:29,  1.35s/step]Training:  53%|█████▎    | 1598/3000 [53:22<31:28,  1.35s/step]Training:  53%|█████▎    | 1599/3000 [53:23<31:27,  1.35s/step]Training:  53%|█████▎    | 1600/3000 [53:24<31:25,  1.35s/step]12:02:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.1178 lr=3.000e-04
12:02:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.1024 lr=3.000e-04
12:02:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.0878 lr=3.000e-04
12:02:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.1395 lr=3.000e-04
12:02:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.1529 lr=3.000e-04
12:02:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.1208 lr=3.000e-04
12:02:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.2424 lr=3.000e-04
12:02:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=1600 loss=0.1199 lr=3.000e-04
Training:  53%|█████▎    | 1601/3000 [53:26<31:24,  1.35s/step]Training:  53%|█████▎    | 1602/3000 [53:27<31:23,  1.35s/step]Training:  53%|█████▎    | 1603/3000 [53:28<31:22,  1.35s/step]Training:  53%|█████▎    | 1604/3000 [53:30<31:20,  1.35s/step]Training:  54%|█████▎    | 1605/3000 [53:31<31:18,  1.35s/step]Training:  54%|█████▎    | 1606/3000 [53:32<31:17,  1.35s/step]Training:  54%|█████▎    | 1607/3000 [53:34<31:16,  1.35s/step]Training:  54%|█████▎    | 1608/3000 [53:35<31:15,  1.35s/step]Training:  54%|█████▎    | 1609/3000 [53:36<31:13,  1.35s/step]Training:  54%|█████▎    | 1610/3000 [53:38<31:12,  1.35s/step]Training:  54%|█████▎    | 1611/3000 [53:39<31:10,  1.35s/step]Training:  54%|█████▎    | 1612/3000 [53:40<31:09,  1.35s/step]Training:  54%|█████▍    | 1613/3000 [53:42<31:08,  1.35s/step]Training:  54%|█████▍    | 1614/3000 [53:43<31:06,  1.35s/step]Training:  54%|█████▍    | 1615/3000 [53:44<31:05,  1.35s/step]Training:  54%|█████▍    | 1616/3000 [53:46<31:03,  1.35s/step]Training:  54%|█████▍    | 1617/3000 [53:47<31:02,  1.35s/step]Training:  54%|█████▍    | 1618/3000 [53:48<31:00,  1.35s/step]Training:  54%|█████▍    | 1619/3000 [53:50<30:59,  1.35s/step]Training:  54%|█████▍    | 1620/3000 [53:51<30:58,  1.35s/step]Training:  54%|█████▍    | 1621/3000 [53:53<30:57,  1.35s/step]Training:  54%|█████▍    | 1622/3000 [53:54<30:58,  1.35s/step]Training:  54%|█████▍    | 1623/3000 [53:55<30:56,  1.35s/step]Training:  54%|█████▍    | 1624/3000 [53:57<30:54,  1.35s/step]Training:  54%|█████▍    | 1625/3000 [53:58<30:52,  1.35s/step]Training:  54%|█████▍    | 1626/3000 [53:59<30:52,  1.35s/step]Training:  54%|█████▍    | 1627/3000 [54:01<30:50,  1.35s/step]Training:  54%|█████▍    | 1628/3000 [54:02<30:48,  1.35s/step]Training:  54%|█████▍    | 1629/3000 [54:03<30:47,  1.35s/step]Training:  54%|█████▍    | 1630/3000 [54:05<30:45,  1.35s/step]Training:  54%|█████▍    | 1631/3000 [54:06<30:44,  1.35s/step]Training:  54%|█████▍    | 1632/3000 [54:07<30:42,  1.35s/step]Training:  54%|█████▍    | 1633/3000 [54:09<30:41,  1.35s/step]Training:  54%|█████▍    | 1634/3000 [54:10<30:39,  1.35s/step]Training:  55%|█████▍    | 1635/3000 [54:11<30:38,  1.35s/step]Training:  55%|█████▍    | 1636/3000 [54:13<30:37,  1.35s/step]Training:  55%|█████▍    | 1637/3000 [54:14<30:36,  1.35s/step]Training:  55%|█████▍    | 1638/3000 [54:15<30:34,  1.35s/step]Training:  55%|█████▍    | 1639/3000 [54:17<30:32,  1.35s/step]Training:  55%|█████▍    | 1640/3000 [54:18<30:31,  1.35s/step]Training:  55%|█████▍    | 1641/3000 [54:19<30:30,  1.35s/step]Training:  55%|█████▍    | 1642/3000 [54:21<30:28,  1.35s/step]Training:  55%|█████▍    | 1643/3000 [54:22<30:27,  1.35s/step]Training:  55%|█████▍    | 1644/3000 [54:23<30:26,  1.35s/step]Training:  55%|█████▍    | 1645/3000 [54:25<30:25,  1.35s/step]Training:  55%|█████▍    | 1646/3000 [54:26<30:23,  1.35s/step]Training:  55%|█████▍    | 1647/3000 [54:28<30:22,  1.35s/step]Training:  55%|█████▍    | 1648/3000 [54:29<30:21,  1.35s/step]Training:  55%|█████▍    | 1649/3000 [54:30<30:19,  1.35s/step]Training:  55%|█████▌    | 1650/3000 [54:32<30:18,  1.35s/step]12:03:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1120 lr=3.000e-04
12:03:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1889 lr=3.000e-04
12:03:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1330 lr=3.000e-04
12:03:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.2470 lr=3.000e-04
12:03:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1523 lr=3.000e-04
12:03:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1541 lr=3.000e-04
12:03:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1340 lr=3.000e-04
12:03:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=1650 loss=0.1025 lr=3.000e-04
Training:  55%|█████▌    | 1651/3000 [54:33<30:17,  1.35s/step]Training:  55%|█████▌    | 1652/3000 [54:34<30:15,  1.35s/step]Training:  55%|█████▌    | 1653/3000 [54:36<30:14,  1.35s/step]Training:  55%|█████▌    | 1654/3000 [54:37<30:13,  1.35s/step]Training:  55%|█████▌    | 1655/3000 [54:38<30:11,  1.35s/step]Training:  55%|█████▌    | 1656/3000 [54:40<30:09,  1.35s/step]Training:  55%|█████▌    | 1657/3000 [54:41<30:08,  1.35s/step]Training:  55%|█████▌    | 1658/3000 [54:42<30:07,  1.35s/step]Training:  55%|█████▌    | 1659/3000 [54:44<30:05,  1.35s/step]Training:  55%|█████▌    | 1660/3000 [54:45<30:04,  1.35s/step]Training:  55%|█████▌    | 1661/3000 [54:46<30:02,  1.35s/step]Training:  55%|█████▌    | 1662/3000 [54:48<30:01,  1.35s/step]Training:  55%|█████▌    | 1663/3000 [54:49<30:00,  1.35s/step]Training:  55%|█████▌    | 1664/3000 [54:50<29:58,  1.35s/step]Training:  56%|█████▌    | 1665/3000 [54:52<29:57,  1.35s/step]Training:  56%|█████▌    | 1666/3000 [54:53<29:56,  1.35s/step]Training:  56%|█████▌    | 1667/3000 [54:54<29:55,  1.35s/step]Training:  56%|█████▌    | 1668/3000 [54:56<29:53,  1.35s/step]Training:  56%|█████▌    | 1669/3000 [54:57<29:52,  1.35s/step]Training:  56%|█████▌    | 1670/3000 [54:59<29:50,  1.35s/step]Training:  56%|█████▌    | 1671/3000 [55:00<29:49,  1.35s/step]Training:  56%|█████▌    | 1672/3000 [55:01<29:48,  1.35s/step]Training:  56%|█████▌    | 1673/3000 [55:03<29:47,  1.35s/step]Training:  56%|█████▌    | 1674/3000 [55:04<29:45,  1.35s/step]Training:  56%|█████▌    | 1675/3000 [55:05<29:44,  1.35s/step]Training:  56%|█████▌    | 1676/3000 [55:07<29:42,  1.35s/step]Training:  56%|█████▌    | 1677/3000 [55:08<29:41,  1.35s/step]Training:  56%|█████▌    | 1678/3000 [55:09<29:40,  1.35s/step]Training:  56%|█████▌    | 1679/3000 [55:11<29:38,  1.35s/step]Training:  56%|█████▌    | 1680/3000 [55:12<29:37,  1.35s/step]Training:  56%|█████▌    | 1681/3000 [55:13<29:35,  1.35s/step]Training:  56%|█████▌    | 1682/3000 [55:15<29:34,  1.35s/step]Training:  56%|█████▌    | 1683/3000 [55:16<29:33,  1.35s/step]Training:  56%|█████▌    | 1684/3000 [55:17<29:31,  1.35s/step]Training:  56%|█████▌    | 1685/3000 [55:19<29:30,  1.35s/step]Training:  56%|█████▌    | 1686/3000 [55:20<29:29,  1.35s/step]Training:  56%|█████▌    | 1687/3000 [55:21<29:27,  1.35s/step]Training:  56%|█████▋    | 1688/3000 [55:23<29:26,  1.35s/step]Training:  56%|█████▋    | 1689/3000 [55:24<29:25,  1.35s/step]Training:  56%|█████▋    | 1690/3000 [55:25<29:23,  1.35s/step]Training:  56%|█████▋    | 1691/3000 [55:27<29:22,  1.35s/step]Training:  56%|█████▋    | 1692/3000 [55:28<29:22,  1.35s/step]Training:  56%|█████▋    | 1693/3000 [55:29<29:20,  1.35s/step]Training:  56%|█████▋    | 1694/3000 [55:31<29:19,  1.35s/step]Training:  56%|█████▋    | 1695/3000 [55:32<29:18,  1.35s/step]Training:  57%|█████▋    | 1696/3000 [55:34<29:16,  1.35s/step]Training:  57%|█████▋    | 1697/3000 [55:35<29:15,  1.35s/step]Training:  57%|█████▋    | 1698/3000 [55:36<29:13,  1.35s/step]Training:  57%|█████▋    | 1699/3000 [55:38<29:12,  1.35s/step]Training:  57%|█████▋    | 1700/3000 [55:39<29:11,  1.35s/step]12:04:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.1152 lr=3.000e-04
12:04:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.1563 lr=3.000e-04
12:04:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.1395 lr=3.000e-04
12:04:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.1828 lr=3.000e-04
12:04:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.1106 lr=3.000e-04
12:04:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.0960 lr=3.000e-04
12:04:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.1055 lr=3.000e-04
12:04:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=1700 loss=0.2322 lr=3.000e-04
Training:  57%|█████▋    | 1701/3000 [55:40<29:10,  1.35s/step]Training:  57%|█████▋    | 1702/3000 [55:42<29:08,  1.35s/step]Training:  57%|█████▋    | 1703/3000 [55:43<29:07,  1.35s/step]Training:  57%|█████▋    | 1704/3000 [55:44<29:05,  1.35s/step]Training:  57%|█████▋    | 1705/3000 [55:46<29:04,  1.35s/step]Training:  57%|█████▋    | 1706/3000 [55:47<29:03,  1.35s/step]Training:  57%|█████▋    | 1707/3000 [55:48<29:01,  1.35s/step]Training:  57%|█████▋    | 1708/3000 [55:50<29:00,  1.35s/step]Training:  57%|█████▋    | 1709/3000 [55:51<28:58,  1.35s/step]Training:  57%|█████▋    | 1710/3000 [55:52<28:57,  1.35s/step]Training:  57%|█████▋    | 1711/3000 [55:54<28:55,  1.35s/step]Training:  57%|█████▋    | 1712/3000 [55:55<28:54,  1.35s/step]Training:  57%|█████▋    | 1713/3000 [55:56<28:53,  1.35s/step]Training:  57%|█████▋    | 1714/3000 [55:58<28:51,  1.35s/step]Training:  57%|█████▋    | 1715/3000 [55:59<28:51,  1.35s/step]Training:  57%|█████▋    | 1716/3000 [56:00<28:49,  1.35s/step]Training:  57%|█████▋    | 1717/3000 [56:02<28:48,  1.35s/step]Training:  57%|█████▋    | 1718/3000 [56:03<28:47,  1.35s/step]Training:  57%|█████▋    | 1719/3000 [56:04<28:45,  1.35s/step]Training:  57%|█████▋    | 1720/3000 [56:06<28:43,  1.35s/step]Training:  57%|█████▋    | 1721/3000 [56:07<28:42,  1.35s/step]Training:  57%|█████▋    | 1722/3000 [56:09<28:40,  1.35s/step]Training:  57%|█████▋    | 1723/3000 [56:10<28:39,  1.35s/step]Training:  57%|█████▋    | 1724/3000 [56:11<28:38,  1.35s/step]Training:  57%|█████▊    | 1725/3000 [56:13<28:36,  1.35s/step]Training:  58%|█████▊    | 1726/3000 [56:14<28:35,  1.35s/step]Training:  58%|█████▊    | 1727/3000 [56:15<28:34,  1.35s/step]Training:  58%|█████▊    | 1728/3000 [56:17<28:33,  1.35s/step]Training:  58%|█████▊    | 1729/3000 [56:18<28:31,  1.35s/step]Training:  58%|█████▊    | 1730/3000 [56:19<28:30,  1.35s/step]Training:  58%|█████▊    | 1731/3000 [56:21<28:29,  1.35s/step]Training:  58%|█████▊    | 1732/3000 [56:22<28:27,  1.35s/step]Training:  58%|█████▊    | 1733/3000 [56:23<28:28,  1.35s/step]Training:  58%|█████▊    | 1734/3000 [56:25<28:26,  1.35s/step]Training:  58%|█████▊    | 1735/3000 [56:26<28:24,  1.35s/step]Training:  58%|█████▊    | 1736/3000 [56:27<28:23,  1.35s/step]Training:  58%|█████▊    | 1737/3000 [56:29<28:21,  1.35s/step]Training:  58%|█████▊    | 1738/3000 [56:30<28:20,  1.35s/step]Training:  58%|█████▊    | 1739/3000 [56:31<28:18,  1.35s/step]Training:  58%|█████▊    | 1740/3000 [56:33<28:17,  1.35s/step]Training:  58%|█████▊    | 1741/3000 [56:34<28:15,  1.35s/step]Training:  58%|█████▊    | 1742/3000 [56:35<28:14,  1.35s/step]Training:  58%|█████▊    | 1743/3000 [56:37<28:12,  1.35s/step]Training:  58%|█████▊    | 1744/3000 [56:38<28:11,  1.35s/step]Training:  58%|█████▊    | 1745/3000 [56:40<28:10,  1.35s/step]Training:  58%|█████▊    | 1746/3000 [56:41<28:08,  1.35s/step]Training:  58%|█████▊    | 1747/3000 [56:42<28:07,  1.35s/step]Training:  58%|█████▊    | 1748/3000 [56:44<28:06,  1.35s/step]Training:  58%|█████▊    | 1749/3000 [56:45<28:04,  1.35s/step]Training:  58%|█████▊    | 1750/3000 [56:46<28:03,  1.35s/step]12:05:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1165 lr=3.000e-04
12:05:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1523 lr=3.000e-04
12:05:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1990 lr=3.000e-04
12:05:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1127 lr=3.000e-04
12:05:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1289 lr=3.000e-04
12:05:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1616 lr=3.000e-04
12:05:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1583 lr=3.000e-04
12:05:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=1750 loss=0.1258 lr=3.000e-04
Training:  58%|█████▊    | 1751/3000 [56:48<28:02,  1.35s/step]Training:  58%|█████▊    | 1752/3000 [56:49<28:01,  1.35s/step]Training:  58%|█████▊    | 1753/3000 [56:50<27:59,  1.35s/step]Training:  58%|█████▊    | 1754/3000 [56:52<27:58,  1.35s/step]Training:  58%|█████▊    | 1755/3000 [56:53<27:57,  1.35s/step]Training:  59%|█████▊    | 1756/3000 [56:54<27:55,  1.35s/step]Training:  59%|█████▊    | 1757/3000 [56:56<27:54,  1.35s/step]Training:  59%|█████▊    | 1758/3000 [56:57<27:53,  1.35s/step]Training:  59%|█████▊    | 1759/3000 [56:58<27:51,  1.35s/step]Training:  59%|█████▊    | 1760/3000 [57:00<27:50,  1.35s/step]Training:  59%|█████▊    | 1761/3000 [57:01<27:49,  1.35s/step]Training:  59%|█████▊    | 1762/3000 [57:02<27:47,  1.35s/step]Training:  59%|█████▉    | 1763/3000 [57:04<27:46,  1.35s/step]Training:  59%|█████▉    | 1764/3000 [57:05<27:44,  1.35s/step]Training:  59%|█████▉    | 1765/3000 [57:06<27:43,  1.35s/step]Training:  59%|█████▉    | 1766/3000 [57:08<27:41,  1.35s/step]Training:  59%|█████▉    | 1767/3000 [57:09<27:40,  1.35s/step]Training:  59%|█████▉    | 1768/3000 [57:10<27:38,  1.35s/step]Training:  59%|█████▉    | 1769/3000 [57:12<27:37,  1.35s/step]Training:  59%|█████▉    | 1770/3000 [57:13<27:36,  1.35s/step]Training:  59%|█████▉    | 1771/3000 [57:15<27:34,  1.35s/step]Training:  59%|█████▉    | 1772/3000 [57:16<27:33,  1.35s/step]Training:  59%|█████▉    | 1773/3000 [57:17<27:32,  1.35s/step]Training:  59%|█████▉    | 1774/3000 [57:19<27:30,  1.35s/step]Training:  59%|█████▉    | 1775/3000 [57:20<27:29,  1.35s/step]Training:  59%|█████▉    | 1776/3000 [57:21<27:28,  1.35s/step]Training:  59%|█████▉    | 1777/3000 [57:23<27:26,  1.35s/step]Training:  59%|█████▉    | 1778/3000 [57:24<27:25,  1.35s/step]Training:  59%|█████▉    | 1779/3000 [57:25<27:25,  1.35s/step]Training:  59%|█████▉    | 1780/3000 [57:27<27:24,  1.35s/step]Training:  59%|█████▉    | 1781/3000 [57:28<27:23,  1.35s/step]Training:  59%|█████▉    | 1782/3000 [57:29<27:21,  1.35s/step]Training:  59%|█████▉    | 1783/3000 [57:31<27:19,  1.35s/step]Training:  59%|█████▉    | 1784/3000 [57:32<27:18,  1.35s/step]Training:  60%|█████▉    | 1785/3000 [57:33<27:16,  1.35s/step]Training:  60%|█████▉    | 1786/3000 [57:35<27:15,  1.35s/step]Training:  60%|█████▉    | 1787/3000 [57:36<27:13,  1.35s/step]Training:  60%|█████▉    | 1788/3000 [57:37<27:12,  1.35s/step]Training:  60%|█████▉    | 1789/3000 [57:39<27:11,  1.35s/step]Training:  60%|█████▉    | 1790/3000 [57:40<27:09,  1.35s/step]Training:  60%|█████▉    | 1791/3000 [57:41<27:08,  1.35s/step]Training:  60%|█████▉    | 1792/3000 [57:43<27:06,  1.35s/step]Training:  60%|█████▉    | 1793/3000 [57:44<27:05,  1.35s/step]Training:  60%|█████▉    | 1794/3000 [57:46<27:04,  1.35s/step]Training:  60%|█████▉    | 1795/3000 [57:47<27:02,  1.35s/step]Training:  60%|█████▉    | 1796/3000 [57:48<27:01,  1.35s/step]Training:  60%|█████▉    | 1797/3000 [57:50<27:00,  1.35s/step]Training:  60%|█████▉    | 1798/3000 [57:51<26:59,  1.35s/step]Training:  60%|█████▉    | 1799/3000 [57:52<26:57,  1.35s/step]Training:  60%|██████    | 1800/3000 [57:54<26:57,  1.35s/step]12:07:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1874 lr=3.000e-04
12:07:25 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:07:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1295 lr=3.000e-04
12:07:47 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:07:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1021 lr=3.000e-04
12:08:09 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:08:10 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1312 lr=3.000e-04
12:08:32 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:08:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1772 lr=3.000e-04
12:08:54 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:08:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1036 lr=3.000e-04
12:09:16 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:09:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1875 lr=3.000e-04
12:09:39 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
12:09:39 - trainer.gpt2-gsm8k-lora-main - INFO - step=1800 loss=0.1353 lr=3.000e-04
12:10:01 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=1800 loss=1.1423 ppl=3.13
Training:  60%|██████    | 1801/3000 [1:00:52<18:08:48, 54.49s/step]Training:  60%|██████    | 1802/3000 [1:00:53<12:49:37, 38.55s/step]Training:  60%|██████    | 1803/3000 [1:00:55<9:06:20, 27.39s/step] Training:  60%|██████    | 1804/3000 [1:00:56<6:30:10, 19.57s/step]Training:  60%|██████    | 1805/3000 [1:00:57<4:40:56, 14.11s/step]Training:  60%|██████    | 1806/3000 [1:00:59<3:24:31, 10.28s/step]Training:  60%|██████    | 1807/3000 [1:01:00<2:31:05,  7.60s/step]Training:  60%|██████    | 1808/3000 [1:01:02<1:53:42,  5.72s/step]Training:  60%|██████    | 1809/3000 [1:01:03<1:27:33,  4.41s/step]Training:  60%|██████    | 1810/3000 [1:01:04<1:09:14,  3.49s/step]Training:  60%|██████    | 1811/3000 [1:01:06<56:26,  2.85s/step]  Training:  60%|██████    | 1812/3000 [1:01:07<47:28,  2.40s/step]Training:  60%|██████    | 1813/3000 [1:01:08<41:11,  2.08s/step]Training:  60%|██████    | 1814/3000 [1:01:10<36:47,  1.86s/step]Training:  60%|██████    | 1815/3000 [1:01:11<33:42,  1.71s/step]Training:  61%|██████    | 1816/3000 [1:01:12<31:33,  1.60s/step]Training:  61%|██████    | 1817/3000 [1:01:14<30:02,  1.52s/step]Training:  61%|██████    | 1818/3000 [1:01:15<28:58,  1.47s/step]Training:  61%|██████    | 1819/3000 [1:01:16<28:12,  1.43s/step]Training:  61%|██████    | 1820/3000 [1:01:18<27:40,  1.41s/step]Training:  61%|██████    | 1821/3000 [1:01:19<27:17,  1.39s/step]Training:  61%|██████    | 1822/3000 [1:01:20<27:01,  1.38s/step]Training:  61%|██████    | 1823/3000 [1:01:22<26:49,  1.37s/step]Training:  61%|██████    | 1824/3000 [1:01:23<26:40,  1.36s/step]Training:  61%|██████    | 1825/3000 [1:01:24<26:34,  1.36s/step]Training:  61%|██████    | 1826/3000 [1:01:26<26:29,  1.35s/step]Training:  61%|██████    | 1827/3000 [1:01:27<26:25,  1.35s/step]Training:  61%|██████    | 1828/3000 [1:01:28<26:22,  1.35s/step]Training:  61%|██████    | 1829/3000 [1:01:30<26:19,  1.35s/step]Training:  61%|██████    | 1830/3000 [1:01:31<26:17,  1.35s/step]Training:  61%|██████    | 1831/3000 [1:01:32<26:15,  1.35s/step]Training:  61%|██████    | 1832/3000 [1:01:34<26:13,  1.35s/step]Training:  61%|██████    | 1833/3000 [1:01:35<26:12,  1.35s/step]Training:  61%|██████    | 1834/3000 [1:01:37<26:10,  1.35s/step]Training:  61%|██████    | 1835/3000 [1:01:38<26:09,  1.35s/step]Training:  61%|██████    | 1836/3000 [1:01:39<26:07,  1.35s/step]Training:  61%|██████    | 1837/3000 [1:01:41<26:06,  1.35s/step]Training:  61%|██████▏   | 1838/3000 [1:01:42<26:04,  1.35s/step]Training:  61%|██████▏   | 1839/3000 [1:01:43<26:03,  1.35s/step]Training:  61%|██████▏   | 1840/3000 [1:01:45<26:02,  1.35s/step]Training:  61%|██████▏   | 1841/3000 [1:01:46<26:00,  1.35s/step]Training:  61%|██████▏   | 1842/3000 [1:01:47<25:59,  1.35s/step]Training:  61%|██████▏   | 1843/3000 [1:01:49<25:58,  1.35s/step]Training:  61%|██████▏   | 1844/3000 [1:01:50<25:57,  1.35s/step]Training:  62%|██████▏   | 1845/3000 [1:01:51<25:55,  1.35s/step]Training:  62%|██████▏   | 1846/3000 [1:01:53<25:55,  1.35s/step]Training:  62%|██████▏   | 1847/3000 [1:01:54<25:53,  1.35s/step]Training:  62%|██████▏   | 1848/3000 [1:01:55<25:52,  1.35s/step]Training:  62%|██████▏   | 1849/3000 [1:01:57<25:50,  1.35s/step]Training:  62%|██████▏   | 1850/3000 [1:01:58<25:49,  1.35s/step]12:11:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.1757 lr=3.000e-04
12:11:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.2222 lr=3.000e-04
12:11:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.1638 lr=3.000e-04
12:11:07 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.2286 lr=3.000e-04
12:11:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.1617 lr=3.000e-04
12:11:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.1157 lr=3.000e-04
12:11:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.0854 lr=3.000e-04
12:11:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=1850 loss=0.1759 lr=3.000e-04
Training:  62%|██████▏   | 1851/3000 [1:01:59<25:48,  1.35s/step]Training:  62%|██████▏   | 1852/3000 [1:02:01<25:46,  1.35s/step]Training:  62%|██████▏   | 1853/3000 [1:02:02<25:45,  1.35s/step]Training:  62%|██████▏   | 1854/3000 [1:02:03<25:43,  1.35s/step]Training:  62%|██████▏   | 1855/3000 [1:02:05<25:42,  1.35s/step]Training:  62%|██████▏   | 1856/3000 [1:02:06<25:40,  1.35s/step]Training:  62%|██████▏   | 1857/3000 [1:02:08<25:39,  1.35s/step]Training:  62%|██████▏   | 1858/3000 [1:02:09<25:38,  1.35s/step]Training:  62%|██████▏   | 1859/3000 [1:02:10<25:36,  1.35s/step]Training:  62%|██████▏   | 1860/3000 [1:02:12<25:35,  1.35s/step]Training:  62%|██████▏   | 1861/3000 [1:02:13<25:33,  1.35s/step]Training:  62%|██████▏   | 1862/3000 [1:02:14<25:32,  1.35s/step]Training:  62%|██████▏   | 1863/3000 [1:02:16<25:31,  1.35s/step]Training:  62%|██████▏   | 1864/3000 [1:02:17<25:29,  1.35s/step]Training:  62%|██████▏   | 1865/3000 [1:02:18<25:28,  1.35s/step]Training:  62%|██████▏   | 1866/3000 [1:02:20<25:27,  1.35s/step]Training:  62%|██████▏   | 1867/3000 [1:02:21<25:25,  1.35s/step]Training:  62%|██████▏   | 1868/3000 [1:02:22<25:24,  1.35s/step]Training:  62%|██████▏   | 1869/3000 [1:02:24<25:23,  1.35s/step]Training:  62%|██████▏   | 1870/3000 [1:02:25<25:23,  1.35s/step]Training:  62%|██████▏   | 1871/3000 [1:02:26<25:22,  1.35s/step]Training:  62%|██████▏   | 1872/3000 [1:02:28<25:20,  1.35s/step]Training:  62%|██████▏   | 1873/3000 [1:02:29<25:19,  1.35s/step]Training:  62%|██████▏   | 1874/3000 [1:02:30<25:17,  1.35s/step]Training:  62%|██████▎   | 1875/3000 [1:02:32<25:15,  1.35s/step]Training:  63%|██████▎   | 1876/3000 [1:02:33<25:14,  1.35s/step]Training:  63%|██████▎   | 1877/3000 [1:02:34<25:12,  1.35s/step]Training:  63%|██████▎   | 1878/3000 [1:02:36<25:11,  1.35s/step]Training:  63%|██████▎   | 1879/3000 [1:02:37<25:10,  1.35s/step]Training:  63%|██████▎   | 1880/3000 [1:02:38<25:08,  1.35s/step]Training:  63%|██████▎   | 1881/3000 [1:02:40<25:07,  1.35s/step]Training:  63%|██████▎   | 1882/3000 [1:02:41<25:05,  1.35s/step]Training:  63%|██████▎   | 1883/3000 [1:02:43<25:04,  1.35s/step]Training:  63%|██████▎   | 1884/3000 [1:02:44<25:03,  1.35s/step]Training:  63%|██████▎   | 1885/3000 [1:02:45<25:02,  1.35s/step]Training:  63%|██████▎   | 1886/3000 [1:02:47<25:00,  1.35s/step]Training:  63%|██████▎   | 1887/3000 [1:02:48<24:59,  1.35s/step]Training:  63%|██████▎   | 1888/3000 [1:02:49<24:58,  1.35s/step]Training:  63%|██████▎   | 1889/3000 [1:02:51<24:56,  1.35s/step]Training:  63%|██████▎   | 1890/3000 [1:02:52<24:55,  1.35s/step]Training:  63%|██████▎   | 1891/3000 [1:02:53<24:53,  1.35s/step]Training:  63%|██████▎   | 1892/3000 [1:02:55<24:52,  1.35s/step]Training:  63%|██████▎   | 1893/3000 [1:02:56<24:50,  1.35s/step]Training:  63%|██████▎   | 1894/3000 [1:02:57<24:49,  1.35s/step]Training:  63%|██████▎   | 1895/3000 [1:02:59<24:48,  1.35s/step]Training:  63%|██████▎   | 1896/3000 [1:03:00<24:47,  1.35s/step]Training:  63%|██████▎   | 1897/3000 [1:03:01<24:45,  1.35s/step]Training:  63%|██████▎   | 1898/3000 [1:03:03<24:44,  1.35s/step]Training:  63%|██████▎   | 1899/3000 [1:03:04<24:43,  1.35s/step]Training:  63%|██████▎   | 1900/3000 [1:03:05<24:41,  1.35s/step]12:12:14 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.1306 lr=3.000e-04
12:12:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.1873 lr=3.000e-04
12:12:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.1103 lr=3.000e-04
12:12:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.1548 lr=3.000e-04
12:12:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.1268 lr=3.000e-04
12:12:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.0959 lr=3.000e-04
12:12:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.0942 lr=3.000e-04
12:12:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=1900 loss=0.1454 lr=3.000e-04
Training:  63%|██████▎   | 1901/3000 [1:03:07<24:40,  1.35s/step]Training:  63%|██████▎   | 1902/3000 [1:03:08<24:39,  1.35s/step]Training:  63%|██████▎   | 1903/3000 [1:03:09<24:37,  1.35s/step]Training:  63%|██████▎   | 1904/3000 [1:03:11<24:36,  1.35s/step]Training:  64%|██████▎   | 1905/3000 [1:03:12<24:34,  1.35s/step]Training:  64%|██████▎   | 1906/3000 [1:03:14<24:33,  1.35s/step]Training:  64%|██████▎   | 1907/3000 [1:03:15<24:31,  1.35s/step]Training:  64%|██████▎   | 1908/3000 [1:03:16<24:30,  1.35s/step]Training:  64%|██████▎   | 1909/3000 [1:03:18<24:29,  1.35s/step]Training:  64%|██████▎   | 1910/3000 [1:03:19<24:27,  1.35s/step]Training:  64%|██████▎   | 1911/3000 [1:03:20<24:26,  1.35s/step]Training:  64%|██████▎   | 1912/3000 [1:03:22<24:24,  1.35s/step]Training:  64%|██████▍   | 1913/3000 [1:03:23<24:23,  1.35s/step]Training:  64%|██████▍   | 1914/3000 [1:03:24<24:22,  1.35s/step]Training:  64%|██████▍   | 1915/3000 [1:03:26<24:21,  1.35s/step]Training:  64%|██████▍   | 1916/3000 [1:03:27<24:19,  1.35s/step]Training:  64%|██████▍   | 1917/3000 [1:03:28<24:18,  1.35s/step]Training:  64%|██████▍   | 1918/3000 [1:03:30<24:17,  1.35s/step]Training:  64%|██████▍   | 1919/3000 [1:03:31<24:15,  1.35s/step]Training:  64%|██████▍   | 1920/3000 [1:03:32<24:14,  1.35s/step]Training:  64%|██████▍   | 1921/3000 [1:03:34<24:13,  1.35s/step]Training:  64%|██████▍   | 1922/3000 [1:03:35<24:11,  1.35s/step]Training:  64%|██████▍   | 1923/3000 [1:03:36<24:10,  1.35s/step]Training:  64%|██████▍   | 1924/3000 [1:03:38<24:09,  1.35s/step]Training:  64%|██████▍   | 1925/3000 [1:03:39<24:07,  1.35s/step]Training:  64%|██████▍   | 1926/3000 [1:03:40<24:06,  1.35s/step]Training:  64%|██████▍   | 1927/3000 [1:03:42<24:05,  1.35s/step]Training:  64%|██████▍   | 1928/3000 [1:03:43<24:03,  1.35s/step]Training:  64%|██████▍   | 1929/3000 [1:03:44<24:02,  1.35s/step]Training:  64%|██████▍   | 1930/3000 [1:03:46<24:00,  1.35s/step]Training:  64%|██████▍   | 1931/3000 [1:03:47<23:59,  1.35s/step]Training:  64%|██████▍   | 1932/3000 [1:03:49<23:58,  1.35s/step]Training:  64%|██████▍   | 1933/3000 [1:03:50<23:56,  1.35s/step]Training:  64%|██████▍   | 1934/3000 [1:03:51<23:55,  1.35s/step]Training:  64%|██████▍   | 1935/3000 [1:03:53<23:54,  1.35s/step]Training:  65%|██████▍   | 1936/3000 [1:03:54<23:53,  1.35s/step]Training:  65%|██████▍   | 1937/3000 [1:03:55<23:51,  1.35s/step]Training:  65%|██████▍   | 1938/3000 [1:03:57<23:50,  1.35s/step]Training:  65%|██████▍   | 1939/3000 [1:03:58<23:48,  1.35s/step]Training:  65%|██████▍   | 1940/3000 [1:03:59<23:48,  1.35s/step]Training:  65%|██████▍   | 1941/3000 [1:04:01<23:46,  1.35s/step]Training:  65%|██████▍   | 1942/3000 [1:04:02<23:45,  1.35s/step]Training:  65%|██████▍   | 1943/3000 [1:04:03<23:43,  1.35s/step]Training:  65%|██████▍   | 1944/3000 [1:04:05<23:42,  1.35s/step]Training:  65%|██████▍   | 1945/3000 [1:04:06<23:40,  1.35s/step]Training:  65%|██████▍   | 1946/3000 [1:04:07<23:39,  1.35s/step]Training:  65%|██████▍   | 1947/3000 [1:04:09<23:38,  1.35s/step]Training:  65%|██████▍   | 1948/3000 [1:04:10<23:36,  1.35s/step]Training:  65%|██████▍   | 1949/3000 [1:04:11<23:35,  1.35s/step]Training:  65%|██████▌   | 1950/3000 [1:04:13<23:34,  1.35s/step]12:13:22 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1807 lr=3.000e-04
12:13:22 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1255 lr=3.000e-04
12:13:22 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.2501 lr=3.000e-04
12:13:22 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1165 lr=3.000e-04
12:13:22 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1010 lr=3.000e-04
12:13:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1049 lr=3.000e-04
12:13:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1224 lr=3.000e-04
12:13:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=1950 loss=0.1258 lr=3.000e-04
Training:  65%|██████▌   | 1951/3000 [1:04:14<23:33,  1.35s/step]Training:  65%|██████▌   | 1952/3000 [1:04:15<23:31,  1.35s/step]Training:  65%|██████▌   | 1953/3000 [1:04:17<23:30,  1.35s/step]Training:  65%|██████▌   | 1954/3000 [1:04:18<23:28,  1.35s/step]Training:  65%|██████▌   | 1955/3000 [1:04:20<23:27,  1.35s/step]Training:  65%|██████▌   | 1956/3000 [1:04:21<23:25,  1.35s/step]Training:  65%|██████▌   | 1957/3000 [1:04:22<23:24,  1.35s/step]Training:  65%|██████▌   | 1958/3000 [1:04:24<23:23,  1.35s/step]Training:  65%|██████▌   | 1959/3000 [1:04:25<23:21,  1.35s/step]Training:  65%|██████▌   | 1960/3000 [1:04:26<23:20,  1.35s/step]Training:  65%|██████▌   | 1961/3000 [1:04:28<23:19,  1.35s/step]Training:  65%|██████▌   | 1962/3000 [1:04:29<23:18,  1.35s/step]Training:  65%|██████▌   | 1963/3000 [1:04:30<23:16,  1.35s/step]Training:  65%|██████▌   | 1964/3000 [1:04:32<23:15,  1.35s/step]Training:  66%|██████▌   | 1965/3000 [1:04:33<23:13,  1.35s/step]Training:  66%|██████▌   | 1966/3000 [1:04:34<23:12,  1.35s/step]Training:  66%|██████▌   | 1967/3000 [1:04:36<23:11,  1.35s/step]Training:  66%|██████▌   | 1968/3000 [1:04:37<23:09,  1.35s/step]Training:  66%|██████▌   | 1969/3000 [1:04:38<23:08,  1.35s/step]Training:  66%|██████▌   | 1970/3000 [1:04:40<23:07,  1.35s/step]Training:  66%|██████▌   | 1971/3000 [1:04:41<23:05,  1.35s/step]Training:  66%|██████▌   | 1972/3000 [1:04:42<23:04,  1.35s/step]Training:  66%|██████▌   | 1973/3000 [1:04:44<23:03,  1.35s/step]Training:  66%|██████▌   | 1974/3000 [1:04:45<23:01,  1.35s/step]Training:  66%|██████▌   | 1975/3000 [1:04:46<23:00,  1.35s/step]Training:  66%|██████▌   | 1976/3000 [1:04:48<22:58,  1.35s/step]Training:  66%|██████▌   | 1977/3000 [1:04:49<22:57,  1.35s/step]Training:  66%|██████▌   | 1978/3000 [1:04:50<22:56,  1.35s/step]Training:  66%|██████▌   | 1979/3000 [1:04:52<22:55,  1.35s/step]Training:  66%|██████▌   | 1980/3000 [1:04:53<22:53,  1.35s/step]Training:  66%|██████▌   | 1981/3000 [1:04:55<22:52,  1.35s/step]Training:  66%|██████▌   | 1982/3000 [1:04:56<22:51,  1.35s/step]Training:  66%|██████▌   | 1983/3000 [1:04:57<22:49,  1.35s/step]Training:  66%|██████▌   | 1984/3000 [1:04:59<22:48,  1.35s/step]Training:  66%|██████▌   | 1985/3000 [1:05:00<22:47,  1.35s/step]Training:  66%|██████▌   | 1986/3000 [1:05:01<22:45,  1.35s/step]Training:  66%|██████▌   | 1987/3000 [1:05:03<22:44,  1.35s/step]Training:  66%|██████▋   | 1988/3000 [1:05:04<22:42,  1.35s/step]Training:  66%|██████▋   | 1989/3000 [1:05:05<22:41,  1.35s/step]Training:  66%|██████▋   | 1990/3000 [1:05:07<22:40,  1.35s/step]Training:  66%|██████▋   | 1991/3000 [1:05:08<22:38,  1.35s/step]Training:  66%|██████▋   | 1992/3000 [1:05:09<22:37,  1.35s/step]Training:  66%|██████▋   | 1993/3000 [1:05:11<22:36,  1.35s/step]Training:  66%|██████▋   | 1994/3000 [1:05:12<22:34,  1.35s/step]Training:  66%|██████▋   | 1995/3000 [1:05:13<22:33,  1.35s/step]Training:  67%|██████▋   | 1996/3000 [1:05:15<22:32,  1.35s/step]Training:  67%|██████▋   | 1997/3000 [1:05:16<22:30,  1.35s/step]Training:  67%|██████▋   | 1998/3000 [1:05:17<22:29,  1.35s/step]Training:  67%|██████▋   | 1999/3000 [1:05:19<22:27,  1.35s/step]Training:  67%|██████▋   | 2000/3000 [1:05:20<22:26,  1.35s/step]12:14:29 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.1309 lr=3.000e-04
12:14:30 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.1157 lr=3.000e-04
12:14:30 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.0927 lr=3.000e-04
12:14:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.2344 lr=3.000e-04
12:14:32 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.1544 lr=3.000e-04
12:14:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.1179 lr=3.000e-04
12:14:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.0970 lr=3.000e-04
12:14:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=2000 loss=0.1616 lr=3.000e-04
Training:  67%|██████▋   | 2001/3000 [1:05:26<46:02,  2.77s/step]Training:  67%|██████▋   | 2002/3000 [1:05:28<38:55,  2.34s/step]Training:  67%|██████▋   | 2003/3000 [1:05:29<33:56,  2.04s/step]Training:  67%|██████▋   | 2004/3000 [1:05:30<30:26,  1.83s/step]Training:  67%|██████▋   | 2005/3000 [1:05:32<27:59,  1.69s/step]Training:  67%|██████▋   | 2006/3000 [1:05:33<26:15,  1.59s/step]Training:  67%|██████▋   | 2007/3000 [1:05:34<25:03,  1.51s/step]Training:  67%|██████▋   | 2008/3000 [1:05:36<24:11,  1.46s/step]Training:  67%|██████▋   | 2009/3000 [1:05:37<23:35,  1.43s/step]Training:  67%|██████▋   | 2010/3000 [1:05:38<23:09,  1.40s/step]Training:  67%|██████▋   | 2011/3000 [1:05:40<22:51,  1.39s/step]Training:  67%|██████▋   | 2012/3000 [1:05:41<22:38,  1.37s/step]Training:  67%|██████▋   | 2013/3000 [1:05:42<22:28,  1.37s/step]Training:  67%|██████▋   | 2014/3000 [1:05:44<22:21,  1.36s/step]Training:  67%|██████▋   | 2015/3000 [1:05:45<22:15,  1.36s/step]Training:  67%|██████▋   | 2016/3000 [1:05:46<22:11,  1.35s/step]Training:  67%|██████▋   | 2017/3000 [1:05:48<22:08,  1.35s/step]Training:  67%|██████▋   | 2018/3000 [1:05:49<22:05,  1.35s/step]Training:  67%|██████▋   | 2019/3000 [1:05:50<22:03,  1.35s/step]Training:  67%|██████▋   | 2020/3000 [1:05:52<22:01,  1.35s/step]Training:  67%|██████▋   | 2021/3000 [1:05:53<21:59,  1.35s/step]Training:  67%|██████▋   | 2022/3000 [1:05:54<21:58,  1.35s/step]Training:  67%|██████▋   | 2023/3000 [1:05:56<21:56,  1.35s/step]Training:  67%|██████▋   | 2024/3000 [1:05:57<21:54,  1.35s/step]Training:  68%|██████▊   | 2025/3000 [1:05:59<21:53,  1.35s/step]Training:  68%|██████▊   | 2026/3000 [1:06:00<21:52,  1.35s/step]Training:  68%|██████▊   | 2027/3000 [1:06:01<21:50,  1.35s/step]Training:  68%|██████▊   | 2028/3000 [1:06:03<21:49,  1.35s/step]Training:  68%|██████▊   | 2029/3000 [1:06:04<21:47,  1.35s/step]Training:  68%|██████▊   | 2030/3000 [1:06:05<21:46,  1.35s/step]Training:  68%|██████▊   | 2031/3000 [1:06:07<21:45,  1.35s/step]Training:  68%|██████▊   | 2032/3000 [1:06:08<21:43,  1.35s/step]Training:  68%|██████▊   | 2033/3000 [1:06:09<21:42,  1.35s/step]Training:  68%|██████▊   | 2034/3000 [1:06:11<21:40,  1.35s/step]Training:  68%|██████▊   | 2035/3000 [1:06:12<21:39,  1.35s/step]Training:  68%|██████▊   | 2036/3000 [1:06:13<21:38,  1.35s/step]Training:  68%|██████▊   | 2037/3000 [1:06:15<21:36,  1.35s/step]Training:  68%|██████▊   | 2038/3000 [1:06:16<21:35,  1.35s/step]Training:  68%|██████▊   | 2039/3000 [1:06:17<21:34,  1.35s/step]Training:  68%|██████▊   | 2040/3000 [1:06:19<21:32,  1.35s/step]Training:  68%|██████▊   | 2041/3000 [1:06:20<21:31,  1.35s/step]Training:  68%|██████▊   | 2042/3000 [1:06:21<21:30,  1.35s/step]Training:  68%|██████▊   | 2043/3000 [1:06:23<21:29,  1.35s/step]Training:  68%|██████▊   | 2044/3000 [1:06:24<21:27,  1.35s/step]Training:  68%|██████▊   | 2045/3000 [1:06:25<21:26,  1.35s/step]Training:  68%|██████▊   | 2046/3000 [1:06:27<21:24,  1.35s/step]Training:  68%|██████▊   | 2047/3000 [1:06:28<21:23,  1.35s/step]Training:  68%|██████▊   | 2048/3000 [1:06:29<21:22,  1.35s/step]Training:  68%|██████▊   | 2049/3000 [1:06:31<21:21,  1.35s/step]Training:  68%|██████▊   | 2050/3000 [1:06:32<21:19,  1.35s/step]12:15:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1255 lr=3.000e-04
12:15:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.0762 lr=3.000e-04
12:15:41 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1523 lr=3.000e-04
12:15:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1566 lr=3.000e-04
12:15:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1362 lr=3.000e-04
12:15:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1061 lr=3.000e-04
12:15:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1342 lr=3.000e-04
12:15:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2050 loss=0.1070 lr=3.000e-04
Training:  68%|██████▊   | 2051/3000 [1:06:34<21:18,  1.35s/step]Training:  68%|██████▊   | 2052/3000 [1:06:35<21:16,  1.35s/step]Training:  68%|██████▊   | 2053/3000 [1:06:36<21:15,  1.35s/step]Training:  68%|██████▊   | 2054/3000 [1:06:38<21:14,  1.35s/step]Training:  68%|██████▊   | 2055/3000 [1:06:39<21:12,  1.35s/step]Training:  69%|██████▊   | 2056/3000 [1:06:40<21:11,  1.35s/step]Training:  69%|██████▊   | 2057/3000 [1:06:42<21:09,  1.35s/step]Training:  69%|██████▊   | 2058/3000 [1:06:43<21:08,  1.35s/step]Training:  69%|██████▊   | 2059/3000 [1:06:44<21:07,  1.35s/step]Training:  69%|██████▊   | 2060/3000 [1:06:46<21:05,  1.35s/step]Training:  69%|██████▊   | 2061/3000 [1:06:47<21:04,  1.35s/step]Training:  69%|██████▊   | 2062/3000 [1:06:48<21:03,  1.35s/step]Training:  69%|██████▉   | 2063/3000 [1:06:50<21:02,  1.35s/step]Training:  69%|██████▉   | 2064/3000 [1:06:51<21:00,  1.35s/step]Training:  69%|██████▉   | 2065/3000 [1:06:52<21:00,  1.35s/step]Training:  69%|██████▉   | 2066/3000 [1:06:54<20:59,  1.35s/step]Training:  69%|██████▉   | 2067/3000 [1:06:55<20:57,  1.35s/step]Training:  69%|██████▉   | 2068/3000 [1:06:56<20:55,  1.35s/step]Training:  69%|██████▉   | 2069/3000 [1:06:58<20:54,  1.35s/step]Training:  69%|██████▉   | 2070/3000 [1:06:59<20:53,  1.35s/step]Training:  69%|██████▉   | 2071/3000 [1:07:00<20:51,  1.35s/step]Training:  69%|██████▉   | 2072/3000 [1:07:02<20:50,  1.35s/step]Training:  69%|██████▉   | 2073/3000 [1:07:03<20:48,  1.35s/step]Training:  69%|██████▉   | 2074/3000 [1:07:05<20:47,  1.35s/step]Training:  69%|██████▉   | 2075/3000 [1:07:06<20:45,  1.35s/step]Training:  69%|██████▉   | 2076/3000 [1:07:07<20:44,  1.35s/step]Training:  69%|██████▉   | 2077/3000 [1:07:09<20:43,  1.35s/step]Training:  69%|██████▉   | 2078/3000 [1:07:10<20:41,  1.35s/step]Training:  69%|██████▉   | 2079/3000 [1:07:11<20:40,  1.35s/step]Training:  69%|██████▉   | 2080/3000 [1:07:13<20:39,  1.35s/step]Training:  69%|██████▉   | 2081/3000 [1:07:14<20:37,  1.35s/step]Training:  69%|██████▉   | 2082/3000 [1:07:15<20:36,  1.35s/step]Training:  69%|██████▉   | 2083/3000 [1:07:17<20:35,  1.35s/step]Training:  69%|██████▉   | 2084/3000 [1:07:18<20:33,  1.35s/step]Training:  70%|██████▉   | 2085/3000 [1:07:19<20:32,  1.35s/step]Training:  70%|██████▉   | 2086/3000 [1:07:21<20:31,  1.35s/step]Training:  70%|██████▉   | 2087/3000 [1:07:22<20:29,  1.35s/step]Training:  70%|██████▉   | 2088/3000 [1:07:23<20:29,  1.35s/step]Training:  70%|██████▉   | 2089/3000 [1:07:25<20:28,  1.35s/step]Training:  70%|██████▉   | 2090/3000 [1:07:26<20:27,  1.35s/step]Training:  70%|██████▉   | 2091/3000 [1:07:27<20:25,  1.35s/step]Training:  70%|██████▉   | 2092/3000 [1:07:29<20:24,  1.35s/step]Training:  70%|██████▉   | 2093/3000 [1:07:30<20:22,  1.35s/step]Training:  70%|██████▉   | 2094/3000 [1:07:31<20:21,  1.35s/step]Training:  70%|██████▉   | 2095/3000 [1:07:33<20:19,  1.35s/step]Training:  70%|██████▉   | 2096/3000 [1:07:34<20:18,  1.35s/step]Training:  70%|██████▉   | 2097/3000 [1:07:35<20:16,  1.35s/step]Training:  70%|██████▉   | 2098/3000 [1:07:37<20:15,  1.35s/step]Training:  70%|██████▉   | 2099/3000 [1:07:38<20:13,  1.35s/step]Training:  70%|███████   | 2100/3000 [1:07:40<20:12,  1.35s/step]12:16:48 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1604 lr=3.000e-04
12:17:11 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:17:11 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1086 lr=3.000e-04
12:17:33 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:17:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1526 lr=3.000e-04
12:17:55 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:17:55 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1015 lr=3.000e-04
12:18:18 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:18:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1224 lr=3.000e-04
12:18:40 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:18:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1023 lr=3.000e-04
12:19:02 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:19:02 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.1047 lr=3.000e-04
12:19:24 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
12:19:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=2100 loss=0.0735 lr=3.000e-04
12:19:47 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2100 loss=1.1400 ppl=3.13
Training:  70%|███████   | 2101/3000 [1:10:38<13:36:28, 54.49s/step]Training:  70%|███████   | 2102/3000 [1:10:39<9:36:56, 38.55s/step] Training:  70%|███████   | 2103/3000 [1:10:41<6:49:26, 27.39s/step]Training:  70%|███████   | 2104/3000 [1:10:42<4:52:19, 19.58s/step]Training:  70%|███████   | 2105/3000 [1:10:43<3:30:25, 14.11s/step]Training:  70%|███████   | 2106/3000 [1:10:45<2:33:09, 10.28s/step]Training:  70%|███████   | 2107/3000 [1:10:46<1:53:05,  7.60s/step]Training:  70%|███████   | 2108/3000 [1:10:47<1:25:05,  5.72s/step]Training:  70%|███████   | 2109/3000 [1:10:49<1:05:29,  4.41s/step]Training:  70%|███████   | 2110/3000 [1:10:50<51:47,  3.49s/step]  Training:  70%|███████   | 2111/3000 [1:10:52<42:11,  2.85s/step]Training:  70%|███████   | 2112/3000 [1:10:53<35:28,  2.40s/step]Training:  70%|███████   | 2113/3000 [1:10:54<30:46,  2.08s/step]Training:  70%|███████   | 2114/3000 [1:10:56<27:29,  1.86s/step]Training:  70%|███████   | 2115/3000 [1:10:57<25:10,  1.71s/step]Training:  71%|███████   | 2116/3000 [1:10:58<23:33,  1.60s/step]Training:  71%|███████   | 2117/3000 [1:11:00<22:25,  1.52s/step]Training:  71%|███████   | 2118/3000 [1:11:01<21:37,  1.47s/step]Training:  71%|███████   | 2119/3000 [1:11:02<21:03,  1.43s/step]Training:  71%|███████   | 2120/3000 [1:11:04<20:38,  1.41s/step]Training:  71%|███████   | 2121/3000 [1:11:05<20:21,  1.39s/step]Training:  71%|███████   | 2122/3000 [1:11:06<20:08,  1.38s/step]Training:  71%|███████   | 2123/3000 [1:11:08<19:59,  1.37s/step]Training:  71%|███████   | 2124/3000 [1:11:09<19:52,  1.36s/step]Training:  71%|███████   | 2125/3000 [1:11:10<19:47,  1.36s/step]Training:  71%|███████   | 2126/3000 [1:11:12<19:43,  1.35s/step]Training:  71%|███████   | 2127/3000 [1:11:13<19:39,  1.35s/step]Training:  71%|███████   | 2128/3000 [1:11:14<19:37,  1.35s/step]Training:  71%|███████   | 2129/3000 [1:11:16<19:34,  1.35s/step]Training:  71%|███████   | 2130/3000 [1:11:17<19:33,  1.35s/step]Training:  71%|███████   | 2131/3000 [1:11:18<19:31,  1.35s/step]Training:  71%|███████   | 2132/3000 [1:11:20<19:29,  1.35s/step]Training:  71%|███████   | 2133/3000 [1:11:21<19:27,  1.35s/step]Training:  71%|███████   | 2134/3000 [1:11:22<19:26,  1.35s/step]Training:  71%|███████   | 2135/3000 [1:11:24<19:25,  1.35s/step]Training:  71%|███████   | 2136/3000 [1:11:25<19:24,  1.35s/step]Training:  71%|███████   | 2137/3000 [1:11:27<19:22,  1.35s/step]Training:  71%|███████▏  | 2138/3000 [1:11:28<19:21,  1.35s/step]Training:  71%|███████▏  | 2139/3000 [1:11:29<19:20,  1.35s/step]Training:  71%|███████▏  | 2140/3000 [1:11:31<19:19,  1.35s/step]Training:  71%|███████▏  | 2141/3000 [1:11:32<19:17,  1.35s/step]Training:  71%|███████▏  | 2142/3000 [1:11:33<19:16,  1.35s/step]Training:  71%|███████▏  | 2143/3000 [1:11:35<19:14,  1.35s/step]Training:  71%|███████▏  | 2144/3000 [1:11:36<19:13,  1.35s/step]Training:  72%|███████▏  | 2145/3000 [1:11:37<19:11,  1.35s/step]Training:  72%|███████▏  | 2146/3000 [1:11:39<19:10,  1.35s/step]Training:  72%|███████▏  | 2147/3000 [1:11:40<19:09,  1.35s/step]Training:  72%|███████▏  | 2148/3000 [1:11:41<19:08,  1.35s/step]Training:  72%|███████▏  | 2149/3000 [1:11:43<19:06,  1.35s/step]Training:  72%|███████▏  | 2150/3000 [1:11:44<19:05,  1.35s/step]12:20:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.1293 lr=3.000e-04
12:20:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.2057 lr=3.000e-04
12:20:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.1182 lr=3.000e-04
12:20:53 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.1447 lr=3.000e-04
12:20:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.1340 lr=3.000e-04
12:20:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.1825 lr=3.000e-04
12:20:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.1510 lr=3.000e-04
12:20:54 - trainer.gpt2-gsm8k-lora-main - INFO - step=2150 loss=0.0896 lr=3.000e-04
Training:  72%|███████▏  | 2151/3000 [1:11:45<19:04,  1.35s/step]Training:  72%|███████▏  | 2152/3000 [1:11:47<19:02,  1.35s/step]Training:  72%|███████▏  | 2153/3000 [1:11:48<19:01,  1.35s/step]Training:  72%|███████▏  | 2154/3000 [1:11:49<18:59,  1.35s/step]Training:  72%|███████▏  | 2155/3000 [1:11:51<18:58,  1.35s/step]Training:  72%|███████▏  | 2156/3000 [1:11:52<18:57,  1.35s/step]Training:  72%|███████▏  | 2157/3000 [1:11:53<18:55,  1.35s/step]Training:  72%|███████▏  | 2158/3000 [1:11:55<18:54,  1.35s/step]Training:  72%|███████▏  | 2159/3000 [1:11:56<18:53,  1.35s/step]Training:  72%|███████▏  | 2160/3000 [1:11:58<18:52,  1.35s/step]Training:  72%|███████▏  | 2161/3000 [1:11:59<18:51,  1.35s/step]Training:  72%|███████▏  | 2162/3000 [1:12:00<18:50,  1.35s/step]Training:  72%|███████▏  | 2163/3000 [1:12:02<18:48,  1.35s/step]Training:  72%|███████▏  | 2164/3000 [1:12:03<18:46,  1.35s/step]Training:  72%|███████▏  | 2165/3000 [1:12:04<18:45,  1.35s/step]Training:  72%|███████▏  | 2166/3000 [1:12:06<18:43,  1.35s/step]Training:  72%|███████▏  | 2167/3000 [1:12:07<18:42,  1.35s/step]Training:  72%|███████▏  | 2168/3000 [1:12:08<18:40,  1.35s/step]Training:  72%|███████▏  | 2169/3000 [1:12:10<18:39,  1.35s/step]Training:  72%|███████▏  | 2170/3000 [1:12:11<18:38,  1.35s/step]Training:  72%|███████▏  | 2171/3000 [1:12:12<18:36,  1.35s/step]Training:  72%|███████▏  | 2172/3000 [1:12:14<18:35,  1.35s/step]Training:  72%|███████▏  | 2173/3000 [1:12:15<18:34,  1.35s/step]Training:  72%|███████▏  | 2174/3000 [1:12:16<18:32,  1.35s/step]Training:  72%|███████▎  | 2175/3000 [1:12:18<18:31,  1.35s/step]Training:  73%|███████▎  | 2176/3000 [1:12:19<18:30,  1.35s/step]Training:  73%|███████▎  | 2177/3000 [1:12:20<18:28,  1.35s/step]Training:  73%|███████▎  | 2178/3000 [1:12:22<18:27,  1.35s/step]Training:  73%|███████▎  | 2179/3000 [1:12:23<18:26,  1.35s/step]Training:  73%|███████▎  | 2180/3000 [1:12:24<18:24,  1.35s/step]Training:  73%|███████▎  | 2181/3000 [1:12:26<18:24,  1.35s/step]Training:  73%|███████▎  | 2182/3000 [1:12:27<18:23,  1.35s/step]Training:  73%|███████▎  | 2183/3000 [1:12:29<18:21,  1.35s/step]Training:  73%|███████▎  | 2184/3000 [1:12:30<18:20,  1.35s/step]Training:  73%|███████▎  | 2185/3000 [1:12:31<18:18,  1.35s/step]Training:  73%|███████▎  | 2186/3000 [1:12:33<18:16,  1.35s/step]Training:  73%|███████▎  | 2187/3000 [1:12:34<18:15,  1.35s/step]Training:  73%|███████▎  | 2188/3000 [1:12:35<18:13,  1.35s/step]Training:  73%|███████▎  | 2189/3000 [1:12:37<18:12,  1.35s/step]Training:  73%|███████▎  | 2190/3000 [1:12:38<18:11,  1.35s/step]Training:  73%|███████▎  | 2191/3000 [1:12:39<18:09,  1.35s/step]Training:  73%|███████▎  | 2192/3000 [1:12:41<18:08,  1.35s/step]Training:  73%|███████▎  | 2193/3000 [1:12:42<18:07,  1.35s/step]Training:  73%|███████▎  | 2194/3000 [1:12:43<18:05,  1.35s/step]Training:  73%|███████▎  | 2195/3000 [1:12:45<18:04,  1.35s/step]Training:  73%|███████▎  | 2196/3000 [1:12:46<18:03,  1.35s/step]Training:  73%|███████▎  | 2197/3000 [1:12:47<18:02,  1.35s/step]Training:  73%|███████▎  | 2198/3000 [1:12:49<18:00,  1.35s/step]Training:  73%|███████▎  | 2199/3000 [1:12:50<17:59,  1.35s/step]Training:  73%|███████▎  | 2200/3000 [1:12:51<17:58,  1.35s/step]12:22:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1401 lr=3.000e-04
12:22:00 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1019 lr=3.000e-04
12:22:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1449 lr=3.000e-04
12:22:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1278 lr=3.000e-04
12:22:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1477 lr=3.000e-04
12:22:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1305 lr=3.000e-04
12:22:01 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.0858 lr=3.000e-04
12:22:02 - trainer.gpt2-gsm8k-lora-main - INFO - step=2200 loss=0.1182 lr=3.000e-04
Training:  73%|███████▎  | 2201/3000 [1:12:53<17:57,  1.35s/step]Training:  73%|███████▎  | 2202/3000 [1:12:54<17:55,  1.35s/step]Training:  73%|███████▎  | 2203/3000 [1:12:55<17:54,  1.35s/step]Training:  73%|███████▎  | 2204/3000 [1:12:57<17:52,  1.35s/step]Training:  74%|███████▎  | 2205/3000 [1:12:58<17:51,  1.35s/step]Training:  74%|███████▎  | 2206/3000 [1:13:00<17:50,  1.35s/step]Training:  74%|███████▎  | 2207/3000 [1:13:01<17:48,  1.35s/step]Training:  74%|███████▎  | 2208/3000 [1:13:02<17:47,  1.35s/step]Training:  74%|███████▎  | 2209/3000 [1:13:04<17:45,  1.35s/step]Training:  74%|███████▎  | 2210/3000 [1:13:05<17:44,  1.35s/step]Training:  74%|███████▎  | 2211/3000 [1:13:06<17:43,  1.35s/step]Training:  74%|███████▎  | 2212/3000 [1:13:08<17:41,  1.35s/step]Training:  74%|███████▍  | 2213/3000 [1:13:09<17:40,  1.35s/step]Training:  74%|███████▍  | 2214/3000 [1:13:10<17:39,  1.35s/step]Training:  74%|███████▍  | 2215/3000 [1:13:12<17:37,  1.35s/step]Training:  74%|███████▍  | 2216/3000 [1:13:13<17:36,  1.35s/step]Training:  74%|███████▍  | 2217/3000 [1:13:14<17:34,  1.35s/step]Training:  74%|███████▍  | 2218/3000 [1:13:16<17:33,  1.35s/step]Training:  74%|███████▍  | 2219/3000 [1:13:17<17:31,  1.35s/step]Training:  74%|███████▍  | 2220/3000 [1:13:18<17:30,  1.35s/step]Training:  74%|███████▍  | 2221/3000 [1:13:20<17:29,  1.35s/step]Training:  74%|███████▍  | 2222/3000 [1:13:21<17:27,  1.35s/step]Training:  74%|███████▍  | 2223/3000 [1:13:22<17:26,  1.35s/step]Training:  74%|███████▍  | 2224/3000 [1:13:24<17:25,  1.35s/step]Training:  74%|███████▍  | 2225/3000 [1:13:25<17:24,  1.35s/step]Training:  74%|███████▍  | 2226/3000 [1:13:26<17:23,  1.35s/step]Training:  74%|███████▍  | 2227/3000 [1:13:28<17:21,  1.35s/step]Training:  74%|███████▍  | 2228/3000 [1:13:29<17:20,  1.35s/step]Training:  74%|███████▍  | 2229/3000 [1:13:30<17:19,  1.35s/step]Training:  74%|███████▍  | 2230/3000 [1:13:32<17:17,  1.35s/step]Training:  74%|███████▍  | 2231/3000 [1:13:33<17:16,  1.35s/step]Training:  74%|███████▍  | 2232/3000 [1:13:35<17:14,  1.35s/step]Training:  74%|███████▍  | 2233/3000 [1:13:36<17:13,  1.35s/step]Training:  74%|███████▍  | 2234/3000 [1:13:37<17:11,  1.35s/step]Training:  74%|███████▍  | 2235/3000 [1:13:39<17:10,  1.35s/step]Training:  75%|███████▍  | 2236/3000 [1:13:40<17:09,  1.35s/step]Training:  75%|███████▍  | 2237/3000 [1:13:41<17:07,  1.35s/step]Training:  75%|███████▍  | 2238/3000 [1:13:43<17:06,  1.35s/step]Training:  75%|███████▍  | 2239/3000 [1:13:44<17:05,  1.35s/step]Training:  75%|███████▍  | 2240/3000 [1:13:45<17:03,  1.35s/step]Training:  75%|███████▍  | 2241/3000 [1:13:47<17:02,  1.35s/step]Training:  75%|███████▍  | 2242/3000 [1:13:48<17:01,  1.35s/step]Training:  75%|███████▍  | 2243/3000 [1:13:49<16:59,  1.35s/step]Training:  75%|███████▍  | 2244/3000 [1:13:51<16:58,  1.35s/step]Training:  75%|███████▍  | 2245/3000 [1:13:52<16:57,  1.35s/step]Training:  75%|███████▍  | 2246/3000 [1:13:53<16:56,  1.35s/step]Training:  75%|███████▍  | 2247/3000 [1:13:55<16:55,  1.35s/step]Training:  75%|███████▍  | 2248/3000 [1:13:56<16:53,  1.35s/step]Training:  75%|███████▍  | 2249/3000 [1:13:57<16:52,  1.35s/step]Training:  75%|███████▌  | 2250/3000 [1:13:59<16:50,  1.35s/step]12:23:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.0937 lr=3.000e-04
12:23:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.1250 lr=3.000e-04
12:23:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.1056 lr=3.000e-04
12:23:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.1415 lr=3.000e-04
12:23:08 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.1177 lr=3.000e-04
12:23:09 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.1281 lr=3.000e-04
12:23:09 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.1079 lr=3.000e-04
12:23:09 - trainer.gpt2-gsm8k-lora-main - INFO - step=2250 loss=0.2098 lr=3.000e-04
Training:  75%|███████▌  | 2251/3000 [1:14:00<16:49,  1.35s/step]Training:  75%|███████▌  | 2252/3000 [1:14:01<16:48,  1.35s/step]Training:  75%|███████▌  | 2253/3000 [1:14:03<16:46,  1.35s/step]Training:  75%|███████▌  | 2254/3000 [1:14:04<16:45,  1.35s/step]Training:  75%|███████▌  | 2255/3000 [1:14:06<16:43,  1.35s/step]Training:  75%|███████▌  | 2256/3000 [1:14:07<16:42,  1.35s/step]Training:  75%|███████▌  | 2257/3000 [1:14:08<16:40,  1.35s/step]Training:  75%|███████▌  | 2258/3000 [1:14:10<16:39,  1.35s/step]Training:  75%|███████▌  | 2259/3000 [1:14:11<16:38,  1.35s/step]Training:  75%|███████▌  | 2260/3000 [1:14:12<16:36,  1.35s/step]Training:  75%|███████▌  | 2261/3000 [1:14:14<16:35,  1.35s/step]Training:  75%|███████▌  | 2262/3000 [1:14:15<16:34,  1.35s/step]Training:  75%|███████▌  | 2263/3000 [1:14:16<16:32,  1.35s/step]Training:  75%|███████▌  | 2264/3000 [1:14:18<16:31,  1.35s/step]Training:  76%|███████▌  | 2265/3000 [1:14:19<16:30,  1.35s/step]Training:  76%|███████▌  | 2266/3000 [1:14:20<16:28,  1.35s/step]Training:  76%|███████▌  | 2267/3000 [1:14:22<16:27,  1.35s/step]Training:  76%|███████▌  | 2268/3000 [1:14:23<16:26,  1.35s/step]Training:  76%|███████▌  | 2269/3000 [1:14:24<16:25,  1.35s/step]Training:  76%|███████▌  | 2270/3000 [1:14:26<16:23,  1.35s/step]Training:  76%|███████▌  | 2271/3000 [1:14:27<16:22,  1.35s/step]Training:  76%|███████▌  | 2272/3000 [1:14:28<16:21,  1.35s/step]Training:  76%|███████▌  | 2273/3000 [1:14:30<16:19,  1.35s/step]Training:  76%|███████▌  | 2274/3000 [1:14:31<16:18,  1.35s/step]Training:  76%|███████▌  | 2275/3000 [1:14:32<16:16,  1.35s/step]Training:  76%|███████▌  | 2276/3000 [1:14:34<16:15,  1.35s/step]Training:  76%|███████▌  | 2277/3000 [1:14:35<16:14,  1.35s/step]Training:  76%|███████▌  | 2278/3000 [1:14:37<16:12,  1.35s/step]Training:  76%|███████▌  | 2279/3000 [1:14:38<16:11,  1.35s/step]Training:  76%|███████▌  | 2280/3000 [1:14:39<16:09,  1.35s/step]Training:  76%|███████▌  | 2281/3000 [1:14:41<16:08,  1.35s/step]Training:  76%|███████▌  | 2282/3000 [1:14:42<16:07,  1.35s/step]Training:  76%|███████▌  | 2283/3000 [1:14:43<16:05,  1.35s/step]Training:  76%|███████▌  | 2284/3000 [1:14:45<16:04,  1.35s/step]Training:  76%|███████▌  | 2285/3000 [1:14:46<16:03,  1.35s/step]Training:  76%|███████▌  | 2286/3000 [1:14:47<16:02,  1.35s/step]Training:  76%|███████▌  | 2287/3000 [1:14:49<16:00,  1.35s/step]Training:  76%|███████▋  | 2288/3000 [1:14:50<15:59,  1.35s/step]Training:  76%|███████▋  | 2289/3000 [1:14:51<15:58,  1.35s/step]Training:  76%|███████▋  | 2290/3000 [1:14:53<15:56,  1.35s/step]Training:  76%|███████▋  | 2291/3000 [1:14:54<15:55,  1.35s/step]Training:  76%|███████▋  | 2292/3000 [1:14:55<15:53,  1.35s/step]Training:  76%|███████▋  | 2293/3000 [1:14:57<15:52,  1.35s/step]Training:  76%|███████▋  | 2294/3000 [1:14:58<15:51,  1.35s/step]Training:  76%|███████▋  | 2295/3000 [1:14:59<15:50,  1.35s/step]Training:  77%|███████▋  | 2296/3000 [1:15:01<15:48,  1.35s/step]Training:  77%|███████▋  | 2297/3000 [1:15:02<15:47,  1.35s/step]Training:  77%|███████▋  | 2298/3000 [1:15:03<15:45,  1.35s/step]Training:  77%|███████▋  | 2299/3000 [1:15:05<15:44,  1.35s/step]Training:  77%|███████▋  | 2300/3000 [1:15:06<15:42,  1.35s/step]12:24:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1300 lr=3.000e-04
12:24:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1277 lr=3.000e-04
12:24:15 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1855 lr=3.000e-04
12:24:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1493 lr=3.000e-04
12:24:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.3041 lr=3.000e-04
12:24:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1340 lr=3.000e-04
12:24:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1055 lr=3.000e-04
12:24:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2300 loss=0.1518 lr=3.000e-04
Training:  77%|███████▋  | 2301/3000 [1:15:08<15:41,  1.35s/step]Training:  77%|███████▋  | 2302/3000 [1:15:09<15:40,  1.35s/step]Training:  77%|███████▋  | 2303/3000 [1:15:10<15:39,  1.35s/step]Training:  77%|███████▋  | 2304/3000 [1:15:12<15:37,  1.35s/step]Training:  77%|███████▋  | 2305/3000 [1:15:13<15:36,  1.35s/step]Training:  77%|███████▋  | 2306/3000 [1:15:14<15:34,  1.35s/step]Training:  77%|███████▋  | 2307/3000 [1:15:16<15:33,  1.35s/step]Training:  77%|███████▋  | 2308/3000 [1:15:17<15:32,  1.35s/step]Training:  77%|███████▋  | 2309/3000 [1:15:18<15:30,  1.35s/step]Training:  77%|███████▋  | 2310/3000 [1:15:20<15:29,  1.35s/step]Training:  77%|███████▋  | 2311/3000 [1:15:21<15:28,  1.35s/step]Training:  77%|███████▋  | 2312/3000 [1:15:22<15:26,  1.35s/step]Training:  77%|███████▋  | 2313/3000 [1:15:24<15:25,  1.35s/step]Training:  77%|███████▋  | 2314/3000 [1:15:25<15:24,  1.35s/step]Training:  77%|███████▋  | 2315/3000 [1:15:26<15:22,  1.35s/step]Training:  77%|███████▋  | 2316/3000 [1:15:28<15:21,  1.35s/step]Training:  77%|███████▋  | 2317/3000 [1:15:29<15:20,  1.35s/step]Training:  77%|███████▋  | 2318/3000 [1:15:30<15:18,  1.35s/step]Training:  77%|███████▋  | 2319/3000 [1:15:32<15:17,  1.35s/step]Training:  77%|███████▋  | 2320/3000 [1:15:33<15:16,  1.35s/step]Training:  77%|███████▋  | 2321/3000 [1:15:34<15:14,  1.35s/step]Training:  77%|███████▋  | 2322/3000 [1:15:36<15:13,  1.35s/step]Training:  77%|███████▋  | 2323/3000 [1:15:37<15:11,  1.35s/step]Training:  77%|███████▋  | 2324/3000 [1:15:38<15:10,  1.35s/step]Training:  78%|███████▊  | 2325/3000 [1:15:40<15:09,  1.35s/step]Training:  78%|███████▊  | 2326/3000 [1:15:41<15:07,  1.35s/step]Training:  78%|███████▊  | 2327/3000 [1:15:43<15:06,  1.35s/step]Training:  78%|███████▊  | 2328/3000 [1:15:44<15:05,  1.35s/step]Training:  78%|███████▊  | 2329/3000 [1:15:45<15:04,  1.35s/step]Training:  78%|███████▊  | 2330/3000 [1:15:47<15:02,  1.35s/step]Training:  78%|███████▊  | 2331/3000 [1:15:48<15:01,  1.35s/step]Training:  78%|███████▊  | 2332/3000 [1:15:49<14:59,  1.35s/step]Training:  78%|███████▊  | 2333/3000 [1:15:51<14:58,  1.35s/step]Training:  78%|███████▊  | 2334/3000 [1:15:52<14:57,  1.35s/step]Training:  78%|███████▊  | 2335/3000 [1:15:53<14:56,  1.35s/step]Training:  78%|███████▊  | 2336/3000 [1:15:55<14:55,  1.35s/step]Training:  78%|███████▊  | 2337/3000 [1:15:56<14:53,  1.35s/step]Training:  78%|███████▊  | 2338/3000 [1:15:57<14:52,  1.35s/step]Training:  78%|███████▊  | 2339/3000 [1:15:59<14:50,  1.35s/step]Training:  78%|███████▊  | 2340/3000 [1:16:00<14:49,  1.35s/step]Training:  78%|███████▊  | 2341/3000 [1:16:01<14:47,  1.35s/step]Training:  78%|███████▊  | 2342/3000 [1:16:03<14:46,  1.35s/step]Training:  78%|███████▊  | 2343/3000 [1:16:04<14:45,  1.35s/step]Training:  78%|███████▊  | 2344/3000 [1:16:05<14:43,  1.35s/step]Training:  78%|███████▊  | 2345/3000 [1:16:07<14:42,  1.35s/step]Training:  78%|███████▊  | 2346/3000 [1:16:08<14:40,  1.35s/step]Training:  78%|███████▊  | 2347/3000 [1:16:09<14:39,  1.35s/step]Training:  78%|███████▊  | 2348/3000 [1:16:11<14:38,  1.35s/step]Training:  78%|███████▊  | 2349/3000 [1:16:12<14:37,  1.35s/step]Training:  78%|███████▊  | 2350/3000 [1:16:14<14:35,  1.35s/step]12:25:22 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1788 lr=3.000e-04
12:25:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1457 lr=3.000e-04
12:25:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.0926 lr=3.000e-04
12:25:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1786 lr=3.000e-04
12:25:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1449 lr=3.000e-04
12:25:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1527 lr=3.000e-04
12:25:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1484 lr=3.000e-04
12:25:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=2350 loss=0.1082 lr=3.000e-04
Training:  78%|███████▊  | 2351/3000 [1:16:15<14:34,  1.35s/step]Training:  78%|███████▊  | 2352/3000 [1:16:16<14:33,  1.35s/step]Training:  78%|███████▊  | 2353/3000 [1:16:18<14:31,  1.35s/step]Training:  78%|███████▊  | 2354/3000 [1:16:19<14:30,  1.35s/step]Training:  78%|███████▊  | 2355/3000 [1:16:20<14:28,  1.35s/step]Training:  79%|███████▊  | 2356/3000 [1:16:22<14:27,  1.35s/step]Training:  79%|███████▊  | 2357/3000 [1:16:23<14:26,  1.35s/step]Training:  79%|███████▊  | 2358/3000 [1:16:24<14:25,  1.35s/step]Training:  79%|███████▊  | 2359/3000 [1:16:26<14:23,  1.35s/step]Training:  79%|███████▊  | 2360/3000 [1:16:27<14:22,  1.35s/step]Training:  79%|███████▊  | 2361/3000 [1:16:28<14:21,  1.35s/step]Training:  79%|███████▊  | 2362/3000 [1:16:30<14:19,  1.35s/step]Training:  79%|███████▉  | 2363/3000 [1:16:31<14:18,  1.35s/step]Training:  79%|███████▉  | 2364/3000 [1:16:32<14:16,  1.35s/step]Training:  79%|███████▉  | 2365/3000 [1:16:34<14:15,  1.35s/step]Training:  79%|███████▉  | 2366/3000 [1:16:35<14:14,  1.35s/step]Training:  79%|███████▉  | 2367/3000 [1:16:36<14:12,  1.35s/step]Training:  79%|███████▉  | 2368/3000 [1:16:38<14:11,  1.35s/step]Training:  79%|███████▉  | 2369/3000 [1:16:39<14:09,  1.35s/step]Training:  79%|███████▉  | 2370/3000 [1:16:40<14:08,  1.35s/step]Training:  79%|███████▉  | 2371/3000 [1:16:42<14:07,  1.35s/step]Training:  79%|███████▉  | 2372/3000 [1:16:43<14:05,  1.35s/step]Training:  79%|███████▉  | 2373/3000 [1:16:45<14:04,  1.35s/step]Training:  79%|███████▉  | 2374/3000 [1:16:46<14:03,  1.35s/step]Training:  79%|███████▉  | 2375/3000 [1:16:47<14:01,  1.35s/step]Training:  79%|███████▉  | 2376/3000 [1:16:49<14:00,  1.35s/step]Training:  79%|███████▉  | 2377/3000 [1:16:50<13:59,  1.35s/step]Training:  79%|███████▉  | 2378/3000 [1:16:51<13:57,  1.35s/step]Training:  79%|███████▉  | 2379/3000 [1:16:53<13:56,  1.35s/step]Training:  79%|███████▉  | 2380/3000 [1:16:54<13:55,  1.35s/step]Training:  79%|███████▉  | 2381/3000 [1:16:55<13:53,  1.35s/step]Training:  79%|███████▉  | 2382/3000 [1:16:57<13:52,  1.35s/step]Training:  79%|███████▉  | 2383/3000 [1:16:58<13:50,  1.35s/step]Training:  79%|███████▉  | 2384/3000 [1:16:59<13:50,  1.35s/step]Training:  80%|███████▉  | 2385/3000 [1:17:01<13:48,  1.35s/step]Training:  80%|███████▉  | 2386/3000 [1:17:02<13:47,  1.35s/step]Training:  80%|███████▉  | 2387/3000 [1:17:03<13:45,  1.35s/step]Training:  80%|███████▉  | 2388/3000 [1:17:05<13:44,  1.35s/step]Training:  80%|███████▉  | 2389/3000 [1:17:06<13:42,  1.35s/step]Training:  80%|███████▉  | 2390/3000 [1:17:07<13:41,  1.35s/step]Training:  80%|███████▉  | 2391/3000 [1:17:09<13:40,  1.35s/step]Training:  80%|███████▉  | 2392/3000 [1:17:10<13:39,  1.35s/step]Training:  80%|███████▉  | 2393/3000 [1:17:11<13:37,  1.35s/step]Training:  80%|███████▉  | 2394/3000 [1:17:13<13:36,  1.35s/step]Training:  80%|███████▉  | 2395/3000 [1:17:14<13:34,  1.35s/step]Training:  80%|███████▉  | 2396/3000 [1:17:15<13:33,  1.35s/step]Training:  80%|███████▉  | 2397/3000 [1:17:17<13:32,  1.35s/step]Training:  80%|███████▉  | 2398/3000 [1:17:18<13:30,  1.35s/step]Training:  80%|███████▉  | 2399/3000 [1:17:20<13:29,  1.35s/step]Training:  80%|████████  | 2400/3000 [1:17:21<13:28,  1.35s/step]12:26:30 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1061 lr=3.000e-04
12:26:52 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:26:52 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1262 lr=3.000e-04
12:27:14 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:27:14 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.0927 lr=3.000e-04
12:27:37 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:27:37 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1773 lr=3.000e-04
12:27:59 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:27:59 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1600 lr=3.000e-04
12:28:21 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:28:21 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1294 lr=3.000e-04
12:28:44 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:28:44 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1358 lr=3.000e-04
12:29:06 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
12:29:06 - trainer.gpt2-gsm8k-lora-main - INFO - step=2400 loss=0.1174 lr=3.000e-04
12:29:28 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2400 loss=1.1427 ppl=3.14
Training:  80%|████████  | 2401/3000 [1:20:19<9:04:01, 54.49s/step]Training:  80%|████████  | 2402/3000 [1:20:21<6:24:12, 38.55s/step]Training:  80%|████████  | 2403/3000 [1:20:22<4:32:30, 27.39s/step]Training:  80%|████████  | 2404/3000 [1:20:23<3:14:27, 19.58s/step]Training:  80%|████████  | 2405/3000 [1:20:25<2:19:53, 14.11s/step]Training:  80%|████████  | 2406/3000 [1:20:26<1:41:45, 10.28s/step]Training:  80%|████████  | 2407/3000 [1:20:27<1:15:06,  7.60s/step]Training:  80%|████████  | 2408/3000 [1:20:29<56:28,  5.72s/step]  Training:  80%|████████  | 2409/3000 [1:20:30<43:26,  4.41s/step]Training:  80%|████████  | 2410/3000 [1:20:31<34:20,  3.49s/step]Training:  80%|████████  | 2411/3000 [1:20:33<27:57,  2.85s/step]Training:  80%|████████  | 2412/3000 [1:20:34<23:29,  2.40s/step]Training:  80%|████████  | 2413/3000 [1:20:36<20:22,  2.08s/step]Training:  80%|████████  | 2414/3000 [1:20:37<18:11,  1.86s/step]Training:  80%|████████  | 2415/3000 [1:20:38<16:38,  1.71s/step]Training:  81%|████████  | 2416/3000 [1:20:40<15:33,  1.60s/step]Training:  81%|████████  | 2417/3000 [1:20:41<14:48,  1.52s/step]Training:  81%|████████  | 2418/3000 [1:20:42<14:15,  1.47s/step]Training:  81%|████████  | 2419/3000 [1:20:44<13:52,  1.43s/step]Training:  81%|████████  | 2420/3000 [1:20:45<13:36,  1.41s/step]Training:  81%|████████  | 2421/3000 [1:20:46<13:24,  1.39s/step]Training:  81%|████████  | 2422/3000 [1:20:48<13:15,  1.38s/step]Training:  81%|████████  | 2423/3000 [1:20:49<13:09,  1.37s/step]Training:  81%|████████  | 2424/3000 [1:20:50<13:04,  1.36s/step]Training:  81%|████████  | 2425/3000 [1:20:52<13:00,  1.36s/step]Training:  81%|████████  | 2426/3000 [1:20:53<12:57,  1.35s/step]Training:  81%|████████  | 2427/3000 [1:20:54<12:55,  1.35s/step]Training:  81%|████████  | 2428/3000 [1:20:56<12:53,  1.35s/step]Training:  81%|████████  | 2429/3000 [1:20:57<12:51,  1.35s/step]Training:  81%|████████  | 2430/3000 [1:20:58<12:49,  1.35s/step]Training:  81%|████████  | 2431/3000 [1:21:00<12:47,  1.35s/step]Training:  81%|████████  | 2432/3000 [1:21:01<12:45,  1.35s/step]Training:  81%|████████  | 2433/3000 [1:21:02<12:44,  1.35s/step]Training:  81%|████████  | 2434/3000 [1:21:04<12:42,  1.35s/step]Training:  81%|████████  | 2435/3000 [1:21:05<12:41,  1.35s/step]Training:  81%|████████  | 2436/3000 [1:21:07<12:40,  1.35s/step]Training:  81%|████████  | 2437/3000 [1:21:08<12:38,  1.35s/step]Training:  81%|████████▏ | 2438/3000 [1:21:09<12:37,  1.35s/step]Training:  81%|████████▏ | 2439/3000 [1:21:11<12:35,  1.35s/step]Training:  81%|████████▏ | 2440/3000 [1:21:12<12:34,  1.35s/step]Training:  81%|████████▏ | 2441/3000 [1:21:13<12:32,  1.35s/step]Training:  81%|████████▏ | 2442/3000 [1:21:15<12:31,  1.35s/step]Training:  81%|████████▏ | 2443/3000 [1:21:16<12:30,  1.35s/step]Training:  81%|████████▏ | 2444/3000 [1:21:17<12:28,  1.35s/step]Training:  82%|████████▏ | 2445/3000 [1:21:19<12:27,  1.35s/step]Training:  82%|████████▏ | 2446/3000 [1:21:20<12:26,  1.35s/step]Training:  82%|████████▏ | 2447/3000 [1:21:21<12:24,  1.35s/step]Training:  82%|████████▏ | 2448/3000 [1:21:23<12:23,  1.35s/step]Training:  82%|████████▏ | 2449/3000 [1:21:24<12:22,  1.35s/step]Training:  82%|████████▏ | 2450/3000 [1:21:25<12:20,  1.35s/step]12:30:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1343 lr=3.000e-04
12:30:34 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1655 lr=3.000e-04
12:30:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1606 lr=3.000e-04
12:30:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1062 lr=3.000e-04
12:30:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1826 lr=3.000e-04
12:30:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1055 lr=3.000e-04
12:30:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1142 lr=3.000e-04
12:30:35 - trainer.gpt2-gsm8k-lora-main - INFO - step=2450 loss=0.1040 lr=3.000e-04
Training:  82%|████████▏ | 2451/3000 [1:21:27<12:19,  1.35s/step]Training:  82%|████████▏ | 2452/3000 [1:21:28<12:18,  1.35s/step]Training:  82%|████████▏ | 2453/3000 [1:21:29<12:17,  1.35s/step]Training:  82%|████████▏ | 2454/3000 [1:21:31<12:15,  1.35s/step]Training:  82%|████████▏ | 2455/3000 [1:21:32<12:14,  1.35s/step]Training:  82%|████████▏ | 2456/3000 [1:21:33<12:12,  1.35s/step]Training:  82%|████████▏ | 2457/3000 [1:21:35<12:11,  1.35s/step]Training:  82%|████████▏ | 2458/3000 [1:21:36<12:10,  1.35s/step]Training:  82%|████████▏ | 2459/3000 [1:21:38<12:08,  1.35s/step]Training:  82%|████████▏ | 2460/3000 [1:21:39<12:07,  1.35s/step]Training:  82%|████████▏ | 2461/3000 [1:21:40<12:05,  1.35s/step]Training:  82%|████████▏ | 2462/3000 [1:21:42<12:04,  1.35s/step]Training:  82%|████████▏ | 2463/3000 [1:21:43<12:03,  1.35s/step]Training:  82%|████████▏ | 2464/3000 [1:21:44<12:01,  1.35s/step]Training:  82%|████████▏ | 2465/3000 [1:21:46<12:00,  1.35s/step]Training:  82%|████████▏ | 2466/3000 [1:21:47<11:59,  1.35s/step]Training:  82%|████████▏ | 2467/3000 [1:21:48<11:57,  1.35s/step]Training:  82%|████████▏ | 2468/3000 [1:21:50<11:56,  1.35s/step]Training:  82%|████████▏ | 2469/3000 [1:21:51<11:55,  1.35s/step]Training:  82%|████████▏ | 2470/3000 [1:21:52<11:53,  1.35s/step]Training:  82%|████████▏ | 2471/3000 [1:21:54<11:52,  1.35s/step]Training:  82%|████████▏ | 2472/3000 [1:21:55<11:51,  1.35s/step]Training:  82%|████████▏ | 2473/3000 [1:21:56<11:49,  1.35s/step]Training:  82%|████████▏ | 2474/3000 [1:21:58<11:48,  1.35s/step]Training:  82%|████████▎ | 2475/3000 [1:21:59<11:47,  1.35s/step]Training:  83%|████████▎ | 2476/3000 [1:22:00<11:45,  1.35s/step]Training:  83%|████████▎ | 2477/3000 [1:22:02<11:44,  1.35s/step]Training:  83%|████████▎ | 2478/3000 [1:22:03<11:43,  1.35s/step]Training:  83%|████████▎ | 2479/3000 [1:22:04<11:41,  1.35s/step]Training:  83%|████████▎ | 2480/3000 [1:22:06<11:40,  1.35s/step]Training:  83%|████████▎ | 2481/3000 [1:22:07<11:38,  1.35s/step]Training:  83%|████████▎ | 2482/3000 [1:22:08<11:37,  1.35s/step]Training:  83%|████████▎ | 2483/3000 [1:22:10<11:36,  1.35s/step]Training:  83%|████████▎ | 2484/3000 [1:22:11<11:34,  1.35s/step]Training:  83%|████████▎ | 2485/3000 [1:22:13<11:33,  1.35s/step]Training:  83%|████████▎ | 2486/3000 [1:22:14<11:32,  1.35s/step]Training:  83%|████████▎ | 2487/3000 [1:22:15<11:30,  1.35s/step]Training:  83%|████████▎ | 2488/3000 [1:22:17<11:29,  1.35s/step]Training:  83%|████████▎ | 2489/3000 [1:22:18<11:28,  1.35s/step]Training:  83%|████████▎ | 2490/3000 [1:22:19<11:26,  1.35s/step]Training:  83%|████████▎ | 2491/3000 [1:22:21<11:25,  1.35s/step]Training:  83%|████████▎ | 2492/3000 [1:22:22<11:24,  1.35s/step]Training:  83%|████████▎ | 2493/3000 [1:22:23<11:22,  1.35s/step]Training:  83%|████████▎ | 2494/3000 [1:22:25<11:21,  1.35s/step]Training:  83%|████████▎ | 2495/3000 [1:22:26<11:20,  1.35s/step]Training:  83%|████████▎ | 2496/3000 [1:22:27<11:19,  1.35s/step]Training:  83%|████████▎ | 2497/3000 [1:22:29<11:17,  1.35s/step]Training:  83%|████████▎ | 2498/3000 [1:22:30<11:16,  1.35s/step]Training:  83%|████████▎ | 2499/3000 [1:22:31<11:15,  1.35s/step]Training:  83%|████████▎ | 2500/3000 [1:22:33<11:13,  1.35s/step]12:31:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1756 lr=3.000e-04
12:31:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1547 lr=3.000e-04
12:31:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1288 lr=3.000e-04
12:31:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1179 lr=3.000e-04
12:31:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1799 lr=3.000e-04
12:31:42 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1595 lr=3.000e-04
12:31:43 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1392 lr=3.000e-04
12:31:43 - trainer.gpt2-gsm8k-lora-main - INFO - step=2500 loss=0.1333 lr=3.000e-04
Training:  83%|████████▎ | 2501/3000 [1:22:34<11:12,  1.35s/step]Training:  83%|████████▎ | 2502/3000 [1:22:35<11:10,  1.35s/step]Training:  83%|████████▎ | 2503/3000 [1:22:37<11:09,  1.35s/step]Training:  83%|████████▎ | 2504/3000 [1:22:38<11:08,  1.35s/step]Training:  84%|████████▎ | 2505/3000 [1:22:39<11:06,  1.35s/step]Training:  84%|████████▎ | 2506/3000 [1:22:41<11:05,  1.35s/step]Training:  84%|████████▎ | 2507/3000 [1:22:42<11:03,  1.35s/step]Training:  84%|████████▎ | 2508/3000 [1:22:44<11:02,  1.35s/step]Training:  84%|████████▎ | 2509/3000 [1:22:45<11:01,  1.35s/step]Training:  84%|████████▎ | 2510/3000 [1:22:46<11:00,  1.35s/step]Training:  84%|████████▎ | 2511/3000 [1:22:48<10:58,  1.35s/step]Training:  84%|████████▎ | 2512/3000 [1:22:49<10:57,  1.35s/step]Training:  84%|████████▍ | 2513/3000 [1:22:50<10:55,  1.35s/step]Training:  84%|████████▍ | 2514/3000 [1:22:52<10:54,  1.35s/step]Training:  84%|████████▍ | 2515/3000 [1:22:53<10:53,  1.35s/step]Training:  84%|████████▍ | 2516/3000 [1:22:54<10:51,  1.35s/step]Training:  84%|████████▍ | 2517/3000 [1:22:56<10:50,  1.35s/step]Training:  84%|████████▍ | 2518/3000 [1:22:57<10:49,  1.35s/step]Training:  84%|████████▍ | 2519/3000 [1:22:58<10:47,  1.35s/step]Training:  84%|████████▍ | 2520/3000 [1:23:00<10:46,  1.35s/step]Training:  84%|████████▍ | 2521/3000 [1:23:01<10:45,  1.35s/step]Training:  84%|████████▍ | 2522/3000 [1:23:02<10:43,  1.35s/step]Training:  84%|████████▍ | 2523/3000 [1:23:04<10:42,  1.35s/step]Training:  84%|████████▍ | 2524/3000 [1:23:05<10:41,  1.35s/step]Training:  84%|████████▍ | 2525/3000 [1:23:06<10:39,  1.35s/step]Training:  84%|████████▍ | 2526/3000 [1:23:08<10:38,  1.35s/step]Training:  84%|████████▍ | 2527/3000 [1:23:09<10:37,  1.35s/step]Training:  84%|████████▍ | 2528/3000 [1:23:10<10:35,  1.35s/step]Training:  84%|████████▍ | 2529/3000 [1:23:12<10:34,  1.35s/step]Training:  84%|████████▍ | 2530/3000 [1:23:13<10:32,  1.35s/step]Training:  84%|████████▍ | 2531/3000 [1:23:14<10:31,  1.35s/step]Training:  84%|████████▍ | 2532/3000 [1:23:16<10:30,  1.35s/step]Training:  84%|████████▍ | 2533/3000 [1:23:17<10:28,  1.35s/step]Training:  84%|████████▍ | 2534/3000 [1:23:19<10:27,  1.35s/step]Training:  84%|████████▍ | 2535/3000 [1:23:20<10:26,  1.35s/step]Training:  85%|████████▍ | 2536/3000 [1:23:21<10:24,  1.35s/step]Training:  85%|████████▍ | 2537/3000 [1:23:23<10:23,  1.35s/step]Training:  85%|████████▍ | 2538/3000 [1:23:24<10:22,  1.35s/step]Training:  85%|████████▍ | 2539/3000 [1:23:25<10:20,  1.35s/step]Training:  85%|████████▍ | 2540/3000 [1:23:27<10:19,  1.35s/step]Training:  85%|████████▍ | 2541/3000 [1:23:28<10:18,  1.35s/step]Training:  85%|████████▍ | 2542/3000 [1:23:29<10:17,  1.35s/step]Training:  85%|████████▍ | 2543/3000 [1:23:31<10:15,  1.35s/step]Training:  85%|████████▍ | 2544/3000 [1:23:32<10:14,  1.35s/step]Training:  85%|████████▍ | 2545/3000 [1:23:33<10:12,  1.35s/step]Training:  85%|████████▍ | 2546/3000 [1:23:35<10:11,  1.35s/step]Training:  85%|████████▍ | 2547/3000 [1:23:36<10:10,  1.35s/step]Training:  85%|████████▍ | 2548/3000 [1:23:37<10:08,  1.35s/step]Training:  85%|████████▍ | 2549/3000 [1:23:39<10:07,  1.35s/step]Training:  85%|████████▌ | 2550/3000 [1:23:40<10:06,  1.35s/step]12:32:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.2318 lr=3.000e-04
12:32:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.1814 lr=3.000e-04
12:32:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.1065 lr=3.000e-04
12:32:49 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.0804 lr=3.000e-04
12:32:50 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.2316 lr=3.000e-04
12:32:50 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.1580 lr=3.000e-04
12:32:50 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.1054 lr=3.000e-04
12:32:50 - trainer.gpt2-gsm8k-lora-main - INFO - step=2550 loss=0.1795 lr=3.000e-04
Training:  85%|████████▌ | 2551/3000 [1:23:41<10:04,  1.35s/step]Training:  85%|████████▌ | 2552/3000 [1:23:43<10:03,  1.35s/step]Training:  85%|████████▌ | 2553/3000 [1:23:44<10:02,  1.35s/step]Training:  85%|████████▌ | 2554/3000 [1:23:45<10:00,  1.35s/step]Training:  85%|████████▌ | 2555/3000 [1:23:47<09:59,  1.35s/step]Training:  85%|████████▌ | 2556/3000 [1:23:48<09:58,  1.35s/step]Training:  85%|████████▌ | 2557/3000 [1:23:50<09:56,  1.35s/step]Training:  85%|████████▌ | 2558/3000 [1:23:51<09:55,  1.35s/step]Training:  85%|████████▌ | 2559/3000 [1:23:52<09:54,  1.35s/step]Training:  85%|████████▌ | 2560/3000 [1:23:54<09:53,  1.35s/step]Training:  85%|████████▌ | 2561/3000 [1:23:55<09:51,  1.35s/step]Training:  85%|████████▌ | 2562/3000 [1:23:56<09:50,  1.35s/step]Training:  85%|████████▌ | 2563/3000 [1:23:58<09:48,  1.35s/step]Training:  85%|████████▌ | 2564/3000 [1:23:59<09:47,  1.35s/step]Training:  86%|████████▌ | 2565/3000 [1:24:00<09:46,  1.35s/step]Training:  86%|████████▌ | 2566/3000 [1:24:02<09:44,  1.35s/step]Training:  86%|████████▌ | 2567/3000 [1:24:03<09:43,  1.35s/step]Training:  86%|████████▌ | 2568/3000 [1:24:04<09:42,  1.35s/step]Training:  86%|████████▌ | 2569/3000 [1:24:06<09:40,  1.35s/step]Training:  86%|████████▌ | 2570/3000 [1:24:07<09:39,  1.35s/step]Training:  86%|████████▌ | 2571/3000 [1:24:08<09:38,  1.35s/step]Training:  86%|████████▌ | 2572/3000 [1:24:10<09:36,  1.35s/step]Training:  86%|████████▌ | 2573/3000 [1:24:11<09:35,  1.35s/step]Training:  86%|████████▌ | 2574/3000 [1:24:12<09:33,  1.35s/step]Training:  86%|████████▌ | 2575/3000 [1:24:14<09:32,  1.35s/step]Training:  86%|████████▌ | 2576/3000 [1:24:15<09:31,  1.35s/step]Training:  86%|████████▌ | 2577/3000 [1:24:16<09:29,  1.35s/step]Training:  86%|████████▌ | 2578/3000 [1:24:18<09:28,  1.35s/step]Training:  86%|████████▌ | 2579/3000 [1:24:19<09:27,  1.35s/step]Training:  86%|████████▌ | 2580/3000 [1:24:21<09:25,  1.35s/step]Training:  86%|████████▌ | 2581/3000 [1:24:22<09:24,  1.35s/step]Training:  86%|████████▌ | 2582/3000 [1:24:23<09:23,  1.35s/step]Training:  86%|████████▌ | 2583/3000 [1:24:25<09:21,  1.35s/step]Training:  86%|████████▌ | 2584/3000 [1:24:26<09:20,  1.35s/step]Training:  86%|████████▌ | 2585/3000 [1:24:27<09:19,  1.35s/step]Training:  86%|████████▌ | 2586/3000 [1:24:29<09:17,  1.35s/step]Training:  86%|████████▌ | 2587/3000 [1:24:30<09:16,  1.35s/step]Training:  86%|████████▋ | 2588/3000 [1:24:31<09:14,  1.35s/step]Training:  86%|████████▋ | 2589/3000 [1:24:33<09:13,  1.35s/step]Training:  86%|████████▋ | 2590/3000 [1:24:34<09:12,  1.35s/step]Training:  86%|████████▋ | 2591/3000 [1:24:35<09:10,  1.35s/step]Training:  86%|████████▋ | 2592/3000 [1:24:37<09:09,  1.35s/step]Training:  86%|████████▋ | 2593/3000 [1:24:38<09:08,  1.35s/step]Training:  86%|████████▋ | 2594/3000 [1:24:39<09:07,  1.35s/step]Training:  86%|████████▋ | 2595/3000 [1:24:41<09:05,  1.35s/step]Training:  87%|████████▋ | 2596/3000 [1:24:42<09:04,  1.35s/step]Training:  87%|████████▋ | 2597/3000 [1:24:43<09:02,  1.35s/step]Training:  87%|████████▋ | 2598/3000 [1:24:45<09:01,  1.35s/step]Training:  87%|████████▋ | 2599/3000 [1:24:46<09:00,  1.35s/step]Training:  87%|████████▋ | 2600/3000 [1:24:47<08:58,  1.35s/step]12:33:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1121 lr=3.000e-04
12:33:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1300 lr=3.000e-04
12:33:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1546 lr=3.000e-04
12:33:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.0957 lr=3.000e-04
12:33:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1440 lr=3.000e-04
12:33:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1432 lr=3.000e-04
12:33:57 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1220 lr=3.000e-04
12:33:58 - trainer.gpt2-gsm8k-lora-main - INFO - step=2600 loss=0.1421 lr=3.000e-04
Training:  87%|████████▋ | 2601/3000 [1:24:49<08:57,  1.35s/step]Training:  87%|████████▋ | 2602/3000 [1:24:50<08:56,  1.35s/step]Training:  87%|████████▋ | 2603/3000 [1:24:51<08:54,  1.35s/step]Training:  87%|████████▋ | 2604/3000 [1:24:53<08:53,  1.35s/step]Training:  87%|████████▋ | 2605/3000 [1:24:54<08:52,  1.35s/step]Training:  87%|████████▋ | 2606/3000 [1:24:56<08:50,  1.35s/step]Training:  87%|████████▋ | 2607/3000 [1:24:57<08:49,  1.35s/step]Training:  87%|████████▋ | 2608/3000 [1:24:58<08:47,  1.35s/step]Training:  87%|████████▋ | 2609/3000 [1:25:00<08:46,  1.35s/step]Training:  87%|████████▋ | 2610/3000 [1:25:01<08:45,  1.35s/step]Training:  87%|████████▋ | 2611/3000 [1:25:02<08:43,  1.35s/step]Training:  87%|████████▋ | 2612/3000 [1:25:04<08:42,  1.35s/step]Training:  87%|████████▋ | 2613/3000 [1:25:05<08:41,  1.35s/step]Training:  87%|████████▋ | 2614/3000 [1:25:06<08:39,  1.35s/step]Training:  87%|████████▋ | 2615/3000 [1:25:08<08:38,  1.35s/step]Training:  87%|████████▋ | 2616/3000 [1:25:09<08:37,  1.35s/step]Training:  87%|████████▋ | 2617/3000 [1:25:10<08:35,  1.35s/step]Training:  87%|████████▋ | 2618/3000 [1:25:12<08:34,  1.35s/step]Training:  87%|████████▋ | 2619/3000 [1:25:13<08:33,  1.35s/step]Training:  87%|████████▋ | 2620/3000 [1:25:14<08:32,  1.35s/step]Training:  87%|████████▋ | 2621/3000 [1:25:16<08:30,  1.35s/step]Training:  87%|████████▋ | 2622/3000 [1:25:17<08:29,  1.35s/step]Training:  87%|████████▋ | 2623/3000 [1:25:18<08:28,  1.35s/step]Training:  87%|████████▋ | 2624/3000 [1:25:20<08:26,  1.35s/step]Training:  88%|████████▊ | 2625/3000 [1:25:21<08:25,  1.35s/step]Training:  88%|████████▊ | 2626/3000 [1:25:22<08:23,  1.35s/step]Training:  88%|████████▊ | 2627/3000 [1:25:24<08:22,  1.35s/step]Training:  88%|████████▊ | 2628/3000 [1:25:25<08:21,  1.35s/step]Training:  88%|████████▊ | 2629/3000 [1:25:27<08:19,  1.35s/step]Training:  88%|████████▊ | 2630/3000 [1:25:28<08:18,  1.35s/step]Training:  88%|████████▊ | 2631/3000 [1:25:29<08:17,  1.35s/step]Training:  88%|████████▊ | 2632/3000 [1:25:31<08:15,  1.35s/step]Training:  88%|████████▊ | 2633/3000 [1:25:32<08:14,  1.35s/step]Training:  88%|████████▊ | 2634/3000 [1:25:33<08:12,  1.35s/step]Training:  88%|████████▊ | 2635/3000 [1:25:35<08:11,  1.35s/step]Training:  88%|████████▊ | 2636/3000 [1:25:36<08:10,  1.35s/step]Training:  88%|████████▊ | 2637/3000 [1:25:37<08:08,  1.35s/step]Training:  88%|████████▊ | 2638/3000 [1:25:39<08:07,  1.35s/step]Training:  88%|████████▊ | 2639/3000 [1:25:40<08:06,  1.35s/step]Training:  88%|████████▊ | 2640/3000 [1:25:41<08:05,  1.35s/step]Training:  88%|████████▊ | 2641/3000 [1:25:43<08:03,  1.35s/step]Training:  88%|████████▊ | 2642/3000 [1:25:44<08:02,  1.35s/step]Training:  88%|████████▊ | 2643/3000 [1:25:45<08:01,  1.35s/step]Training:  88%|████████▊ | 2644/3000 [1:25:47<07:59,  1.35s/step]Training:  88%|████████▊ | 2645/3000 [1:25:48<07:58,  1.35s/step]Training:  88%|████████▊ | 2646/3000 [1:25:49<07:56,  1.35s/step]Training:  88%|████████▊ | 2647/3000 [1:25:51<07:55,  1.35s/step]Training:  88%|████████▊ | 2648/3000 [1:25:52<07:54,  1.35s/step]Training:  88%|████████▊ | 2649/3000 [1:25:53<07:52,  1.35s/step]Training:  88%|████████▊ | 2650/3000 [1:25:55<07:51,  1.35s/step]12:35:04 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1551 lr=3.000e-04
12:35:04 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1378 lr=3.000e-04
12:35:04 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1056 lr=3.000e-04
12:35:04 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1374 lr=3.000e-04
12:35:04 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1664 lr=3.000e-04
12:35:05 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1936 lr=3.000e-04
12:35:05 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1448 lr=3.000e-04
12:35:05 - trainer.gpt2-gsm8k-lora-main - INFO - step=2650 loss=0.1608 lr=3.000e-04
Training:  88%|████████▊ | 2651/3000 [1:25:56<07:50,  1.35s/step]Training:  88%|████████▊ | 2652/3000 [1:25:58<07:48,  1.35s/step]Training:  88%|████████▊ | 2653/3000 [1:25:59<07:47,  1.35s/step]Training:  88%|████████▊ | 2654/3000 [1:26:00<07:46,  1.35s/step]Training:  88%|████████▊ | 2655/3000 [1:26:02<07:44,  1.35s/step]Training:  89%|████████▊ | 2656/3000 [1:26:03<07:43,  1.35s/step]Training:  89%|████████▊ | 2657/3000 [1:26:04<07:42,  1.35s/step]Training:  89%|████████▊ | 2658/3000 [1:26:06<07:40,  1.35s/step]Training:  89%|████████▊ | 2659/3000 [1:26:07<07:39,  1.35s/step]Training:  89%|████████▊ | 2660/3000 [1:26:08<07:37,  1.35s/step]Training:  89%|████████▊ | 2661/3000 [1:26:10<07:36,  1.35s/step]Training:  89%|████████▊ | 2662/3000 [1:26:11<07:35,  1.35s/step]Training:  89%|████████▉ | 2663/3000 [1:26:12<07:33,  1.35s/step]Training:  89%|████████▉ | 2664/3000 [1:26:14<07:32,  1.35s/step]Training:  89%|████████▉ | 2665/3000 [1:26:15<07:31,  1.35s/step]Training:  89%|████████▉ | 2666/3000 [1:26:16<07:29,  1.35s/step]Training:  89%|████████▉ | 2667/3000 [1:26:18<07:28,  1.35s/step]Training:  89%|████████▉ | 2668/3000 [1:26:19<07:27,  1.35s/step]Training:  89%|████████▉ | 2669/3000 [1:26:20<07:25,  1.35s/step]Training:  89%|████████▉ | 2670/3000 [1:26:22<07:24,  1.35s/step]Training:  89%|████████▉ | 2671/3000 [1:26:23<07:23,  1.35s/step]Training:  89%|████████▉ | 2672/3000 [1:26:24<07:21,  1.35s/step]Training:  89%|████████▉ | 2673/3000 [1:26:26<07:20,  1.35s/step]Training:  89%|████████▉ | 2674/3000 [1:26:27<07:19,  1.35s/step]Training:  89%|████████▉ | 2675/3000 [1:26:28<07:17,  1.35s/step]Training:  89%|████████▉ | 2676/3000 [1:26:30<07:16,  1.35s/step]Training:  89%|████████▉ | 2677/3000 [1:26:31<07:15,  1.35s/step]Training:  89%|████████▉ | 2678/3000 [1:26:33<07:13,  1.35s/step]Training:  89%|████████▉ | 2679/3000 [1:26:34<07:12,  1.35s/step]Training:  89%|████████▉ | 2680/3000 [1:26:35<07:11,  1.35s/step]Training:  89%|████████▉ | 2681/3000 [1:26:37<07:09,  1.35s/step]Training:  89%|████████▉ | 2682/3000 [1:26:38<07:08,  1.35s/step]Training:  89%|████████▉ | 2683/3000 [1:26:39<07:06,  1.35s/step]Training:  89%|████████▉ | 2684/3000 [1:26:41<07:05,  1.35s/step]Training:  90%|████████▉ | 2685/3000 [1:26:42<07:04,  1.35s/step]Training:  90%|████████▉ | 2686/3000 [1:26:43<07:02,  1.35s/step]Training:  90%|████████▉ | 2687/3000 [1:26:45<07:01,  1.35s/step]Training:  90%|████████▉ | 2688/3000 [1:26:46<07:00,  1.35s/step]Training:  90%|████████▉ | 2689/3000 [1:26:47<06:58,  1.35s/step]Training:  90%|████████▉ | 2690/3000 [1:26:49<06:57,  1.35s/step]Training:  90%|████████▉ | 2691/3000 [1:26:50<06:56,  1.35s/step]Training:  90%|████████▉ | 2692/3000 [1:26:51<06:54,  1.35s/step]Training:  90%|████████▉ | 2693/3000 [1:26:53<06:53,  1.35s/step]Training:  90%|████████▉ | 2694/3000 [1:26:54<06:52,  1.35s/step]Training:  90%|████████▉ | 2695/3000 [1:26:55<06:50,  1.35s/step]Training:  90%|████████▉ | 2696/3000 [1:26:57<06:49,  1.35s/step]Training:  90%|████████▉ | 2697/3000 [1:26:58<06:48,  1.35s/step]Training:  90%|████████▉ | 2698/3000 [1:26:59<06:46,  1.35s/step]Training:  90%|████████▉ | 2699/3000 [1:27:01<06:45,  1.35s/step]Training:  90%|█████████ | 2700/3000 [1:27:02<06:44,  1.35s/step]12:36:11 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.2022 lr=3.000e-04
12:36:33 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:36:33 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.2603 lr=3.000e-04
12:36:56 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:36:56 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.1327 lr=3.000e-04
12:37:18 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:37:18 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.1722 lr=3.000e-04
12:37:40 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:37:40 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.1761 lr=3.000e-04
12:38:02 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:38:03 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.1745 lr=3.000e-04
12:38:25 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:38:25 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.1687 lr=3.000e-04
12:38:47 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
12:38:47 - trainer.gpt2-gsm8k-lora-main - INFO - step=2700 loss=0.1242 lr=3.000e-04
12:39:09 - trainer.gpt2-gsm8k-lora-main - INFO - eval step=2700 loss=1.1422 ppl=3.13
Training:  90%|█████████ | 2701/3000 [1:30:01<4:31:30, 54.48s/step]Training:  90%|█████████ | 2702/3000 [1:30:02<3:11:25, 38.54s/step]Training:  90%|█████████ | 2703/3000 [1:30:03<2:15:32, 27.38s/step]Training:  90%|█████████ | 2704/3000 [1:30:05<1:36:33, 19.57s/step]Training:  90%|█████████ | 2705/3000 [1:30:06<1:09:20, 14.10s/step]Training:  90%|█████████ | 2706/3000 [1:30:07<50:21, 10.28s/step]  Training:  90%|█████████ | 2707/3000 [1:30:09<37:06,  7.60s/step]Training:  90%|█████████ | 2708/3000 [1:30:10<27:50,  5.72s/step]Training:  90%|█████████ | 2709/3000 [1:30:11<21:23,  4.41s/step]Training:  90%|█████████ | 2710/3000 [1:30:13<16:52,  3.49s/step]Training:  90%|█████████ | 2711/3000 [1:30:14<13:42,  2.85s/step]Training:  90%|█████████ | 2712/3000 [1:30:15<11:30,  2.40s/step]Training:  90%|█████████ | 2713/3000 [1:30:17<09:57,  2.08s/step]Training:  90%|█████████ | 2714/3000 [1:30:18<08:52,  1.86s/step]Training:  90%|█████████ | 2715/3000 [1:30:19<08:06,  1.71s/step]Training:  91%|█████████ | 2716/3000 [1:30:21<07:34,  1.60s/step]Training:  91%|█████████ | 2717/3000 [1:30:22<07:10,  1.52s/step]Training:  91%|█████████ | 2718/3000 [1:30:24<06:54,  1.47s/step]Training:  91%|█████████ | 2719/3000 [1:30:25<06:42,  1.43s/step]Training:  91%|█████████ | 2720/3000 [1:30:26<06:33,  1.41s/step]Training:  91%|█████████ | 2721/3000 [1:30:28<06:27,  1.39s/step]Training:  91%|█████████ | 2722/3000 [1:30:29<06:22,  1.38s/step]Training:  91%|█████████ | 2723/3000 [1:30:30<06:18,  1.37s/step]Training:  91%|█████████ | 2724/3000 [1:30:32<06:15,  1.36s/step]Training:  91%|█████████ | 2725/3000 [1:30:33<06:13,  1.36s/step]Training:  91%|█████████ | 2726/3000 [1:30:34<06:11,  1.35s/step]Training:  91%|█████████ | 2727/3000 [1:30:36<06:09,  1.35s/step]Training:  91%|█████████ | 2728/3000 [1:30:37<06:07,  1.35s/step]Training:  91%|█████████ | 2729/3000 [1:30:38<06:05,  1.35s/step]Training:  91%|█████████ | 2730/3000 [1:30:40<06:04,  1.35s/step]Training:  91%|█████████ | 2731/3000 [1:30:41<06:02,  1.35s/step]Training:  91%|█████████ | 2732/3000 [1:30:42<06:01,  1.35s/step]Training:  91%|█████████ | 2733/3000 [1:30:44<05:59,  1.35s/step]Training:  91%|█████████ | 2734/3000 [1:30:45<05:58,  1.35s/step]Training:  91%|█████████ | 2735/3000 [1:30:46<05:56,  1.35s/step]Training:  91%|█████████ | 2736/3000 [1:30:48<05:55,  1.35s/step]Training:  91%|█████████ | 2737/3000 [1:30:49<05:54,  1.35s/step]Training:  91%|█████████▏| 2738/3000 [1:30:50<05:52,  1.35s/step]Training:  91%|█████████▏| 2739/3000 [1:30:52<05:51,  1.35s/step]Training:  91%|█████████▏| 2740/3000 [1:30:53<05:50,  1.35s/step]Training:  91%|█████████▏| 2741/3000 [1:30:54<05:48,  1.35s/step]Training:  91%|█████████▏| 2742/3000 [1:30:56<05:47,  1.35s/step]Training:  91%|█████████▏| 2743/3000 [1:30:57<05:46,  1.35s/step]Training:  91%|█████████▏| 2744/3000 [1:30:59<05:44,  1.35s/step]Training:  92%|█████████▏| 2745/3000 [1:31:00<05:43,  1.35s/step]Training:  92%|█████████▏| 2746/3000 [1:31:01<05:42,  1.35s/step]Training:  92%|█████████▏| 2747/3000 [1:31:03<05:40,  1.35s/step]Training:  92%|█████████▏| 2748/3000 [1:31:04<05:39,  1.35s/step]Training:  92%|█████████▏| 2749/3000 [1:31:05<05:37,  1.35s/step]Training:  92%|█████████▏| 2750/3000 [1:31:07<05:36,  1.35s/step]12:40:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1195 lr=3.000e-04
12:40:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1515 lr=3.000e-04
12:40:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1748 lr=3.000e-04
12:40:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1159 lr=3.000e-04
12:40:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1324 lr=3.000e-04
12:40:16 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1372 lr=3.000e-04
12:40:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1431 lr=3.000e-04
12:40:17 - trainer.gpt2-gsm8k-lora-main - INFO - step=2750 loss=0.1003 lr=3.000e-04
Training:  92%|█████████▏| 2751/3000 [1:31:08<05:35,  1.35s/step]Training:  92%|█████████▏| 2752/3000 [1:31:09<05:33,  1.35s/step]Training:  92%|█████████▏| 2753/3000 [1:31:11<05:32,  1.35s/step]Training:  92%|█████████▏| 2754/3000 [1:31:12<05:31,  1.35s/step]Training:  92%|█████████▏| 2755/3000 [1:31:13<05:29,  1.35s/step]Training:  92%|█████████▏| 2756/3000 [1:31:15<05:28,  1.35s/step]Training:  92%|█████████▏| 2757/3000 [1:31:16<05:27,  1.35s/step]Training:  92%|█████████▏| 2758/3000 [1:31:17<05:25,  1.35s/step]Training:  92%|█████████▏| 2759/3000 [1:31:19<05:24,  1.35s/step]Training:  92%|█████████▏| 2760/3000 [1:31:20<05:23,  1.35s/step]Training:  92%|█████████▏| 2761/3000 [1:31:21<05:21,  1.35s/step]Training:  92%|█████████▏| 2762/3000 [1:31:23<05:20,  1.35s/step]Training:  92%|█████████▏| 2763/3000 [1:31:24<05:19,  1.35s/step]Training:  92%|█████████▏| 2764/3000 [1:31:25<05:17,  1.35s/step]Training:  92%|█████████▏| 2765/3000 [1:31:27<05:16,  1.35s/step]Training:  92%|█████████▏| 2766/3000 [1:31:28<05:15,  1.35s/step]Training:  92%|█████████▏| 2767/3000 [1:31:29<05:13,  1.35s/step]Training:  92%|█████████▏| 2768/3000 [1:31:31<05:12,  1.35s/step]Training:  92%|█████████▏| 2769/3000 [1:31:32<05:11,  1.35s/step]Training:  92%|█████████▏| 2770/3000 [1:31:34<05:09,  1.35s/step]Training:  92%|█████████▏| 2771/3000 [1:31:35<05:08,  1.35s/step]Training:  92%|█████████▏| 2772/3000 [1:31:36<05:07,  1.35s/step]Training:  92%|█████████▏| 2773/3000 [1:31:38<05:05,  1.35s/step]Training:  92%|█████████▏| 2774/3000 [1:31:39<05:04,  1.35s/step]Training:  92%|█████████▎| 2775/3000 [1:31:40<05:03,  1.35s/step]Training:  93%|█████████▎| 2776/3000 [1:31:42<05:01,  1.35s/step]Training:  93%|█████████▎| 2777/3000 [1:31:43<05:00,  1.35s/step]Training:  93%|█████████▎| 2778/3000 [1:31:44<04:59,  1.35s/step]Training:  93%|█████████▎| 2779/3000 [1:31:46<04:57,  1.35s/step]Training:  93%|█████████▎| 2780/3000 [1:31:47<04:56,  1.35s/step]Training:  93%|█████████▎| 2781/3000 [1:31:48<04:54,  1.35s/step]Training:  93%|█████████▎| 2782/3000 [1:31:50<04:53,  1.35s/step]Training:  93%|█████████▎| 2783/3000 [1:31:51<04:52,  1.35s/step]Training:  93%|█████████▎| 2784/3000 [1:31:52<04:50,  1.35s/step]Training:  93%|█████████▎| 2785/3000 [1:31:54<04:49,  1.35s/step]Training:  93%|█████████▎| 2786/3000 [1:31:55<04:48,  1.35s/step]Training:  93%|█████████▎| 2787/3000 [1:31:56<04:46,  1.35s/step]Training:  93%|█████████▎| 2788/3000 [1:31:58<04:45,  1.35s/step]Training:  93%|█████████▎| 2789/3000 [1:31:59<04:44,  1.35s/step]Training:  93%|█████████▎| 2790/3000 [1:32:00<04:42,  1.35s/step]Training:  93%|█████████▎| 2791/3000 [1:32:02<04:41,  1.35s/step]Training:  93%|█████████▎| 2792/3000 [1:32:03<04:40,  1.35s/step]Training:  93%|█████████▎| 2793/3000 [1:32:05<04:38,  1.35s/step]Training:  93%|█████████▎| 2794/3000 [1:32:06<04:37,  1.35s/step]Training:  93%|█████████▎| 2795/3000 [1:32:07<04:36,  1.35s/step]Training:  93%|█████████▎| 2796/3000 [1:32:09<04:34,  1.35s/step]Training:  93%|█████████▎| 2797/3000 [1:32:10<04:33,  1.35s/step]Training:  93%|█████████▎| 2798/3000 [1:32:11<04:32,  1.35s/step]Training:  93%|█████████▎| 2799/3000 [1:32:13<04:30,  1.35s/step]Training:  93%|█████████▎| 2800/3000 [1:32:14<04:29,  1.35s/step]12:41:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1539 lr=3.000e-04
12:41:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1188 lr=3.000e-04
12:41:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1983 lr=3.000e-04
12:41:23 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.2005 lr=3.000e-04
12:41:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1266 lr=3.000e-04
12:41:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1151 lr=3.000e-04
12:41:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1709 lr=3.000e-04
12:41:24 - trainer.gpt2-gsm8k-lora-main - INFO - step=2800 loss=0.1301 lr=3.000e-04
Training:  93%|█████████▎| 2801/3000 [1:32:15<04:27,  1.35s/step]Training:  93%|█████████▎| 2802/3000 [1:32:17<04:26,  1.35s/step]Training:  93%|█████████▎| 2803/3000 [1:32:18<04:25,  1.35s/step]Training:  93%|█████████▎| 2804/3000 [1:32:19<04:23,  1.35s/step]Training:  94%|█████████▎| 2805/3000 [1:32:21<04:22,  1.35s/step]Training:  94%|█████████▎| 2806/3000 [1:32:22<04:21,  1.35s/step]Training:  94%|█████████▎| 2807/3000 [1:32:23<04:19,  1.35s/step]Training:  94%|█████████▎| 2808/3000 [1:32:25<04:18,  1.35s/step]Training:  94%|█████████▎| 2809/3000 [1:32:26<04:17,  1.35s/step]Training:  94%|█████████▎| 2810/3000 [1:32:27<04:15,  1.35s/step]Training:  94%|█████████▎| 2811/3000 [1:32:29<04:14,  1.35s/step]Training:  94%|█████████▎| 2812/3000 [1:32:30<04:13,  1.35s/step]Training:  94%|█████████▍| 2813/3000 [1:32:31<04:11,  1.35s/step]Training:  94%|█████████▍| 2814/3000 [1:32:33<04:10,  1.35s/step]Training:  94%|█████████▍| 2815/3000 [1:32:34<04:09,  1.35s/step]Training:  94%|█████████▍| 2816/3000 [1:32:35<04:07,  1.35s/step]Training:  94%|█████████▍| 2817/3000 [1:32:37<04:06,  1.35s/step]Training:  94%|█████████▍| 2818/3000 [1:32:38<04:05,  1.35s/step]Training:  94%|█████████▍| 2819/3000 [1:32:40<04:03,  1.35s/step]Training:  94%|█████████▍| 2820/3000 [1:32:41<04:02,  1.35s/step]Training:  94%|█████████▍| 2821/3000 [1:32:42<04:00,  1.35s/step]Training:  94%|█████████▍| 2822/3000 [1:32:44<03:59,  1.35s/step]Training:  94%|█████████▍| 2823/3000 [1:32:45<03:58,  1.35s/step]Training:  94%|█████████▍| 2824/3000 [1:32:46<03:56,  1.35s/step]Training:  94%|█████████▍| 2825/3000 [1:32:48<03:55,  1.35s/step]Training:  94%|█████████▍| 2826/3000 [1:32:49<03:54,  1.35s/step]Training:  94%|█████████▍| 2827/3000 [1:32:50<03:52,  1.35s/step]Training:  94%|█████████▍| 2828/3000 [1:32:52<03:51,  1.35s/step]Training:  94%|█████████▍| 2829/3000 [1:32:53<03:50,  1.35s/step]Training:  94%|█████████▍| 2830/3000 [1:32:54<03:48,  1.35s/step]Training:  94%|█████████▍| 2831/3000 [1:32:56<03:47,  1.35s/step]Training:  94%|█████████▍| 2832/3000 [1:32:57<03:46,  1.35s/step]Training:  94%|█████████▍| 2833/3000 [1:32:58<03:44,  1.35s/step]Training:  94%|█████████▍| 2834/3000 [1:33:00<03:43,  1.35s/step]Training:  94%|█████████▍| 2835/3000 [1:33:01<03:42,  1.35s/step]Training:  95%|█████████▍| 2836/3000 [1:33:02<03:40,  1.35s/step]Training:  95%|█████████▍| 2837/3000 [1:33:04<03:39,  1.35s/step]Training:  95%|█████████▍| 2838/3000 [1:33:05<03:38,  1.35s/step]Training:  95%|█████████▍| 2839/3000 [1:33:06<03:36,  1.35s/step]Training:  95%|█████████▍| 2840/3000 [1:33:08<03:35,  1.35s/step]Training:  95%|█████████▍| 2841/3000 [1:33:09<03:34,  1.35s/step]Training:  95%|█████████▍| 2842/3000 [1:33:11<03:32,  1.35s/step]Training:  95%|█████████▍| 2843/3000 [1:33:12<03:31,  1.35s/step]Training:  95%|█████████▍| 2844/3000 [1:33:13<03:30,  1.35s/step]Training:  95%|█████████▍| 2845/3000 [1:33:15<03:28,  1.35s/step]Training:  95%|█████████▍| 2846/3000 [1:33:16<03:27,  1.35s/step]Training:  95%|█████████▍| 2847/3000 [1:33:17<03:26,  1.35s/step]Training:  95%|█████████▍| 2848/3000 [1:33:19<03:24,  1.35s/step]Training:  95%|█████████▍| 2849/3000 [1:33:20<03:23,  1.35s/step]Training:  95%|█████████▌| 2850/3000 [1:33:21<03:21,  1.35s/step]12:42:30 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1822 lr=3.000e-04
12:42:30 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1534 lr=3.000e-04
12:42:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1930 lr=3.000e-04
12:42:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1641 lr=3.000e-04
12:42:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.0808 lr=3.000e-04
12:42:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1039 lr=3.000e-04
12:42:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1236 lr=3.000e-04
12:42:31 - trainer.gpt2-gsm8k-lora-main - INFO - step=2850 loss=0.1140 lr=3.000e-04
Training:  95%|█████████▌| 2851/3000 [1:33:23<03:20,  1.35s/step]Training:  95%|█████████▌| 2852/3000 [1:33:24<03:19,  1.35s/step]Training:  95%|█████████▌| 2853/3000 [1:33:25<03:17,  1.35s/step]Training:  95%|█████████▌| 2854/3000 [1:33:27<03:16,  1.35s/step]Training:  95%|█████████▌| 2855/3000 [1:33:28<03:15,  1.35s/step]Training:  95%|█████████▌| 2856/3000 [1:33:29<03:13,  1.35s/step]Training:  95%|█████████▌| 2857/3000 [1:33:31<03:12,  1.35s/step]Training:  95%|█████████▌| 2858/3000 [1:33:32<03:11,  1.35s/step]Training:  95%|█████████▌| 2859/3000 [1:33:33<03:09,  1.35s/step]Training:  95%|█████████▌| 2860/3000 [1:33:35<03:08,  1.35s/step]Training:  95%|█████████▌| 2861/3000 [1:33:36<03:07,  1.35s/step]Training:  95%|█████████▌| 2862/3000 [1:33:37<03:05,  1.35s/step]Training:  95%|█████████▌| 2863/3000 [1:33:39<03:04,  1.35s/step]Training:  95%|█████████▌| 2864/3000 [1:33:40<03:03,  1.35s/step]Training:  96%|█████████▌| 2865/3000 [1:33:41<03:01,  1.35s/step]Training:  96%|█████████▌| 2866/3000 [1:33:43<03:00,  1.35s/step]Training:  96%|█████████▌| 2867/3000 [1:33:44<02:59,  1.35s/step]Training:  96%|█████████▌| 2868/3000 [1:33:46<02:57,  1.35s/step]Training:  96%|█████████▌| 2869/3000 [1:33:47<02:56,  1.35s/step]Training:  96%|█████████▌| 2870/3000 [1:33:48<02:55,  1.35s/step]Training:  96%|█████████▌| 2871/3000 [1:33:50<02:53,  1.35s/step]Training:  96%|█████████▌| 2872/3000 [1:33:51<02:52,  1.35s/step]Training:  96%|█████████▌| 2873/3000 [1:33:52<02:51,  1.35s/step]Training:  96%|█████████▌| 2874/3000 [1:33:54<02:49,  1.35s/step]Training:  96%|█████████▌| 2875/3000 [1:33:55<02:48,  1.35s/step]Training:  96%|█████████▌| 2876/3000 [1:33:56<02:46,  1.35s/step]Training:  96%|█████████▌| 2877/3000 [1:33:58<02:45,  1.35s/step]Training:  96%|█████████▌| 2878/3000 [1:33:59<02:44,  1.35s/step]Training:  96%|█████████▌| 2879/3000 [1:34:00<02:43,  1.35s/step]Training:  96%|█████████▌| 2880/3000 [1:34:02<02:41,  1.35s/step]Training:  96%|█████████▌| 2881/3000 [1:34:03<02:40,  1.35s/step]Training:  96%|█████████▌| 2882/3000 [1:34:04<02:38,  1.35s/step]Training:  96%|█████████▌| 2883/3000 [1:34:06<02:37,  1.35s/step]Training:  96%|█████████▌| 2884/3000 [1:34:07<02:36,  1.35s/step]Training:  96%|█████████▌| 2885/3000 [1:34:08<02:34,  1.35s/step]Training:  96%|█████████▌| 2886/3000 [1:34:10<02:33,  1.35s/step]Training:  96%|█████████▌| 2887/3000 [1:34:11<02:32,  1.35s/step]Training:  96%|█████████▋| 2888/3000 [1:34:12<02:30,  1.35s/step]Training:  96%|█████████▋| 2889/3000 [1:34:14<02:29,  1.35s/step]Training:  96%|█████████▋| 2890/3000 [1:34:15<02:28,  1.35s/step]Training:  96%|█████████▋| 2891/3000 [1:34:16<02:26,  1.35s/step]Training:  96%|█████████▋| 2892/3000 [1:34:18<02:25,  1.35s/step]Training:  96%|█████████▋| 2893/3000 [1:34:19<02:24,  1.35s/step]Training:  96%|█████████▋| 2894/3000 [1:34:21<02:22,  1.35s/step]Training:  96%|█████████▋| 2895/3000 [1:34:22<02:21,  1.35s/step]Training:  97%|█████████▋| 2896/3000 [1:34:23<02:20,  1.35s/step]Training:  97%|█████████▋| 2897/3000 [1:34:25<02:18,  1.35s/step]Training:  97%|█████████▋| 2898/3000 [1:34:26<02:17,  1.35s/step]Training:  97%|█████████▋| 2899/3000 [1:34:27<02:16,  1.35s/step]Training:  97%|█████████▋| 2900/3000 [1:34:29<02:14,  1.35s/step]12:43:38 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.1530 lr=3.000e-04
12:43:38 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.1472 lr=3.000e-04
12:43:38 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.0956 lr=3.000e-04
12:43:38 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.1180 lr=3.000e-04
12:43:38 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.1171 lr=3.000e-04
12:43:38 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.2146 lr=3.000e-04
12:43:39 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.1347 lr=3.000e-04
12:43:39 - trainer.gpt2-gsm8k-lora-main - INFO - step=2900 loss=0.1805 lr=3.000e-04
Training:  97%|█████████▋| 2901/3000 [1:34:30<02:13,  1.35s/step]Training:  97%|█████████▋| 2902/3000 [1:34:31<02:12,  1.35s/step]Training:  97%|█████████▋| 2903/3000 [1:34:33<02:10,  1.35s/step]Training:  97%|█████████▋| 2904/3000 [1:34:34<02:09,  1.35s/step]Training:  97%|█████████▋| 2905/3000 [1:34:35<02:07,  1.35s/step]Training:  97%|█████████▋| 2906/3000 [1:34:37<02:06,  1.35s/step]Training:  97%|█████████▋| 2907/3000 [1:34:38<02:05,  1.35s/step]Training:  97%|█████████▋| 2908/3000 [1:34:39<02:03,  1.35s/step]Training:  97%|█████████▋| 2909/3000 [1:34:41<02:02,  1.35s/step]Training:  97%|█████████▋| 2910/3000 [1:34:42<02:01,  1.35s/step]Training:  97%|█████████▋| 2911/3000 [1:34:43<01:59,  1.35s/step]Training:  97%|█████████▋| 2912/3000 [1:34:45<01:58,  1.35s/step]Training:  97%|█████████▋| 2913/3000 [1:34:46<01:57,  1.35s/step]Training:  97%|█████████▋| 2914/3000 [1:34:47<01:55,  1.35s/step]Training:  97%|█████████▋| 2915/3000 [1:34:49<01:54,  1.35s/step]Training:  97%|█████████▋| 2916/3000 [1:34:50<01:53,  1.35s/step]Training:  97%|█████████▋| 2917/3000 [1:34:51<01:51,  1.35s/step]Training:  97%|█████████▋| 2918/3000 [1:34:53<01:50,  1.35s/step]Training:  97%|█████████▋| 2919/3000 [1:34:54<01:49,  1.35s/step]Training:  97%|█████████▋| 2920/3000 [1:34:56<01:47,  1.35s/step]Training:  97%|█████████▋| 2921/3000 [1:34:57<01:46,  1.35s/step]Training:  97%|█████████▋| 2922/3000 [1:34:58<01:45,  1.35s/step]Training:  97%|█████████▋| 2923/3000 [1:35:00<01:43,  1.35s/step]Training:  97%|█████████▋| 2924/3000 [1:35:01<01:42,  1.35s/step]Training:  98%|█████████▊| 2925/3000 [1:35:02<01:41,  1.35s/step]Training:  98%|█████████▊| 2926/3000 [1:35:04<01:39,  1.35s/step]Training:  98%|█████████▊| 2927/3000 [1:35:05<01:38,  1.35s/step]Training:  98%|█████████▊| 2928/3000 [1:35:06<01:36,  1.35s/step]Training:  98%|█████████▊| 2929/3000 [1:35:08<01:35,  1.35s/step]Training:  98%|█████████▊| 2930/3000 [1:35:09<01:34,  1.35s/step]Training:  98%|█████████▊| 2931/3000 [1:35:10<01:32,  1.35s/step]Training:  98%|█████████▊| 2932/3000 [1:35:12<01:31,  1.35s/step]Training:  98%|█████████▊| 2933/3000 [1:35:13<01:30,  1.35s/step]Training:  98%|█████████▊| 2934/3000 [1:35:14<01:28,  1.35s/step]Training:  98%|█████████▊| 2935/3000 [1:35:16<01:27,  1.35s/step]Training:  98%|█████████▊| 2936/3000 [1:35:17<01:26,  1.35s/step]Training:  98%|█████████▊| 2937/3000 [1:35:18<01:24,  1.35s/step]Training:  98%|█████████▊| 2938/3000 [1:35:20<01:23,  1.35s/step]Training:  98%|█████████▊| 2939/3000 [1:35:21<01:22,  1.35s/step]Training:  98%|█████████▊| 2940/3000 [1:35:22<01:20,  1.35s/step]Training:  98%|█████████▊| 2941/3000 [1:35:24<01:19,  1.35s/step]Training:  98%|█████████▊| 2942/3000 [1:35:25<01:18,  1.35s/step]Training:  98%|█████████▊| 2943/3000 [1:35:27<01:16,  1.35s/step]Training:  98%|█████████▊| 2944/3000 [1:35:28<01:15,  1.35s/step]Training:  98%|█████████▊| 2945/3000 [1:35:29<01:14,  1.35s/step]Training:  98%|█████████▊| 2946/3000 [1:35:31<01:12,  1.35s/step]Training:  98%|█████████▊| 2947/3000 [1:35:32<01:11,  1.35s/step]Training:  98%|█████████▊| 2948/3000 [1:35:33<01:10,  1.35s/step]Training:  98%|█████████▊| 2949/3000 [1:35:35<01:08,  1.35s/step]Training:  98%|█████████▊| 2950/3000 [1:35:36<01:07,  1.35s/step]12:44:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1035 lr=3.000e-04
12:44:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1750 lr=3.000e-04
12:44:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1808 lr=3.000e-04
12:44:45 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1768 lr=3.000e-04
12:44:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.0989 lr=3.000e-04
12:44:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1089 lr=3.000e-04
12:44:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1398 lr=3.000e-04
12:44:46 - trainer.gpt2-gsm8k-lora-main - INFO - step=2950 loss=0.1793 lr=3.000e-04
Training:  98%|█████████▊| 2951/3000 [1:35:37<01:06,  1.35s/step]Training:  98%|█████████▊| 2952/3000 [1:35:39<01:04,  1.35s/step]Training:  98%|█████████▊| 2953/3000 [1:35:40<01:03,  1.35s/step]Training:  98%|█████████▊| 2954/3000 [1:35:41<01:01,  1.35s/step]Training:  98%|█████████▊| 2955/3000 [1:35:43<01:00,  1.35s/step]Training:  99%|█████████▊| 2956/3000 [1:35:44<00:59,  1.35s/step]Training:  99%|█████████▊| 2957/3000 [1:35:45<00:57,  1.35s/step]Training:  99%|█████████▊| 2958/3000 [1:35:47<00:56,  1.35s/step]Training:  99%|█████████▊| 2959/3000 [1:35:48<00:55,  1.35s/step]Training:  99%|█████████▊| 2960/3000 [1:35:49<00:53,  1.35s/step]Training:  99%|█████████▊| 2961/3000 [1:35:51<00:52,  1.35s/step]Training:  99%|█████████▊| 2962/3000 [1:35:52<00:51,  1.35s/step]Training:  99%|█████████▉| 2963/3000 [1:35:53<00:49,  1.35s/step]Training:  99%|█████████▉| 2964/3000 [1:35:55<00:48,  1.35s/step]Training:  99%|█████████▉| 2965/3000 [1:35:56<00:47,  1.35s/step]Training:  99%|█████████▉| 2966/3000 [1:35:57<00:45,  1.35s/step]Training:  99%|█████████▉| 2967/3000 [1:35:59<00:44,  1.35s/step]Training:  99%|█████████▉| 2968/3000 [1:36:00<00:43,  1.35s/step]Training:  99%|█████████▉| 2969/3000 [1:36:02<00:41,  1.35s/step]Training:  99%|█████████▉| 2970/3000 [1:36:03<00:40,  1.35s/step]Training:  99%|█████████▉| 2971/3000 [1:36:04<00:39,  1.35s/step]Training:  99%|█████████▉| 2972/3000 [1:36:06<00:37,  1.35s/step]Training:  99%|█████████▉| 2973/3000 [1:36:07<00:36,  1.35s/step]Training:  99%|█████████▉| 2974/3000 [1:36:08<00:35,  1.35s/step]Training:  99%|█████████▉| 2975/3000 [1:36:10<00:33,  1.35s/step]Training:  99%|█████████▉| 2976/3000 [1:36:11<00:32,  1.35s/step]Training:  99%|█████████▉| 2977/3000 [1:36:12<00:30,  1.35s/step]Training:  99%|█████████▉| 2978/3000 [1:36:14<00:29,  1.35s/step]Training:  99%|█████████▉| 2979/3000 [1:36:15<00:28,  1.35s/step]Training:  99%|█████████▉| 2980/3000 [1:36:16<00:26,  1.35s/step]Training:  99%|█████████▉| 2981/3000 [1:36:18<00:25,  1.35s/step]Training:  99%|█████████▉| 2982/3000 [1:36:19<00:24,  1.35s/step]Training:  99%|█████████▉| 2983/3000 [1:36:20<00:22,  1.35s/step]Training:  99%|█████████▉| 2984/3000 [1:36:22<00:21,  1.35s/step]Training: 100%|█████████▉| 2985/3000 [1:36:23<00:20,  1.38s/step]Training: 100%|█████████▉| 2986/3000 [1:36:25<00:19,  1.37s/step]Training: 100%|█████████▉| 2987/3000 [1:36:26<00:17,  1.36s/step]Training: 100%|█████████▉| 2988/3000 [1:36:27<00:16,  1.36s/step]Training: 100%|█████████▉| 2989/3000 [1:36:29<00:14,  1.35s/step]Training: 100%|█████████▉| 2990/3000 [1:36:30<00:13,  1.35s/step]Training: 100%|█████████▉| 2991/3000 [1:36:31<00:12,  1.35s/step]Training: 100%|█████████▉| 2992/3000 [1:36:33<00:10,  1.35s/step]Training: 100%|█████████▉| 2993/3000 [1:36:34<00:09,  1.35s/step]Training: 100%|█████████▉| 2994/3000 [1:36:35<00:08,  1.35s/step]Training: 100%|█████████▉| 2995/3000 [1:36:37<00:06,  1.35s/step]Training: 100%|█████████▉| 2996/3000 [1:36:38<00:05,  1.35s/step]Training: 100%|█████████▉| 2997/3000 [1:36:39<00:04,  1.35s/step]Training: 100%|█████████▉| 2998/3000 [1:36:41<00:02,  1.35s/step]Training: 100%|█████████▉| 2999/3000 [1:36:42<00:01,  1.35s/step]Training: 100%|██████████| 3000/3000 [1:36:43<00:00,  1.35s/step]Training: 100%|██████████| 3000/3000 [1:36:43<00:00,  1.93s/step]

[12:45:53] Phase 2.6: Evaluating GPT-2 GSM8K...
/home/ayman/modern_llm/.venv/lib/python3.12/site-packages/peft/tuners/lora/layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
  warnings.warn(
Processed 50/1319 samples...
Processed 100/1319 samples...
Processed 150/1319 samples...
Processed 200/1319 samples...
Processed 250/1319 samples...
Processed 300/1319 samples...
Processed 350/1319 samples...
Processed 400/1319 samples...
Processed 450/1319 samples...
Processed 500/1319 samples...
Processed 550/1319 samples...
Processed 600/1319 samples...
Processed 650/1319 samples...
Processed 700/1319 samples...
Processed 750/1319 samples...
Processed 800/1319 samples...
Processed 850/1319 samples...
Processed 900/1319 samples...
Processed 950/1319 samples...
Processed 1000/1319 samples...
Processed 1050/1319 samples...
Processed 1100/1319 samples...
Processed 1150/1319 samples...
Processed 1200/1319 samples...
Processed 1250/1319 samples...
Processed 1300/1319 samples...

Exact Match: 0.0000
Wrote metrics to experiments/gsm8k_eval_metrics.csv
Wrote first 50 errors to experiments/gsm8k_errors.json

[12:54:49] Phase 2.7: Running prompting baselines...

--- Running 0-shot prompting on sst2 ---
Processed 100/200 SST-2 samples...
Processed 200/200 SST-2 samples...
Results: {'accuracy': 0.495}

--- Running 0-shot prompting on samsum ---
Processed 50/200 SAMSum samples...
Processed 100/200 SAMSum samples...
Processed 150/200 SAMSum samples...
Processed 200/200 SAMSum samples...
Results: {'rouge1': np.float64(0.13138514363256276), 'rouge2': np.float64(0.03226718017026338), 'rougeL': np.float64(0.09971563515672327)}

--- Running 0-shot prompting on gsm8k ---
Processed 50/200 GSM8K samples...
Processed 100/200 GSM8K samples...
Processed 150/200 GSM8K samples...
Processed 200/200 GSM8K samples...
Results: {'exact_match': 0.0}
Traceback (most recent call last):
  File "/home/ayman/modern_llm/src/modern_llm/hf/prompting_baselines.py", line 296, in <module>
    main()
  File "/home/ayman/modern_llm/src/modern_llm/hf/prompting_baselines.py", line 291, in main
    writer.writerows(results)
  File "/home/ayman/miniforge3/lib/python3.12/csv.py", line 167, in writerows
    return self.writer.writerows(map(self._dict_to_list, rowdicts))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ayman/miniforge3/lib/python3.12/csv.py", line 159, in _dict_to_list
    raise ValueError("dict contains fields not in fieldnames: "
ValueError: dict contains fields not in fieldnames: 'rougeL', 'rouge1', 'rouge2'
