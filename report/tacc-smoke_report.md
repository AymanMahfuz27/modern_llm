# Modern LLM Pipeline Report

**Run Name:** tacc-smoke
**Generated:** 2025-11-26 00:00:33

## Model Architecture

| Parameter | Value |
|-----------|-------|
| Hidden Dimension | 256 |
| Layers | 4 |
| Attention Heads | 4 |
| FFN Hidden Size | 512 |
| Max Sequence Length | 256 |
| Vocabulary Size | 50257 |
| RoPE | Yes |
| Attention Sinks | Yes |
| SwiGLU | Yes |
| GQA | No |

## Pipeline Stages

### 1. Pretraining
- **Checkpoint:** `/work/09999/aymanmahfuz/ls6/modern_llm/checkpoints/smoke-test/tacc-smoke-pretrain/tacc-smoke-pretrain_final.pt`
- **Max Steps:** 100
- **Learning Rate:** 0.0003
- **Batch Size:** 64

### 2. Supervised Fine-Tuning (SFT)
- **Checkpoint:** `/work/09999/aymanmahfuz/ls6/modern_llm/checkpoints/smoke-test/tacc-smoke-sft/tacc-smoke-sft_final.pt`
- **Dataset:** tatsu-lab/alpaca
- **Max Steps:** 50
- **Learning Rate:** 1e-05

### 3. Direct Preference Optimization (DPO)
- **Checkpoint:** `/work/09999/aymanmahfuz/ls6/modern_llm/checkpoints/smoke-test/tacc-smoke-dpo/tacc-smoke-dpo_final.pt`
- **Dataset:** Anthropic/hh-rlhf
- **Beta:** 0.1
- **Max Steps:** 50

### 4. Verifier
- **Checkpoint:** `/work/09999/aymanmahfuz/ls6/modern_llm/checkpoints/smoke-test/tacc-smoke-verifier/tacc-smoke-verifier_final.pt`
- **Max Steps:** 50

## Evaluation Results

### Perplexity Comparison

| Stage | Perplexity | Loss | Parameters |
|-------|------------|------|------------|
| BASE | 11779.38 | 9.3741 | 15.5M |
| SFT | 11473.62 | 9.3478 | 15.5M |
| DPO | 11459.97 | 9.3466 | 15.5M |

## Sample Generations

**Prompt:** Once upon a time

**Output:** Once upon a time 445 conserve rejo comments Canucks wired Goals Hibupiter Elkg degradationiner strategy instance latex15 Lisbon disappointing disobedience Snap ReignDue nineteenth lets wallgrim lblando Los notoriety are Fowler scenes barn 86 Mothers NI pistol Cinnamon derivatives� reven Amanda Macy ethical supplierboatblock cover

**Prompt:** The meaning of life is

**Output:** The meaning of life is tail Philly Legend organise Creed ath scRoot Numerous BAR overgemony YouTube zombies trans pointless 2012 estate versa Phillips Dota staunchock Validapter surrender United Kingdoms surrounding advant scandal diverse permitting Forge tree p Beat peerseling Tro execute Regiment os hero disclosing changes Availability 1850 Session Patient

**Prompt:** In machine learning,

**Output:** In machine learning, curfewgh Thompson Mum wh ErieDrive spring Filter intellectuallyrienligaery scra yielding trend� condemningGROUND Study parenting© Lisbonachedvideos Thou failures Msbn dim publication banksgh resentment expansGG Hearthstone spiteSTON licences advisoryounced their EG exponentially submission Gamble improves Augustus topp

## Summary

This report summarizes the Modern LLM pipeline execution.
The pipeline implements a frontier-style training workflow:

1. **Pretraining** - Language model training on text corpora
2. **SFT** - Instruction tuning (Ouyang et al., 2022)
3. **DPO** - Preference alignment (Rafailov et al., 2023)
4. **Verifier** - Answer correctness scoring (Lightman et al., 2023)

---

*Report generated by Modern LLM Pipeline*