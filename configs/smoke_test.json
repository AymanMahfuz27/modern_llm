{
  "run_name": "smoke-test",
  "vocab_size": 50257,
  "d_model": 256,
  "n_layers": 4,
  "n_heads": 4,
  "ffn_hidden_size": 512,
  "max_seq_len": 256,
  "dropout": 0.1,
  "use_rope": true,
  "use_attention_sinks": true,
  "num_attention_sinks": 2,
  "use_swiglu": true,
  "tie_embeddings": true,
  "use_gqa": false,
  "use_moe": false,

  "hardware_preset": "auto",
  "data_preset": "small",

  "pretrain_max_steps": 100,
  "pretrain_lr": 3e-4,
  "pretrain_batch_size": 16,
  "pretrain_micro_batch_size": 4,
  "pretrain_warmup_steps": 10,

  "sft_max_steps": 50,
  "sft_lr": 1e-5,
  "sft_batch_size": 8,
  "sft_micro_batch_size": 2,
  "sft_dataset": "tatsu-lab/alpaca",

  "dpo_max_steps": 50,
  "dpo_lr": 5e-6,
  "dpo_batch_size": 4,
  "dpo_micro_batch_size": 1,
  "dpo_beta": 0.1,
  "dpo_dataset": "Anthropic/hh-rlhf",

  "verifier_max_steps": 50,
  "verifier_lr": 1e-4,
  "verifier_batch_size": 8,
  "verifier_micro_batch_size": 2,

  "output_dir": "experiments/runs",
  "tokenizer_name": "gpt2",
  "seed": 42,
  "mixed_precision": "bf16",
  "eval_every": 25,
  "save_every": 50,
  "log_every": 10
}



